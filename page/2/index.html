<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>XJH&#039;s Secret Base</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="XJH&#039;s Secret Base"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="XJH&#039;s Secret Base"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="/img/logo.png"><meta name="description" content="XJH的秘密基地"><meta property="og:type" content="blog"><meta property="og:title" content="XJH&#039;s Secret Base"><meta property="og:url" content="http://asgard-tim.github.io/"><meta property="og:site_name" content="XJH&#039;s Secret Base"><meta property="og:description" content="XJH的秘密基地"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://asgard-tim.github.io/img/og_image.png"><meta property="article:author" content="明诚"><meta property="article:tag" content="XJH&#039;s blogs"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://asgard-tim.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://Asgard-Tim.github.io"},"headline":"XJH's Secret Base","image":["http://asgard-tim.github.io/img/og_image.png"],"author":{"@type":"Person","name":"明诚"},"publisher":{"@type":"Organization","name":"XJH's Secret Base","logo":{"@type":"ImageObject","url":"http://asgard-tim.github.io/img/title.png"}},"description":"XJH的秘密基地"}</script><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/xt256.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/title.png" alt="XJH&#039;s Secret Base" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com">GitHub</a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><a class="image is-7by3" href="/2023/03/20/20230320/"><img class="fill" src="/images/story/4.jpg" alt="20230320"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-03-19T16:00:00.000Z" title="2023/3/20 00:00:00">2023-03-20</time>发表</span><span class="level-item"><time dateTime="2023-08-04T03:12:43.283Z" title="2023/8/4 11:12:43">2023-08-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/About-XJH/">About XJH</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></span><span class="level-item">5 分钟读完 (大约749个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/03/20/20230320/">20230320</a></p><div class="content"><p>“十九岁的憔悴<br>朋友 生活从不搭理心结<br>啤酒 笑声和烟<br>朋友 和我聊聊疲倦”<br>——蔡维泽《十九》<br>十四岁的时候第一次听到这首歌，或许那时的我从来不会想到，五年后的自己，会来到这座陌生的城市，开启自己新的生活。<br>可是弹指一挥间，我们就已经长大了。<br>不知道下一次再听到这首歌，想起那个和那些如烟火般绚烂的夏天，又会是谁的十九岁呢？<br>小的时候，觉得大人总是忘记自己的生日是一件特别不可思议的事情。可是，直到一两周之前，我才猛然发现，被忙碌的生活裹挟着的我们，竟也一步步沦为这样的可悲。<br>忙里偷闲，在快节奏的学习生活里学会享受生活的美好与“慢乐”，或许是之后很长一段时间内的人生课题吧。<br>很久没有发过说说了。很大一部分原因是，在经历了那些值得纪念的盛大之后，往往都已经精疲力竭了；而等到精力回复好的时候，却早已失去那股新鲜劲，分享的欲望已不在了。<br>虽然事实上，生活中许多琐碎而有趣的美好瞬间，似乎比那些精彩的活动更加值得纪念。生活着的每一分每一秒，都在真实地塑造着我们每一个人。<br>但是。尽管数不清的琐事和艰巨的项目让空闲显得那么难能可贵，尽管学习的压力逐渐消磨着我们分享与记录的欲望与能力，可值得庆幸的是，当我们还想同感彼此的悲欢，倾诉彼此的心声的时候，你们依然在我的身边，依然是那些最值得分享与信赖的朋友。<br>所以，我仍然觉得我是幸运的。起码，比十九岁的蔡维泽，要幸运很多。<br>希望，在遍体鳞伤之时，我们都能迎来，属于自己的浴火重生。<br>去看更大的世界，体验更缤纷的人生。<br>无限风光在险峰，无限伟岸雄伟壮观，有些路或许一生也难以用脚丈量。<br>那么，就勇敢的向前走吧。<br>再见了，我的十八岁。终究和你迎来告别。<br>你好，十九岁。<br>十九岁的你，应该会比十八岁更厉害吧。<br>但还是希望你，和你的朋友们，健康而快乐地，度过未来的每一天。<br>“我们仍是唱着歌的，不论悲喜的明天。”</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-03-05T05:12:58.000Z" title="2023/3/5 13:12:58">2023-03-05</time>发表</span><span class="level-item"><time dateTime="2023-08-03T09:18:18.757Z" title="2023/8/3 17:18:18">2023-08-03</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a><span> / </span><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/">工程原理</a></span><span class="level-item">30 分钟读完 (大约4448个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/03/05/car/">寻迹小车</a></p><div class="content"><h4 id="一、绪论"><a href="#一、绪论" class="headerlink" title="一、绪论"></a>一、绪论</h4><hr>
<h5 id="1-1-实验背景"><a href="#1-1-实验背景" class="headerlink" title="1.1 实验背景"></a>1.1 实验背景</h5><h6 id="1-1-1-问题的情景"><a href="#1-1-1-问题的情景" class="headerlink" title="1.1.1 问题的情景"></a>1.1.1 问题的情景</h6><p>长期以来，由于我国是人口大国而且工业基础薄弱，因此早期在我国机器人的发展受到一定的限制。然而随着制造业工人的人力成本的不断上升与社会自动化程度的不断提高，我国也开始着重于发展机器人，并且也取得了较大的进步。在 1995 年，我国沈阳自动化所开始研制HT—100A点焊机器人，是我国较早的机器人了，如图1所示；此后，沈阳新松公司研发出了6 kg弧焊机器人，此机器人不仅实用，而且轻便，如图 2 所示；之后，哈尔滨工业大学机器 人研究所也研发出了便携式机器人，此机器人具有 6 自由度，增强了焊接能力，成为在恶劣环境中实现焊接功能的重要设备。总之，在国家“863 计划”与“十一五”计划的指导下，我国机器人的设计取得了飞速发 展，甚至在机器人的某些关键部件的设计已经接近于世界先进水平，并在世界工业机器人领域已经占有一席之地了。</p>
<p><img src="/images/car/1.png" alt="1"></p>
<p><img src="/images/car/2.png" alt="2"></p>
<h6 id="1-1-2-实验的目的"><a href="#1-1-2-实验的目的" class="headerlink" title="1.1.2 实验的目的"></a>1.1.2 实验的目的</h6><p>目前，机器人的发展趋势非常的迅猛，机器人可以替代人类去从事高危险的工作，减轻了人类的劳动强度。本文通过对机器人的发展史进行简要的介绍，阐明了我国发展机器人的必要性。同时，对于我国的发展而言，我国正处于工业化进程的关键时期，将来的高强度、高危险行业的工人数量将会急剧的下降，机器人将会迎来新的“春天”，所以机器人的发展仍拥有巨大的发展空间。同时，由于我国各机器人的厂商对于机器人的研发能力与金钱投资的不同，在我国的机器人市场上的竞争也会愈演愈烈，最终也将形成我国的机器人研发市场。总之，在未来的几十年里，相信重点发展机器人将会成为社会的发展趋势，不久机器人将会引领未来，加入到我国现代化建设的行列中。小车，也就是轮式机器人，作为以学科交叉、产品创新为特色的明月班同学，切入这个产业不失为优秀的选择，故而选取小车为切入点了解相关知识。</p>
<h5 id="1-2-实验内容"><a href="#1-2-实验内容" class="headerlink" title="1.2 实验内容"></a>1.2 实验内容</h5><h6 id="1-2-1-使用51单片机控制及其元器件"><a href="#1-2-1-使用51单片机控制及其元器件" class="headerlink" title="1.2.1 使用51单片机控制及其元器件"></a>1.2.1 使用51单片机控制及其元器件</h6><p>STC89C52控制板芯片、1.5V干电池x4、L298N电机驱动板x1、红外循迹模块、直流电机x2以及搭建材料若干；</p>
<p><img src="/images/car/3.jpg" alt="3"></p>
<h6 id="1-2-2使用FPGA开发板控制及其元器件"><a href="#1-2-2使用FPGA开发板控制及其元器件" class="headerlink" title="1.2.2使用FPGA开发板控制及其元器件"></a>1.2.2使用FPGA开发板控制及其元器件</h6><p>Cyclonell EP2C5T144控制板芯片1.5V干电池x4、L298N电机驱动板x1、红外循迹模块、直流电机x2以及搭建材料若干；</p>
<p><img src="/images/car/4.jpg" alt="4"></p>
<br>

<h4 id="二、实现过程"><a href="#二、实现过程" class="headerlink" title="二、实现过程"></a>二、实现过程</h4><hr>
<h5 id="2-1-总体工作原理简释"><a href="#2-1-总体工作原理简释" class="headerlink" title="2.1 总体工作原理简释"></a>2.1 总体工作原理简释</h5><h6 id="2-1-2-红外循迹模块"><a href="#2-1-2-红外循迹模块" class="headerlink" title="2.1.2 红外循迹模块"></a>2.1.2 红外循迹模块</h6><p>第一步，位于小车前端的红外模块会释放红外线探测下方是否为黑色区域，并将相应的高低电平信号传递至控制模块（51单片机&#x2F;FPGA开发板）处理，控制模块随后将发送信息至L298N电机驱动的控制模块，并由此控制左右两轮的转动速度以及转动方向，从而实现对黑线的反应和循迹。</p>
<p>作为电机的驱动模块，该模块对控制小车移动有着重要且直接的作用。</p>
<p><img src="/images/car/5.png" alt="5"></p>
<p>利用红外发射器向地面发射红外线，并用传感器接收由地面反射的红外线。当红外接收模块下方为黑色轨迹时，红外线被黑色轨迹吸收，传感器没有接收到红外线，红外循迹模块输出低电平到单片机。反之，传感器接收到红外线，红外循迹模块输出高电平到单片机。可通过红外循迹模块输出的信号来判断小车是否偏离轨迹。可调电阻可以调节传感器的灵敏度，易于调试。使用红外循迹模块方案也易于实现，红外循迹方案相比于摄像循迹成本更加便宜，软件设计更加简单，设计制作周期短，具备一定可靠性。</p>
<p>对于左电机，共有输入ENA、IN1、IN2，输出OUT1（黑线）、OUT2（红线）、其信号与运动对应如下：（0,X,X）停止、（1,0,0）停止、（1,1,0）正传、（1,0,1）反转、（1,1,1）停止；</p>
<p>对于右电机，共有输入ENB、IN3、IN4，输出OUT3（黑线）、OUT4（红线），其信号与运动对应如下：（0,X,X）停止、（1,0,0）停止、（1,1,0）反传、（1,0,1）正转、（1,1,1）停止。</p>
<h6 id="2-1-3-L298N电机驱动模块"><a href="#2-1-3-L298N电机驱动模块" class="headerlink" title="2.1.3 L298N电机驱动模块"></a>2.1.3 L298N电机驱动模块</h6><p><img src="/images/car/6.jpg" alt="6"></p>
<p>L298N是ST公司的一款电机驱动芯片，也是集成了双H桥，但与上面两个略有不同。电机驱动电压3~48V；可持续工作的输出电流为2A，峰值可达3A。如上图，L298N模块明显有较多的外接元件，这与L298N的内部结构有关。如上图，由于该芯片在H桥上的损耗严重发热较明显（饱和压降大），需要加装散热片，因此在使用上比前两个芯片复杂，体积也相对较大。其各引脚如下图所示。</p>
<p><img src="/images/car/7.png" alt="7"></p>
<h5 id="2-2-使用51单片机部分"><a href="#2-2-使用51单片机部分" class="headerlink" title="2.2 使用51单片机部分"></a>2.2 使用51单片机部分</h5><h6 id="2-2-1-硬件接线"><a href="#2-2-1-硬件接线" class="headerlink" title="2.2.1 硬件接线"></a>2.2.1 硬件接线</h6><p><img src="/images/car/8.png" alt="8"></p>
<p><img src="/images/car/9.png" alt="9"></p>
<p>1为电源输入，与电池盒的输出线相连；2为电源输出，3为驱动板输入，两者需要相连，注意红线为VCC，黑线为GND；4 为单片机IO口引脚，5为驱动板的IN1到 IN4以及ENA和ENB，按照器件上的标注对应连接即可。 6 为与循迹模块的对应接口，按照器件上的标注对应连接即可。 7 和 8 为驱动板与两个电机之间的连线，按照上图所示连接即可。 到这里，基本完成了小车的硬件组装与线路连接，小车要完成循迹进行这些连线就够了，不过在烧录程序到单片机中时还需要 额外的连线，这个将在后面进行说明。</p>
<p>供电上使用四节5号电池。</p>
<h6 id="2-2-2-程序设计"><a href="#2-2-2-程序设计" class="headerlink" title="2.2.2 程序设计"></a>2.2.2 程序设计</h6><p>首先是如何处理红外模块的探测结果。我们需要先对结果进行编码。我们记没有识别到黑线为0，识别到为1，则我们需要一个算式来囊括左右传感器结果并能对不同情况进行表示。在这里，我们记data2为左边的结果，data3为右边的结果，现给出算式data1&#x3D;data2*10+data3，data1即检测结果。根据data2、data3不同组合：（1,1）在黑线上；（1,0）略向右偏离；（0,1）略向左偏离；（0,0）完全偏离轨道，分别对应了data1的四个取值，即11、10、1、0，亦即四种情况。相应的，我们需要做出四种反馈，即“前进”、“左转”、“右转”、“停下”。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;reg52.h&gt;</span><span class="comment">//51头文件</span></span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> pwm\_val\_left, pwm\_val\_right; <span class="comment">//中间变量</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> pwm\_left, pwm\_right; <span class="comment">//定义PWM输出高电平的时间的变量（用户操作PWM的变量）</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PWM\_DUTY 100 <span class="comment">//定义PWM的周期，数值为定时器0溢出周期，假如定时器溢出时间为100us，则PWM周期为10ms。</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PWM\_HIGH\_MIN 35 <span class="comment">//限制PWM输出的最小占空比</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PWM\_HIGH\_MAX PWM\_DUTY <span class="comment">//限制PWM输出的最大占空比</span></span></span><br><span class="line"></span><br><span class="line">/\*电机驱动IO定义\*/</span><br><span class="line">sbit leftMotorPwm = P1^<span class="number">5</span>; <span class="comment">//为1 左电机使能</span></span><br><span class="line">sbit IN1 = P1^<span class="number">4</span>; <span class="comment">//为1 左电机正转</span></span><br><span class="line">sbit IN2 = P1^<span class="number">3</span>; <span class="comment">//为1 左电机反转</span></span><br><span class="line">sbit IN3 = P1^<span class="number">2</span>; <span class="comment">//为1 右电机反转</span></span><br><span class="line">sbit IN4 = P1^<span class="number">1</span>; <span class="comment">//为1 右电机正转</span></span><br><span class="line">sbit rightMotorPwm = P1^<span class="number">0</span>; <span class="comment">//为1 右电机使能</span></span><br><span class="line"></span><br><span class="line">sbit leftSensor = P3^<span class="number">4</span>;<span class="comment">//左传感器：为0没有识别到黑线，为1识别到黑线</span></span><br><span class="line">sbit rightSensor = P3^<span class="number">5</span>;<span class="comment">//右传感器：为0没有识别到黑线，为1识别到黑线</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> Timer0\_Init(<span class="type">void</span>); <span class="comment">//定时器初始化</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">LoadPWM</span><span class="params">(<span class="type">void</span>)</span>;<span class="comment">//装入PWM输出值</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">forward</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> LeftSpeed, <span class="type">unsigned</span> <span class="type">char</span> RightSpeed)</span>;<span class="comment">//前进</span></span><br><span class="line"><span class="type">void</span> left\_run(<span class="type">unsigned</span> <span class="type">char</span> LeftSpeed, <span class="type">unsigned</span> <span class="type">char</span> RightSpeed);<span class="comment">//左转</span></span><br><span class="line"><span class="type">void</span> right\_run(<span class="type">unsigned</span> <span class="type">char</span> LeftSpeed, <span class="type">unsigned</span> <span class="type">char</span> RightSpeed);<span class="comment">//右转</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">back</span><span class="params">(<span class="type">void</span>)</span>;<span class="comment">//后退修正</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Tracking</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//为0 没有识别到黑线 为1识别到黑线</span></span><br><span class="line"><span class="type">char</span> data1, data2 = leftSensor,data3 = rightSensor;</span><br><span class="line">data1 = data2\*<span class="number">10</span>+data3;</span><br><span class="line"><span class="keyword">if</span>(data1 == <span class="number">11</span>)<span class="comment">//在黑线上，前进</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//forward(120,120);//前进</span></span><br><span class="line">forward(<span class="number">70</span>,<span class="number">70</span>);<span class="comment">//前进</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(data1 == <span class="number">10</span>)<span class="comment">//小幅偏右，左转</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//left\_run(80,160);//左转</span></span><br><span class="line">left\_run(<span class="number">70</span>,<span class="number">70</span>);<span class="comment">//左转</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(data1 == <span class="number">1</span>)<span class="comment">//小幅偏左，右转</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//right\_run(160,80);//右转</span></span><br><span class="line">right\_run(<span class="number">70</span>,<span class="number">70</span>);<span class="comment">//右转</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(data1 == <span class="number">0</span>)<span class="comment">//大幅偏左或偏右，已脱离轨道</span></span><br><span class="line">&#123;</span><br><span class="line">back();<span class="comment">//后退校正</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/\*主函数\*/</span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">Timer0\_Init();<span class="comment">//定时0初始化</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">Tracking();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">forward</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> LeftSpeed,<span class="type">unsigned</span> <span class="type">char</span> RightSpeed)</span></span><br><span class="line">&#123;</span><br><span class="line">pwm\_left = LeftSpeed,pwm\_right = RightSpeed;<span class="comment">//设置速度</span></span><br><span class="line">IN1 = <span class="number">1</span>;</span><br><span class="line">IN2 = <span class="number">0</span>;</span><br><span class="line">IN3 = <span class="number">0</span>;</span><br><span class="line">IN4 = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> left\_run(<span class="type">unsigned</span> <span class="type">char</span> LeftSpeed, <span class="type">unsigned</span> <span class="type">char</span> RightSpeed)</span><br><span class="line">&#123;</span><br><span class="line">pwm\_left = LeftSpeed,pwm\_right = RightSpeed;<span class="comment">//设置速度</span></span><br><span class="line">IN1 = <span class="number">1</span>;</span><br><span class="line">IN2 = <span class="number">0</span>;</span><br><span class="line">IN3 = <span class="number">1</span>;</span><br><span class="line">IN4 = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> right\_run(<span class="type">unsigned</span> <span class="type">char</span> LeftSpeed, <span class="type">unsigned</span> <span class="type">char</span> RightSpeed)</span><br><span class="line">&#123;</span><br><span class="line">pwm\_left = LeftSpeed,pwm\_right = RightSpeed;<span class="comment">//设置速度</span></span><br><span class="line">IN1 = <span class="number">0</span>;</span><br><span class="line">IN2 = <span class="number">1</span>;</span><br><span class="line">IN3 = <span class="number">0</span>;</span><br><span class="line">IN4 = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">back</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">pwm\_left = LeftSpeed,pwm\_right = RightSpeed;<span class="comment">//设置速度</span></span><br><span class="line">IN1 = <span class="number">0</span>;</span><br><span class="line">IN2 = <span class="number">1</span>;</span><br><span class="line">IN3 = <span class="number">1</span>;</span><br><span class="line">IN4 = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\* Timer0初始化\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/</span><br><span class="line"><span class="type">void</span> Timer0\_Init(<span class="type">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">TMOD |= <span class="number">0x02</span>;<span class="comment">//定时器0，8位自动重装模块</span></span><br><span class="line">TH0 = <span class="number">164</span>;</span><br><span class="line">TL0 = <span class="number">164</span>;<span class="comment">//11.0592M晶振，12T溢出时间约等于100微秒</span></span><br><span class="line">TR0 = <span class="number">1</span>;<span class="comment">//启动定时器0</span></span><br><span class="line">ET0 = <span class="number">1</span>;<span class="comment">//允许定时器0中断</span></span><br><span class="line">EA = <span class="number">1</span>;<span class="comment">//总中断允许</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\* Timer0中断函数\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/</span><br><span class="line"><span class="type">void</span> timer0\_int (<span class="type">void</span>) interrupt <span class="number">1</span></span><br><span class="line">&#123;</span><br><span class="line">pwm\_val\_left++;</span><br><span class="line">pwm\_val\_right++;</span><br><span class="line"><span class="keyword">if</span>(pwm\_left &gt; PWM\_HIGH\_MAX) pwm\_left = PWM\_HIGH\_MAX; <span class="comment">//如果左输出写入大于最大占空比数据，则强制为最大占空比。</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_left &lt; PWM\_HIGH\_MIN) pwm\_left = PWM\_HIGH\_MIN; <span class="comment">//如果左输出写入小于最小占空比数据，则强制为最小占空比。</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_right &gt; PWM\_HIGH\_MAX) pwm\_right = PWM\_HIGH\_MAX; <span class="comment">//如果右输出写入大于最大占空比数据，则强制为最大占空比。</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_right &lt; PWM\_HIGH\_MIN) pwm\_right = PWM\_HIGH\_MIN; <span class="comment">//如果右输出写入小于最小占空比数据，则强制为最小占空比。</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_val\_left&lt;=pwm\_left) leftMotorPwm = <span class="number">1</span>; <span class="comment">//装载左PWM输出高电平时间</span></span><br><span class="line"><span class="keyword">else</span> leftMotorPwm = <span class="number">0</span>; <span class="comment">//装载左PWM输出低电平时间</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_val\_left&gt;=PWM\_DUTY) pwm\_val\_left = <span class="number">0</span>; <span class="comment">//如果左对比值大于等于最大占空比数据，则为零</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_val\_right&lt;=pwm\_right) rightMotorPwm = <span class="number">1</span>; <span class="comment">//装载右PWM输出高电平时间</span></span><br><span class="line"><span class="keyword">else</span> rightMotorPwm = <span class="number">0</span>; <span class="comment">//装载右PWM输出低电平时间</span></span><br><span class="line"><span class="keyword">if</span>(pwm\_val\_right&gt;=PWM\_DUTY) pwm\_val\_right = <span class="number">0</span>; <span class="comment">//如果右对比值大于等于最大占空比数据，则为零</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="2-3-使用FPGA开发板部分"><a href="#2-3-使用FPGA开发板部分" class="headerlink" title="2.3 使用FPGA开发板部分"></a>2.3 使用FPGA开发板部分</h5><h6 id="2-3-1-硬件接线"><a href="#2-3-1-硬件接线" class="headerlink" title="2.3.1 硬件接线"></a>2.3.1 硬件接线</h6><p>系统时钟和复位信号必须为PIN17和PIN_90，不过这两个引脚在开发板上已经连接上了，无须手动连接。其它的引脚可以在下表中“FPGA引出I&#x2F;O”部分选择即可，然后参照之间的51单片机进行连接。</p>
<p>此处附上接线实物图，需要注意的是，FPGA需要独立的接线供电，如充电宝等等。</p>
<p><img src="/images/car/10.jpg" alt="10"></p>
<h6 id="2-3-2程序设计"><a href="#2-3-2程序设计" class="headerlink" title="2.3.2程序设计"></a>2.3.2程序设计</h6><p>逻辑上大体与51相同，此处附上代码部分以及引脚的设置图。</p>
<p><img src="/images/car/11.jpg" alt="11"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">LIBRARY ieee;</span><br><span class="line">USE ieee.<span class="built_in">std</span>\_logic\_1164.all;</span><br><span class="line">ENTITY cartracking IS</span><br><span class="line"><span class="title function_">GENERIC</span> <span class="params">(</span></span><br><span class="line"><span class="params">--时钟为<span class="number">50</span>MHz，为了产生<span class="number">100</span>Hz的PWM波，设置计数值为<span class="number">500000</span></span></span><br><span class="line"><span class="params">cnt\_meta : INTEGER := <span class="number">500000</span>;</span></span><br><span class="line"><span class="params">--对应了停止、前进、左转、右转状态IN4到IN1的输出</span></span><br><span class="line"><span class="params">Back : STD\_LOGIC\_VECTOR(<span class="number">3</span> DOWNTO <span class="number">0</span>) := <span class="string">&quot;0110&quot;</span>;</span></span><br><span class="line"><span class="params">Forward : STD\_LOGIC\_VECTOR(<span class="number">3</span> DOWNTO <span class="number">0</span>) := <span class="string">&quot;1001&quot;</span>;</span></span><br><span class="line"><span class="params">Left\_Go : STD\_LOGIC\_VECTOR(<span class="number">3</span> DOWNTO <span class="number">0</span>) := <span class="string">&quot;0101&quot;</span>;</span></span><br><span class="line"><span class="params">Right\_Go : STD\_LOGIC\_VECTOR(<span class="number">3</span> DOWNTO <span class="number">0</span>) := <span class="string">&quot;1010&quot;</span></span></span><br><span class="line"><span class="params">)</span>;</span><br><span class="line"></span><br><span class="line">--\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*输入输出端口\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*</span><br><span class="line">PORT (</span><br><span class="line">sys\_clk : IN STD\_LOGIC;</span><br><span class="line">sys\_rst\_n : IN STD\_LOGIC;</span><br><span class="line">infrared : IN STD\_LOGIC\_VECTOR(<span class="number">1</span> DOWNTO <span class="number">0</span>);</span><br><span class="line">pwm\_left : OUT STD\_LOGIC;</span><br><span class="line">pwm\_right : OUT STD\_LOGIC;</span><br><span class="line">in\_motor : OUT STD\_LOGIC\_VECTOR(<span class="number">3</span> DOWNTO <span class="number">0</span>)</span><br><span class="line">);</span><br><span class="line">END cartracking;</span><br><span class="line"></span><br><span class="line">ARCHITECTURE trans OF cartracking IS</span><br><span class="line">SIGNAL cnt : INTEGER;</span><br><span class="line">SIGNAL duty\_left : INTEGER;</span><br><span class="line">SIGNAL duty\_right : INTEGER;</span><br><span class="line">BEGIN</span><br><span class="line"><span class="title function_">PROCESS</span> <span class="params">(sys\_rst\_n, infrared)</span></span><br><span class="line">BEGIN</span><br><span class="line"><span class="title function_">IF</span> <span class="params">(sys\_rst\_n = <span class="string">&#x27;0&#x27;</span>)</span> THEN</span><br><span class="line">duty\_right &lt;= <span class="number">60</span>;</span><br><span class="line">duty\_left &lt;= <span class="number">60</span>;</span><br><span class="line">ELSE</span><br><span class="line">CASE infrared IS</span><br><span class="line">WHEN <span class="string">&quot;00&quot;</span> =&gt;</span><br><span class="line">in\_motor &lt;= Back;--后退</span><br><span class="line">WHEN <span class="string">&quot;01&quot;</span> =&gt;</span><br><span class="line">in\_motor &lt;= Right\_Go;--右转</span><br><span class="line">--PWM波的占空比，应设置合适的值来控制小车的转速，为了在仿真时可以对比，特将左右轮设置了不同的占空比。</span><br><span class="line">duty\_left &lt;= <span class="number">35</span>;</span><br><span class="line">duty\_right &lt;= <span class="number">55</span>;</span><br><span class="line">WHEN <span class="string">&quot;10&quot;</span> =&gt;</span><br><span class="line">in\_motor &lt;= Left\_Go;--左转</span><br><span class="line">duty\_left &lt;= <span class="number">55</span>;</span><br><span class="line">duty\_right &lt;= <span class="number">35</span>;</span><br><span class="line">WHEN OTHERS =&gt;</span><br><span class="line">in\_motor &lt;= Forward;--前进</span><br><span class="line">duty\_left &lt;= <span class="number">50</span>;</span><br><span class="line">duty\_right &lt;= <span class="number">50</span>;</span><br><span class="line">END CASE;</span><br><span class="line">END IF;</span><br><span class="line">END PROCESS;</span><br><span class="line"></span><br><span class="line">PROCESS (sys\_clk, sys\_rst\_n)</span><br><span class="line">BEGIN</span><br><span class="line"><span class="title function_">IF</span> <span class="params">(sys\_rst\_n = <span class="string">&#x27;0&#x27;</span>)</span> THEN</span><br><span class="line">cnt &lt;= <span class="number">0</span>;</span><br><span class="line">ELSIF (sys\_clk<span class="number">&#x27;</span>EVENT AND sys\_clk = <span class="string">&#x27;1&#x27;</span>) THEN</span><br><span class="line"><span class="title function_">IF</span> <span class="params">(cnt = cnt\_meta)</span> THEN</span><br><span class="line">cnt &lt;= <span class="number">0</span>;</span><br><span class="line">ELSE</span><br><span class="line">cnt &lt;= cnt + <span class="number">1</span>;</span><br><span class="line">END IF;</span><br><span class="line">END IF;</span><br><span class="line">END PROCESS;</span><br><span class="line"></span><br><span class="line">PROCESS (sys\_clk, sys\_rst\_n)</span><br><span class="line">BEGIN</span><br><span class="line"><span class="title function_">IF</span> <span class="params">(sys\_rst\_n = <span class="string">&#x27;0&#x27;</span>)</span> THEN</span><br><span class="line">pwm\_left &lt;= <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">pwm\_right &lt;= <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">ELSIF (sys\_clk<span class="number">&#x27;</span>EVENT AND sys\_clk = <span class="string">&#x27;1&#x27;</span>) THEN</span><br><span class="line"><span class="title function_">IF</span> <span class="params">(cnt &gt;= (cnt\_meta / <span class="number">100</span>)\* duty\_left)</span> THEN</span><br><span class="line">pwm\_left &lt;= <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">ELSE</span><br><span class="line">pwm\_left &lt;= <span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">END IF;</span><br><span class="line">IF (cnt &gt;= (cnt\_meta / <span class="number">100</span>) \* duty\_right) THEN</span><br><span class="line">pwm\_right &lt;= <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">ELSE</span><br><span class="line">pwm\_right &lt;= <span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">END IF;</span><br><span class="line">END IF;</span><br><span class="line">END PROCESS;</span><br><span class="line">END trans;</span><br></pre></td></tr></table></figure>

<br>

<h4 id="3调试及优化"><a href="#3调试及优化" class="headerlink" title="3调试及优化"></a>3调试及优化</h4><hr>
<h5 id="3-1简单优化"><a href="#3-1简单优化" class="headerlink" title="3.1简单优化"></a>3.1简单优化</h5><p>由于在测试时需要在保证小车前进速度的同时兼顾其转弯的效率和稳定性，特别是如果直行时转速过快会导致小车在转弯时直接冲出赛道而无法循迹。在原本的设计中，我们将未识别到黑线的反应设置为电机停转而使得小车停止，而这会使得小车无法在冲出赛道后进行自我校正。因此，我们将未识别到黑线时的输出信号由“0000”改为“0110”，即使得左右电机均由原本的停转改为反转，从而实现循迹过程中对于轨道循迹的自我修正。</p>
<p>在 PWM 频率设置的时候， PWM 的频率太低可能导致电机转动不稳定，不 是匀速转动，而 PWM 频率过高可能导致电机反应不过来或者超过电路的上限截止频率。事实上，考虑到转弯过程的稳定性与速度问题，包括与直行过程的速度以及传感器的灵敏度调节配合，我们需要通过实际测试来进一步确定在直行、左转、右转和倒退过程中设定的PWM占空比与转速。具体在调试之后所得到的合适参数已经在上面的代码中有所体现，在此不过多赘述。</p>
<p><img src="/images/car/12.png" alt="12"></p>
<p><img src="/images/car/13.png" alt="13"></p>
<h5 id="3-2调试过程"><a href="#3-2调试过程" class="headerlink" title="3.2调试过程"></a>3.2调试过程</h5><p>考虑到验收时的重要评判标准是小车循迹一周的时间，且小车本身运动缓慢，我们首先将目光放在了转速的提高上。修改参数大幅提高了轮子的转速后，我们进行了一次实验：结果出乎意料，小车非但没有预想的那样，反而在行进的过程中持续摇摆。分析原因是行进角度不平行于轨道时容易冲出轨道，后续针对此原因，在红外灵敏度以及直行、左转、右转和倒退过程中设定的PWM占空比与转速多次调试与测试。中途红外模块损坏，经过排查确定后更换了新的。此外，我们注意到行进中的不稳定性还来自于万向轮的松散，我们尝试了不限于胶带、缠绳等各种方式加以限制，效果均不理想，虽然直道可以稳定快速行进，转弯却尤为吃力。</p>
<p>最后51的部分取得了第二名的不错成绩。但是FPGA部分却难遂人意。我们一直将注意力放在数据的调试上却忽略了时间的把控，以至于直到最后快结束才仓促进行测试，测试时还发生了接线断开等突发状况。我们本着希望更加灵活的愿望想别的同学借来充电宝供电，没想到这成为了测试失败的最大缘由——充电宝供电严重不足，导致小车行进乏力，但等到我们重新接上电脑供电确认可以正常运行时，却被告知时间已到，不允许再次测试以保证公平。最后无奈接受这个最慢的成绩。</p>
<br>

<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><hr>
<p>[1] 默默无闻小菜鸡. 电机驱动芯片（H桥、直流电机驱动方式）——DRV8833、TB6612、A4950、L298N的详解与比较[EB&#x2F;OL]. <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44897194/article/details/105524808">https://blog.csdn.net/qq_44897194/article/details/105524808</a>, 2020-5-11.</p>
<p>[2] 周海,叶兵. 机器人的发展现状及应用前景[J]. <a target="_blank" rel="noopener" href="https://kns.cnki.net/kcms2/article/abstract?v=3uoqIhG8C44YLTlOAiTRKibYlV5Vjs7iAEhECQAQ9aTiC5BjCgn0Rn5ykE3W8_mbbrKtMuQk3r9gP-p4derKJErhs1XrNO9Y&uniplatform=NZKPT">https://kns.cnki.net/kcms2/article/abstract?v=3uoqIhG8C44YLTlOAiTRKibYlV5Vjs7iAEhECQAQ9aTiC5BjCgn0Rn5ykE3W8_mbbrKtMuQk3r9gP-p4derKJErhs1XrNO9Y&amp;uniplatform=NZKPT</a>, 2017-6-18.</p>
<br>

<h4 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h4><hr>
<p>感谢老师们在本课程中的精心准备与付出。在数电和模电部分得到了曾正教授和袁刚教授的悉心教诲，在后续的项目部分得到了李敏教授和凌睿教授的认真指导，最终得以基本实现预定目标，特此鸣谢！</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-02-11T15:23:03.000Z" title="2023/2/11 23:23:03">2023-02-11</time>发表</span><span class="level-item"><time dateTime="2023-08-04T05:43:29.521Z" title="2023/8/4 13:43:29">2023-08-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a><span> / </span><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></span><span class="level-item">几秒读完 (大约75个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/02/11/facerecognition/">人脸识别项目</a></p><div class="content"><p>本项目全部代码已同步上传至Github,仓库链接：<a target="_blank" rel="noopener" href="https://github.com/Asgard-Tim/face_recoginition">Asgard-Tim&#x2F;face_recoginition: 重庆大学明月科创实验班线性代数课程项目 (github.com)</a></p>
<p>使用方法与识别效果如下。</p>
<p><img src="/images/face/1.png" alt="1"></p>
<p><img src="/images/face/2.png" alt="2"></p>
<p><img src="/images/face/3.png" alt="3"></p>
<p><img src="/images/face/4.png" alt="4"></p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2023/01/01/20230101/"><img class="fill" src="/images/story/5.jpg" alt="20230101"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-12-31T16:00:00.000Z" title="2023/1/1 00:00:00">2023-01-01</time>发表</span><span class="level-item"><time dateTime="2023-08-04T03:12:59.626Z" title="2023/8/4 11:12:59">2023-08-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/About-XJH/">About XJH</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></span><span class="level-item">7 分钟读完 (大约1047个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/01/01/20230101/">20230101</a></p><div class="content"><p>“天空不留下我的痕迹，但我已经飞过。”<br>我们或许都只是漫漫岁月长河之中的过客罢了。<br>好像是在重庆的某个瞬间，看到手机上苏州地铁S1线23年底有望开通的时候，才突然想起来，好像已经是2022年了。<br>小的时候看新闻夜班车说十年之后苏州会有一条地铁叫S1，可以直接从苏州乘到上海，那个时候觉得这是多么的不可思议，而十年又是多么漫长。<br>却是一眨眼就来到。<br>即使是现在，想想这一年过来仍然是做梦一般。零模之后是为了HanYu而疯狂的一整个冬天和4A＜的遗憾收场，然后是疫情打乱了所有人的步伐顺便毁掉了最后的春天和最后的樱花。昙花一现之后是低谷，站起来之后再倒下然后再是拼命爬起，高考最终还是猝不及防地如期而至。接着就是混乱之夏。兴奋、焦急、离别、泪水、遗憾、愤怒、纠结、不甘与沉沦，这些词语交织在一起，连同着记忆中的那片园子和那些这辈子都不会忘记的好朋友，共同埋葬了整个夏天和整个青春。但时光从不让我们做好准备，金秋九月大学的生活依旧虽迟但到，我们被迫分别，终究还是离开了这个学习生活了十余载的故乡，来到了陌生的城市，对于新的生活与新的世界充满了美好的幻想，却仍然被最后的疫情击得粉碎碎。所有的尝试与冲撞终究败给了现实，所幸热爱可抵岁月漫长。国庆节的二次选拔充满了戏剧性，从满怀期待到心慌意乱再到欣喜若狂却终究败兴而归然后是重整行装东山再起最终还是不负众望，一切都是命运最好的安排。紧接着迎来的就是一段“痛并快乐着”的忙碌生活，充实快乐与疲惫不堪裹挟着我们每一个人，最后还是被返乡的风吹回县城，小阳人终于迎来了久违的安逸与平静。<br>把这一年的故事讲完，我的内心静如止水。或者是释怀，或许是淡然，但所有的轰轰烈烈都是那么刻骨铭心，我们也终究要告别热烈的过去，奔赴更加美好的未来。<br>没有遗憾是不可能的，但过往的挫败从来不妨碍我们继续向前奋力奔跑，不是吗？朝着更美好的明天。<br>生命的意义，就是即使知晓痛苦的结局，依然向着命运抗争。<br>“你无法阻止波涛汹涌，但你可以学会踏浪而行。”<br>卑微的起点会促使你开始一件事，但是让你坚持下来的，一定是热情和使命。<br>生命要么是一场伟大的冒险，要么什么都不是。<br>All in, or nothing.<br>悟已往之不谏，知来者之可追。<br>钟表能回到原点，但不再是昨天。<br>所以我们从不后悔，也从不停止向前。<br>没有借口。下次人山人海，我会站上去。<br>“祝愿祖国繁荣昌盛、国泰民安！祝愿世界和平美好、幸福安宁！祝愿大家新年快乐、皆得所愿！”<br>那么，就是2023了。<br>这一年，又会发生些什么呢？我也不知道。<br>但我唯一知道的是，你们肯定还在，还在我的身边。<br>岂曰无衣，与子同袍。<br>兄弟们天下无敌！<br>新年快乐！</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/10/09/20221009/"><img class="fill" src="/images/story/6.jpg" alt="20221009"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-09T12:00:00.000Z" title="2022/10/9 20:00:00">2022-10-09</time>发表</span><span class="level-item"><time dateTime="2023-08-04T03:11:44.295Z" title="2023/8/4 11:11:44">2023-08-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/About-XJH/">About XJH</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></span><span class="level-item">几秒读完 (大约98个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/09/20221009/">20221009</a></p><div class="content"><p>“热爱可抵岁月漫长。”<br>生命要么是一场伟大的冒险，要么什么都不是。<br>生命的意义，就是即使知晓痛苦的结局，依然向着命运抗争。<br>“你无法阻止波涛汹涌，但你可以学会踏浪而行。”<br>努力终会有回报，我用歌声来证明！</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-10-04T11:31:00.000Z" title="2022/10/4 19:31:00">2022-10-04</time>发表</span><span class="level-item"><time dateTime="2023-08-04T03:11:41.121Z" title="2023/8/4 11:11:41">2023-08-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/About-XJH/">About XJH</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></span><span class="level-item">2 分钟读完 (大约231个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/10/04/20221004/">20221004</a></p><div class="content"><p>昂首阔步向前走，向着过去挥挥手。<br>当然这远远不够，往前走之后你还要跳跃，这个跳跃就是信仰。<br>荒谬就是理性遇到了终点，但理性的终点就是信仰的起点。<br>人类社会一路走来，过去我们看到雷鸣电闪，我们有了神话；后来我们看到战争，我们遇到了宗教；现代人遭遇了生活的荒谬，我们有了哲学。<br>我们从来没有放弃过信仰，尤其是对苦难的信仰。<br>多难兴邦，天将降大任于斯人也。<br>这跟享受荒谬一样，是多么反直觉的答案，但这个答案就叫做信仰。<br>我们必须从苦难中汲取营养，因为只有享受苦难，我们才能享受生活。</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/09/27/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"><img class="fill" src="/images/phi.png" alt="2.预备知识"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-09-27T06:06:00.000Z" title="2022/9/27 14:06:00">2022-09-27</time>发表</span><span class="level-item"><time dateTime="2023-09-27T06:08:32.900Z" title="2023/9/27 14:08:32">2023-09-27</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a></span><span class="level-item">10 分钟读完 (大约1440个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/09/27/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/">2.预备知识</a></p><div class="content"><h2 id="2-1-数据操作"><a href="#2-1-数据操作" class="headerlink" title="2.1 数据操作"></a>2.1 数据操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">12</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([12])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.numel()</span><br></pre></td></tr></table></figure>




<pre><code>12
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X=x.reshape(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([3, 4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y=x.reshape(-<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line">Y</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Z=x.reshape(<span class="number">3</span>,-<span class="number">1</span>)</span><br><span class="line">Z</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.zeros((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]],

        [[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 1.6438, -1.2879,  0.2324,  0.2719],
        [-0.6636,  0.9939, -0.8435, -1.0906],
        [-0.5617,  0.2107, -0.9530,  0.7362]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=torch.tensor([<span class="number">1.0</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">8</span>])</span><br><span class="line">y=torch.tensor([<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">x+y,x-y,x*y,x/y,x**y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([ 3.,  4.,  6., 10.]),
 tensor([-1.,  0.,  2.,  6.]),
 tensor([ 2.,  4.,  8., 16.]),
 tensor([0.5000, 1.0000, 2.0000, 4.0000]),
 tensor([ 1.,  4., 16., 64.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(x)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X=torch.arange(<span class="number">12</span>,dtype=torch.float32).reshape((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y=torch.tensor([[<span class="number">2.0</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]])</span><br><span class="line">Y</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[2., 1., 4., 3.],
        [1., 2., 3., 4.],
        [4., 3., 2., 1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat((X,Y),dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.],
        [ 2.,  1.,  4.,  3.],
        [ 1.,  2.,  3.,  4.],
        [ 4.,  3.,  2.,  1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat((X,Y),dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X==Y,X&lt;Y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[False,  True, False,  True],
         [False, False, False, False],
         [False, False, False, False]]),
 tensor([[ True, False,  True, False],
         [False, False, False, False],
         [False, False, False, False]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>tensor(66.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=torch.arange(<span class="number">6</span>).reshape(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">b=torch.arange(<span class="number">2</span>).reshape(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">a,b</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[[0],
          [1]],
 
         [[2],
          [3]],
 
         [[4],
          [5]]]),
 tensor([[0, 1]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c=a+b</span><br><span class="line">c</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[0, 1],
         [1, 2]],

        [[2, 3],
         [3, 4]],

        [[4, 5],
         [5, 6]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0, 1],
        [1, 2]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[-<span class="number">1</span>],X[<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([ 8.,  9., 10., 11.]),
 tensor([[ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">1</span>,<span class="number">2</span>]=<span class="number">9</span></span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  9.,  7.],
        [ 8.,  9., 10., 11.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">0</span>:<span class="number">2</span>,:]=<span class="number">12</span></span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[12., 12., 12., 12.],
        [12., 12., 12., 12.],
        [ 8.,  9., 10., 11.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before=<span class="built_in">id</span>(Y)</span><br><span class="line">Y=Y+X</span><br><span class="line"><span class="built_in">id</span>(Y)==before</span><br></pre></td></tr></table></figure>




<pre><code>False
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Z=torch.zeros_like(Y)</span><br><span class="line">Z</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;id(Z):&#x27;</span>,<span class="built_in">id</span>(Z))</span><br></pre></td></tr></table></figure>

<pre><code>id(Z): 3055861362752
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Z[:]=X+Y</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;id(Z):&#x27;</span>,<span class="built_in">id</span>(Z))</span><br></pre></td></tr></table></figure>

<pre><code>id(Z): 3055861362752
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before=<span class="built_in">id</span>(X)</span><br><span class="line">X+=Y</span><br><span class="line"><span class="built_in">id</span>(X)==before</span><br></pre></td></tr></table></figure>




<pre><code>True
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A=X.numpy()</span><br><span class="line">B=torch.tensor(A)</span><br><span class="line"><span class="built_in">type</span>(A),<span class="built_in">type</span>(B)</span><br></pre></td></tr></table></figure>




<pre><code>(numpy.ndarray, torch.Tensor)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A,B</span><br></pre></td></tr></table></figure>




<pre><code>(array([[26., 25., 28., 27.],
        [25., 26., 27., 28.],
        [20., 21., 22., 23.]], dtype=float32),
 tensor([[26., 25., 28., 27.],
         [25., 26., 27., 28.],
         [20., 21., 22., 23.]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a=torch.tensor([<span class="number">3.5</span>])</span><br><span class="line">a,a.item(),<span class="built_in">float</span>(a),<span class="built_in">int</span>(a)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([3.5000]), 3.5, 3.5, 3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">12</span>)</span><br><span class="line">X=x.reshape(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[ 0,  1],
         [ 2,  3]],

        [[ 4,  5],
         [ 6,  7]],

        [[ 8,  9],
         [10, 11]]])
</code></pre>
<h2 id="2-2-数据预处理"><a href="#2-2-数据预处理" class="headerlink" title="2.2 数据预处理"></a>2.2 数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.makedirs(os.path.join(<span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span>), exist_ok=<span class="literal">True</span>)</span><br><span class="line">data_file = os.path.join(<span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;NumRooms,Alley,Price\n&#x27;</span>)  <span class="comment"># 列名</span></span><br><span class="line">    f.write(<span class="string">&#x27;NA,Pave,127500\n&#x27;</span>)  <span class="comment"># 每行表示一个数据样本</span></span><br><span class="line">    f.write(<span class="string">&#x27;2,NA,106000\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;4,NA,178100\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;NA,NA,140000\n&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(data_file)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>

<pre><code>   NumRooms Alley   Price
0       NaN  Pave  127500
1       2.0   NaN  106000
2       4.0   NaN  178100
3       NaN   NaN  140000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs, outputs = data.iloc[:, <span class="number">0</span>:<span class="number">2</span>], data.iloc[:, <span class="number">2</span>]</span><br><span class="line">inputs = inputs.fillna(inputs.mean())</span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br></pre></td></tr></table></figure>

<pre><code>   NumRooms Alley
0       3.0  Pave
1       2.0   NaN
2       4.0   NaN
3       3.0   NaN
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs = pd.get_dummies(inputs)</span><br><span class="line"><span class="comment">#inputs = pd.get_dummies(inputs, dummy_na=True)</span></span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br></pre></td></tr></table></figure>

<pre><code>   NumRooms  Alley_Pave  Alley_nan
0       3.0           1          0
1       2.0           0          1
2       4.0           0          1
3       3.0           0          1
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">X = torch.tensor(inputs.to_numpy(dtype=<span class="built_in">float</span>))</span><br><span class="line">y = torch.tensor(outputs.to_numpy(dtype=<span class="built_in">float</span>))</span><br><span class="line"><span class="comment">#X，y = torch.tensor(inputs.values),torch.tensor(outputs.values)</span></span><br><span class="line">X, y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[3., 1., 0.],
         [2., 0., 1.],
         [4., 0., 1.],
         [3., 0., 1.]], dtype=torch.float64),
 tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))
</code></pre>
<h2 id="2-3-线性代数"><a href="#2-3-线性代数" class="headerlink" title="2.3 线性代数"></a>2.3 线性代数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">3.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">x + y, x * y, x / y, x**y</span><br></pre></td></tr></table></figure>




<pre><code>(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.arange(<span class="number">4</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0, 1, 2, 3])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>tensor(3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(x)</span><br></pre></td></tr></table></figure>




<pre><code>4
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([4])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A=torch.arange(<span class="number">20</span>).reshape(<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line">A</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15],
        [16, 17, 18, 19]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.T</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0,  4,  8, 12, 16],
        [ 1,  5,  9, 13, 17],
        [ 2,  6, 10, 14, 18],
        [ 3,  7, 11, 15, 19]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">B=torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">0</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]])</span><br><span class="line">B</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[1, 2, 3],
        [2, 0, 4],
        [3, 4, 5]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B==B.T</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[True, True, True],
        [True, True, True],
        [True, True, True]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X=torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11]],

        [[12, 13, 14, 15],
         [16, 17, 18, 19],
         [20, 21, 22, 23]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A=torch.arange(<span class="number">20</span>,dtype=torch.float32).reshape(<span class="number">5</span>,<span class="number">4</span>)</span><br><span class="line">B=A.clone()</span><br><span class="line">A,A+B</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [12., 13., 14., 15.],
         [16., 17., 18., 19.]]),
 tensor([[ 0.,  2.,  4.,  6.],
         [ 8., 10., 12., 14.],
         [16., 18., 20., 22.],
         [24., 26., 28., 30.],
         [32., 34., 36., 38.]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A*B</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[  0.,   1.,   4.,   9.],
        [ 16.,  25.,  36.,  49.],
        [ 64.,  81., 100., 121.],
        [144., 169., 196., 225.],
        [256., 289., 324., 361.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="number">2</span></span><br><span class="line">X=torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">a+X,(a*X).shape</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[[ 2,  3,  4,  5],
          [ 6,  7,  8,  9],
          [10, 11, 12, 13]],
 
         [[14, 15, 16, 17],
          [18, 19, 20, 21],
          [22, 23, 24, 25]]]),
 torch.Size([2, 3, 4]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.arange(<span class="number">4</span>,dtype=torch.float32)</span><br><span class="line">x,x.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([0., 1., 2., 3.]), tensor(6.))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape,A.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>(torch.Size([5, 4]), tensor(190.))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A_sum_axis0=A.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">A_sum_axis0,A_sum_axis0.shape</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([40., 45., 50., 55.]), torch.Size([4]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A_sum_axis1=A.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">A_sum_axis1,A_sum_axis1.shape</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.<span class="built_in">sum</span>(axis=[<span class="number">0</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>tensor(190.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.mean(),A.<span class="built_in">sum</span>(),A.numel(),A.<span class="built_in">sum</span>()/A.numel()</span><br></pre></td></tr></table></figure>




<pre><code>(tensor(9.5000), tensor(190.), 20, tensor(9.5000))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.mean(axis=<span class="number">0</span>),A.<span class="built_in">sum</span>(axis=<span class="number">0</span>)/A.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum_A=A.<span class="built_in">sum</span>(axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line">sum_A</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 6.],
        [22.],
        [38.],
        [54.],
        [70.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A / sum_A</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[0.0000, 0.1667, 0.3333, 0.5000],
        [0.1818, 0.2273, 0.2727, 0.3182],
        [0.2105, 0.2368, 0.2632, 0.2895],
        [0.2222, 0.2407, 0.2593, 0.2778],
        [0.2286, 0.2429, 0.2571, 0.2714]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.cumsum(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  6.,  8., 10.],
        [12., 15., 18., 21.],
        [24., 28., 32., 36.],
        [40., 45., 50., 55.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y=torch.ones(<span class="number">4</span>,dtype=torch.float32)</span><br><span class="line">x,y,torch.dot(x,y)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(x*y)</span><br></pre></td></tr></table></figure>




<pre><code>tensor(6.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.shape,x.shape,torch.mv(A,x)</span><br></pre></td></tr></table></figure>




<pre><code>(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">B=torch.ones(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">torch.mm(A,B)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 6.,  6.,  6.],
        [22., 22., 22.],
        [38., 38., 38.],
        [54., 54., 54.],
        [70., 70., 70.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">u=torch.tensor([<span class="number">3.0</span>,-<span class="number">4.0</span>])</span><br><span class="line">torch.norm(u)</span><br></pre></td></tr></table></figure>




<pre><code>tensor(5.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">abs</span>(u).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>tensor(7.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.norm(torch.ones((<span class="number">4</span>,<span class="number">9</span>)))</span><br></pre></td></tr></table></figure>




<pre><code>tensor(6.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=torch.arange(<span class="number">24</span>,dtype=torch.float32).reshape((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">x,<span class="built_in">len</span>(x)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[[ 0.,  1.,  2.,  3.],
          [ 4.,  5.,  6.,  7.],
          [ 8.,  9., 10., 11.]],
 
         [[12., 13., 14., 15.],
          [16., 17., 18., 19.],
          [20., 21., 22., 23.]]]),
 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.<span class="built_in">sum</span>(axis=<span class="number">0</span>),x.<span class="built_in">sum</span>(axis=<span class="number">1</span>),x.<span class="built_in">sum</span>(axis=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[12., 14., 16., 18.],
         [20., 22., 24., 26.],
         [28., 30., 32., 34.]]),
 tensor([[12., 15., 18., 21.],
         [48., 51., 54., 57.]]),
 tensor([[ 6., 22., 38.],
         [54., 70., 86.]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y=torch.arange(<span class="number">120</span>,dtype=torch.float32).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[[[  0.,   1.,   2.,   3.,   4.],
          [  5.,   6.,   7.,   8.,   9.],
          [ 10.,  11.,  12.,  13.,  14.],
          [ 15.,  16.,  17.,  18.,  19.]],

         [[ 20.,  21.,  22.,  23.,  24.],
          [ 25.,  26.,  27.,  28.,  29.],
          [ 30.,  31.,  32.,  33.,  34.],
          [ 35.,  36.,  37.,  38.,  39.]],

         [[ 40.,  41.,  42.,  43.,  44.],
          [ 45.,  46.,  47.,  48.,  49.],
          [ 50.,  51.,  52.,  53.,  54.],
          [ 55.,  56.,  57.,  58.,  59.]]],
</code></pre>
<p>​<br>            [[[ 60.,  61.,  62.,  63.,  64.],<br>              [ 65.,  66.,  67.,  68.,  69.],<br>              [ 70.,  71.,  72.,  73.,  74.],<br>              [ 75.,  76.,  77.,  78.,  79.]],</p>
<pre><code>         [[ 80.,  81.,  82.,  83.,  84.],
          [ 85.,  86.,  87.,  88.,  89.],
          [ 90.,  91.,  92.,  93.,  94.],
          [ 95.,  96.,  97.,  98.,  99.]],

         [[100., 101., 102., 103., 104.],
          [105., 106., 107., 108., 109.],
          [110., 111., 112., 113., 114.],
          [115., 116., 117., 118., 119.]]]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">z=torch.linalg.norm(y)<span class="comment">#torch.linalg.norm函数可用于求解多轴张量的类L2范数，要求张量各元素数据类型为浮点数或者复数</span></span><br><span class="line"><span class="comment">#z=torch.linalg.norm(input,p,dim)</span></span><br><span class="line"><span class="comment">#input：输入张量。它的数据类型必须是浮点型或复数型。对于复数的输入，范数使用每个元素的绝对值。注意，输入张量中元素的数据类型一定得是浮点型或者是复数哦，不然就会报错！这个就是主要变化，其次是不能使用 input.norm</span></span><br><span class="line"><span class="comment">#p：范数的阶数。默认是2阶—“fro”，也就是弗罗贝尼乌斯范数（Frobenius norm）。如果输入p=某个正整数，则求解对应的p阶范数。其公式为  sum(abs(x)**p)**(1./p)。</span></span><br><span class="line"><span class="comment">#dim：对输入的张量计算其指定维度（如dim=1，则表示计算第二个维度）上所有元素的范数。如果不对dim进行赋值，则会计算输入张量所有维度上的范数。当然如果指定维数不在输入张量的尺寸之内，将出现错误。</span></span><br><span class="line">z</span><br></pre></td></tr></table></figure>




<pre><code>tensor(754.2015)
</code></pre>
<h2 id="2-4-微积分"><a href="#2-4-微积分" class="headerlink" title="2.4 微积分"></a>2.4 微积分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib_inline <span class="keyword">import</span> backend_inline</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">3</span>*x**<span class="number">2</span>-<span class="number">4</span>*x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">numerical_lim</span>(<span class="params">f,x,h</span>):</span><br><span class="line">    <span class="keyword">return</span> (f(x+h)-f(x))/h</span><br><span class="line"></span><br><span class="line">h=<span class="number">0.1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;h=<span class="subst">&#123;h:<span class="number">.5</span>f&#125;</span>,numerical limit=<span class="subst">&#123;numerical_lim(f,<span class="number">1</span>,h):<span class="number">.5</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    h*=<span class="number">0.1</span></span><br></pre></td></tr></table></figure>

<pre><code>h=0.10000,numerical limit=2.30000
h=0.01000,numerical limit=2.03000
h=0.00100,numerical limit=2.00300
h=0.00010,numerical limit=2.00030
h=0.00001,numerical limit=2.00003
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#三个用于图形配置的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">use_svg_display</span>():   <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">##@save标记可将对应函数/类/语句保存在d2l包中，以后无需定义就可以直接调用；e.g:d2l.use_svg_display()</span></span><br><span class="line">    <span class="comment">#使用svg格式在Jupyter中显示绘图</span></span><br><span class="line">    backend_inline.set_matplotlib_formats(<span class="string">&#x27;svg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_figsize</span>(<span class="params">figsize=(<span class="params"><span class="number">3.5</span>,<span class="number">2.5</span></span>)</span>):   <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#设置matplotlib的图表大小</span></span><br><span class="line">    use_svg_display()</span><br><span class="line">    d2l.plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>]=figsize</span><br><span class="line">    </span><br><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_axes</span>(<span class="params">axes,xlabel,ylabel,xlim,ylim,xscale,yscale,legend</span>):</span><br><span class="line">    <span class="comment">#设置matplotlib的轴</span></span><br><span class="line">    axes.set_xlabel(xlabel)</span><br><span class="line">    axes.set_ylabel(ylabel)</span><br><span class="line">    axes.set_xscale(xscale)</span><br><span class="line">    axes.set_yscale(yscale)</span><br><span class="line">    axes.set_xlim(xlim)</span><br><span class="line">    axes.set_ylim(ylim)</span><br><span class="line">    <span class="keyword">if</span> legend:</span><br><span class="line">        axes.legend(legend)</span><br><span class="line">    axes.grid()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#plot函数：可绘制多条曲线</span></span><br><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">X,Y=<span class="literal">None</span>,xlabel=<span class="literal">None</span>,ylabel=<span class="literal">None</span>,legend=<span class="literal">None</span>,xlim=<span class="literal">None</span>,ylim=<span class="literal">None</span>,xscale=<span class="string">&#x27;linear&#x27;</span>,yscale=<span class="string">&#x27;linear&#x27;</span>,fmts=(<span class="params"><span class="string">&#x27;-&#x27;</span>,<span class="string">&#x27;m--&#x27;</span>,<span class="string">&#x27;g-.&#x27;</span>,<span class="string">&#x27;r:&#x27;</span></span>),figsize=(<span class="params"><span class="number">3.5</span>,<span class="number">2.5</span></span>),axes=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment">#绘制数据点</span></span><br><span class="line">    <span class="keyword">if</span> legend <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        legend=[]</span><br><span class="line"></span><br><span class="line">    set_figsize(figsize)</span><br><span class="line">    axes=axes <span class="keyword">if</span> axes <span class="keyword">else</span> d2l.plt.gca()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#如果X有一个轴，输出True</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">has_one_axis</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span>(<span class="built_in">hasattr</span>(X,<span class="string">&quot;ndim&quot;</span>) <span class="keyword">and</span> X.ndim==<span class="number">1</span> <span class="keyword">or</span> <span class="built_in">isinstance</span>(X,<span class="built_in">list</span>) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(X[<span class="number">0</span>],<span class="string">&quot;__len__&quot;</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> has_one_axis(X):</span><br><span class="line">        X=[X]</span><br><span class="line">    <span class="keyword">if</span> Y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        X,Y=[[]]*<span class="built_in">len</span>(X),X</span><br><span class="line">    <span class="keyword">elif</span> has_one_axis(Y):</span><br><span class="line">        X=X*<span class="built_in">len</span>(Y)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(X)!=<span class="built_in">len</span>(Y):</span><br><span class="line">        X=X*<span class="built_in">len</span>(Y)</span><br><span class="line">    axes.cla()</span><br><span class="line">    <span class="keyword">for</span> x,y,fmt <span class="keyword">in</span> <span class="built_in">zip</span>(X,Y,fmts):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(x):</span><br><span class="line">            axes.plot(x,y,fmt)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            axes.plot(y,fmt)</span><br><span class="line">    set_axes(axes,xlabel,ylabel,xlim,ylim,xscale,yscale,legend)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=np.arange(<span class="number">0</span>,<span class="number">3</span>,<span class="number">0.1</span>)</span><br><span class="line">plot(x,[f(x),<span class="number">2</span>*x-<span class="number">3</span>],<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;f(x)&#x27;</span>,legend=[<span class="string">&#x27;f(x)&#x27;</span>,<span class="string">&#x27;Tangent line(x=1)&#x27;</span>])</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86_files/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86_78_0.svg" alt="svg"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">g</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x**<span class="number">3</span>-(<span class="number">1</span>/x)</span><br><span class="line">plot(x,[g(x),<span class="number">4</span>*x-<span class="number">4</span>],<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;g(x)&#x27;</span>,legend=[<span class="string">&#x27;g(x)&#x27;</span>,<span class="string">&#x27;Tangent line(x=1)&#x27;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>F:\user\Temp\ipykernel_25528\1423519574.py:2: RuntimeWarning: divide by zero encountered in true_divide
  return x**3-(1/x)
</code></pre>
<p><img src="/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86_files/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86_79_1.svg" alt="svg"></p>
<h2 id="2-5-自动微分"><a href="#2-5-自动微分" class="headerlink" title="2.5 自动微分"></a>2.5 自动微分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x=torch.arange(<span class="number">4.0</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0., 1., 2., 3.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y=<span class="number">2</span>*torch.dot(x,x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>




<pre><code>tensor(28.)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.requires_grad_(<span class="literal">True</span>) <span class="comment">#等价于x=torch.arange(4.0,requires_grad=True)</span></span><br><span class="line">x.grad <span class="comment">#默认值为None</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y=<span class="number">2</span>*torch.dot(x,x)</span><br><span class="line">y</span><br></pre></td></tr></table></figure>




<pre><code>tensor(28., grad_fn=&lt;MulBackward0&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward()<span class="comment">#通过调用反向传播函数自动计算y关于x每个分量的梯度</span></span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>




<pre><code>tensor([ 0.,  4.,  8., 12.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.grad==<span class="number">4</span>*x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([True, True, True, True])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()<span class="comment">#在默认情况下，PyTorch会累积梯度，我们需要清除之前的值</span></span><br><span class="line"></span><br><span class="line">y=x.<span class="built_in">sum</span>()</span><br><span class="line">y.backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1., 1., 1., 1.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对非标量变量：不计算微分矩阵，而是单独计算批量中每个样本的偏导数之和</span></span><br><span class="line"><span class="comment">#对[非标量]调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y=x*x</span><br><span class="line">y.<span class="built_in">sum</span>().backward()<span class="comment">#等价于y.backward(torch.ones(len(x)))——传递1的梯度合适：只求偏导数的和</span></span><br><span class="line">y,x.grad</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([0., 1., 4., 9.], grad_fn=&lt;MulBackward0&gt;), tensor([0., 2., 4., 6.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br><span class="line">y=x*x</span><br><span class="line">u=y.detach()<span class="comment">#分离变量（复制副本，保留计算结果，后续处理的u不带有y除数值外的其他性质）</span></span><br><span class="line">z=u*x</span><br><span class="line"></span><br><span class="line">z.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad==u</span><br></pre></td></tr></table></figure>




<pre><code>tensor([True, True, True, True])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br><span class="line">y.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad==<span class="number">2</span>*x</span><br></pre></td></tr></table></figure>




<pre><code>tensor([True, True, True, True])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a</span>):</span><br><span class="line">    b=a*<span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> b.norm()&lt;<span class="number">1000</span>:</span><br><span class="line">        b=b*<span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> b.<span class="built_in">sum</span>()&gt;<span class="number">0</span>:</span><br><span class="line">        c=b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        c=<span class="number">100</span>*b</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">a=torch.randn(size=(),requires_grad=<span class="literal">True</span>)</span><br><span class="line">d=f(a)</span><br><span class="line">d.backward()<span class="comment">#注意：运行backward函数会自动清除计算图；但可通过在第一次backward中加一句retain_grad=True，即d.backward(retain_graph=True)，意思为一直保留计算图</span></span><br><span class="line"></span><br><span class="line">a,d,a.grad==d/a,a.grad</span><br></pre></td></tr></table></figure>




<pre><code>(tensor(0.1050, requires_grad=True),
 tensor(1719.5204, grad_fn=&lt;MulBackward0&gt;),
 tensor(True),
 tensor(16384.))
</code></pre>
<h2 id="2-6-概率"><a href="#2-6-概率" class="headerlink" title="2.6 概率"></a>2.6 概率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.distributions <span class="keyword">import</span> multinomial<span class="comment">#multinomial 多项分布</span></span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">fair_probs=torch.ones([<span class="number">6</span>])/<span class="number">6</span></span><br><span class="line">fair_probs,multinomial.Multinomial(<span class="number">1</span>,fair_probs).sample()</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]),
 tensor([0., 0., 0., 0., 1., 0.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multinomial.Multinomial(<span class="number">10</span>,fair_probs).sample()</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2., 0., 1., 3., 1., 3.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">counts=multinomial.Multinomial(<span class="number">1000</span>,fair_probs).sample()<span class="comment">#将结果储存为float32以进行除法</span></span><br><span class="line">counts/<span class="number">1000</span><span class="comment">#相对频率作为估计值</span></span><br></pre></td></tr></table></figure>




<pre><code>tensor([0.1640, 0.1610, 0.1720, 0.1730, 0.1610, 0.1690])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">counts=multinomial.Multinomial(<span class="number">10</span>,fair_probs).sample((<span class="number">500</span>,))</span><br><span class="line">cum_counts=counts.cumsum(dim=<span class="number">0</span>)<span class="comment">#cumsum:累加函数</span></span><br><span class="line">estimates=cum_counts/cum_counts.<span class="built_in">sum</span>(dim=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">d2l.set_figsize((<span class="number">6</span>,<span class="number">4.5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    d2l.plt.plot(estimates[:,i].numpy(),label=(<span class="string">&quot;P(die=&quot;</span>+<span class="built_in">str</span>(i+<span class="number">1</span>)+<span class="string">&quot;)&quot;</span>))</span><br><span class="line">d2l.plt.axhline(y=<span class="number">0.167</span>,color=<span class="string">&#x27;black&#x27;</span>,linestyle=<span class="string">&#x27;dashed&#x27;</span>)</span><br><span class="line">d2l.plt.gca().set_xlabel(<span class="string">&#x27;Groups of experiments&#x27;</span>)</span><br><span class="line">d2l.plt.gca().set_ylabel(<span class="string">&#x27;Estimated probability&#x27;</span>)</span><br><span class="line">d2l.plt.legend();</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86_files/2.%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86_96_0.svg" alt="svg"><br>​    </p>
<h2 id="2-7-查阅文档"><a href="#2-7-查阅文档" class="headerlink" title="2.7 查阅文档"></a>2.7 查阅文档</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">dir</span>(torch.distributions))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;AbsTransform&#39;, &#39;AffineTransform&#39;, &#39;Bernoulli&#39;, &#39;Beta&#39;, &#39;Binomial&#39;, &#39;CatTransform&#39;, &#39;Categorical&#39;, &#39;Cauchy&#39;, &#39;Chi2&#39;, &#39;ComposeTransform&#39;, &#39;ContinuousBernoulli&#39;, &#39;CorrCholeskyTransform&#39;, &#39;CumulativeDistributionTransform&#39;, &#39;Dirichlet&#39;, &#39;Distribution&#39;, &#39;ExpTransform&#39;, &#39;Exponential&#39;, &#39;ExponentialFamily&#39;, &#39;FisherSnedecor&#39;, &#39;Gamma&#39;, &#39;Geometric&#39;, &#39;Gumbel&#39;, &#39;HalfCauchy&#39;, &#39;HalfNormal&#39;, &#39;Independent&#39;, &#39;IndependentTransform&#39;, &#39;Kumaraswamy&#39;, &#39;LKJCholesky&#39;, &#39;Laplace&#39;, &#39;LogNormal&#39;, &#39;LogisticNormal&#39;, &#39;LowRankMultivariateNormal&#39;, &#39;LowerCholeskyTransform&#39;, &#39;MixtureSameFamily&#39;, &#39;Multinomial&#39;, &#39;MultivariateNormal&#39;, &#39;NegativeBinomial&#39;, &#39;Normal&#39;, &#39;OneHotCategorical&#39;, &#39;OneHotCategoricalStraightThrough&#39;, &#39;Pareto&#39;, &#39;Poisson&#39;, &#39;PowerTransform&#39;, &#39;RelaxedBernoulli&#39;, &#39;RelaxedOneHotCategorical&#39;, &#39;ReshapeTransform&#39;, &#39;SigmoidTransform&#39;, &#39;SoftmaxTransform&#39;, &#39;SoftplusTransform&#39;, &#39;StackTransform&#39;, &#39;StickBreakingTransform&#39;, &#39;StudentT&#39;, &#39;TanhTransform&#39;, &#39;Transform&#39;, &#39;TransformedDistribution&#39;, &#39;Uniform&#39;, &#39;VonMises&#39;, &#39;Weibull&#39;, &#39;Wishart&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;bernoulli&#39;, &#39;beta&#39;, &#39;biject_to&#39;, &#39;binomial&#39;, &#39;categorical&#39;, &#39;cauchy&#39;, &#39;chi2&#39;, &#39;constraint_registry&#39;, &#39;constraints&#39;, &#39;continuous_bernoulli&#39;, &#39;dirichlet&#39;, &#39;distribution&#39;, &#39;exp_family&#39;, &#39;exponential&#39;, &#39;fishersnedecor&#39;, &#39;gamma&#39;, &#39;geometric&#39;, &#39;gumbel&#39;, &#39;half_cauchy&#39;, &#39;half_normal&#39;, &#39;identity_transform&#39;, &#39;independent&#39;, &#39;kl&#39;, &#39;kl_divergence&#39;, &#39;kumaraswamy&#39;, &#39;laplace&#39;, &#39;lkj_cholesky&#39;, &#39;log_normal&#39;, &#39;logistic_normal&#39;, &#39;lowrank_multivariate_normal&#39;, &#39;mixture_same_family&#39;, &#39;multinomial&#39;, &#39;multivariate_normal&#39;, &#39;negative_binomial&#39;, &#39;normal&#39;, &#39;one_hot_categorical&#39;, &#39;pareto&#39;, &#39;poisson&#39;, &#39;register_kl&#39;, &#39;relaxed_bernoulli&#39;, &#39;relaxed_categorical&#39;, &#39;studentT&#39;, &#39;transform_to&#39;, &#39;transformed_distribution&#39;, &#39;transforms&#39;, &#39;uniform&#39;, &#39;utils&#39;, &#39;von_mises&#39;, &#39;weibull&#39;, &#39;wishart&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">help</span>(torch.ones)</span><br></pre></td></tr></table></figure>

<pre><code>Help on built-in function ones in module torch:

ones(...)
    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -&gt; Tensor
    
    Returns a tensor filled with the scalar value `1`, with the shape defined
    by the variable argument :attr:`size`.
    
    Args:
        size (int...): a sequence of integers defining the shape of the output tensor.
            Can be a variable number of arguments or a collection like a list or tuple.
    
    Keyword arguments:
        out (Tensor, optional): the output tensor.
        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).
        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.
            Default: ``torch.strided``.
        device (:class:`torch.device`, optional): the desired device of returned tensor.
            Default: if ``None``, uses the current device for the default tensor type
            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU
            for CPU tensor types and the current CUDA device for CUDA tensor types.
        requires_grad (bool, optional): If autograd should record operations on the
            returned tensor. Default: ``False``.
    
    Example::
    
        &gt;&gt;&gt; torch.ones(2, 3)
        tensor([[ 1.,  1.,  1.],
                [ 1.,  1.,  1.]])
    
        &gt;&gt;&gt; torch.ones(5)
        tensor([ 1.,  1.,  1.,  1.,  1.])
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([1., 1., 1., 1.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">?</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>?</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">help</span>(<span class="built_in">list</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Help on class list in module builtins:

class list(object)
 |  list(iterable=(), /)
 |  
 |  Built-in mutable sequence.
 |  
 |  If no argument is given, the constructor creates a new empty list.
 |  The argument must be an iterable if specified.
 |  
 |  Methods defined here:
 |  
 |  __add__(self, value, /)
 |      Return self+value.
 |  
 |  __contains__(self, key, /)
 |      Return key in self.
 |  
 |  __delitem__(self, key, /)
 |      Delete self[key].
 |  
 |  __eq__(self, value, /)
 |      Return self==value.
 |  
 |  __ge__(self, value, /)
 |      Return self&gt;=value.
 |  
 |  __getattribute__(self, name, /)
 |      Return getattr(self, name).
 |  
 |  __getitem__(...)
 |      x.__getitem__(y) &lt;==&gt; x[y]
 |  
 |  __gt__(self, value, /)
 |      Return self&gt;value.
 |  
 |  __iadd__(self, value, /)
 |      Implement self+=value.
 |  
 |  __imul__(self, value, /)
 |      Implement self*=value.
 |  
 |  __init__(self, /, *args, **kwargs)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  __iter__(self, /)
 |      Implement iter(self).
 |  
 |  __le__(self, value, /)
 |      Return self&lt;=value.
 |  
 |  __len__(self, /)
 |      Return len(self).
 |  
 |  __lt__(self, value, /)
 |      Return self&lt;value.
 |  
 |  __mul__(self, value, /)
 |      Return self*value.
 |  
 |  __ne__(self, value, /)
 |      Return self!=value.
 |  
 |  __repr__(self, /)
 |      Return repr(self).
 |  
 |  __reversed__(self, /)
 |      Return a reverse iterator over the list.
 |  
 |  __rmul__(self, value, /)
 |      Return value*self.
 |  
 |  __setitem__(self, key, value, /)
 |      Set self[key] to value.
 |  
 |  __sizeof__(self, /)
 |      Return the size of the list in memory, in bytes.
 |  
 |  append(self, object, /)
 |      Append object to the end of the list.
 |  
 |  clear(self, /)
 |      Remove all items from list.
 |  
 |  copy(self, /)
 |      Return a shallow copy of the list.
 |  
 |  count(self, value, /)
 |      Return number of occurrences of value.
 |  
 |  extend(self, iterable, /)
 |      Extend list by appending elements from the iterable.
 |  
 |  index(self, value, start=0, stop=9223372036854775807, /)
 |      Return first index of value.
 |      
 |      Raises ValueError if the value is not present.
 |  
 |  insert(self, index, object, /)
 |      Insert object before index.
 |  
 |  pop(self, index=-1, /)
 |      Remove and return item at index (default last).
 |      
 |      Raises IndexError if list is empty or index is out of range.
 |  
 |  remove(self, value, /)
 |      Remove first occurrence of value.
 |      
 |      Raises ValueError if the value is not present.
 |  
 |  reverse(self, /)
 |      Reverse *IN PLACE*.
 |  
 |  sort(self, /, *, key=None, reverse=False)
 |      Sort the list in ascending order and return None.
 |      
 |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the
 |      order of two equal elements is maintained).
 |      
 |      If a key function is given, apply it once to each list item and sort them,
 |      ascending or descending, according to their function values.
 |      
 |      The reverse flag can be set to sort in descending order.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  __class_getitem__(...) from builtins.type
 |      See PEP 585
 |  
 |  ----------------------------------------------------------------------
 |  Static methods defined here:
 |  
 |  __new__(*args, **kwargs) from builtins.type
 |      Create and return a new object.  See help(type) for accurate signature.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __hash__ = None
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span>??</span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/09/25/20220925/"><img class="fill" src="/images/story/7.jpg" alt="20220925"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-09-25T08:16:00.000Z" title="2022/9/25 16:16:00">2022-09-25</time>发表</span><span class="level-item"><time dateTime="2023-08-04T03:25:19.685Z" title="2023/8/4 11:25:19">2023-08-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/About-XJH/">About XJH</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a><span> / </span><a class="link-muted" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></span><span class="level-item">1 分钟读完 (大约183个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/09/25/20220925/">20220925</a></p><div class="content"><p>年轻的躯体里充斥着自由的空气，随着血液氤氲扩散，遍布每一个细胞。它们贪婪地吮吸着，破晓前最后的黑暗。他们知道，走过这漫漫长夜，明天曙光就会照耀整个大地。<br>#重启线下课#<br>谁能想到，半个下午找完了所有要上课的教结果室发现才走了学校的一半还不到<br>谁又能想到，从教学楼的二楼走楼梯上楼，楼上居然还是二楼<img src="http://qzonestyle.gtimg.cn/qzone/em/e114.png"><br>但宿舍楼下就有钢琴我是真的会爱住<br>那我们就明天见咯<img src="http://qzonestyle.gtimg.cn/qzone/em/e271.png"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">上一页</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/page/3/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/head.jpg" alt="明诚"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">明诚</p><p class="is-size-6 is-block">走过的路，每一步都算数。</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>江苏 苏州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">18</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">27</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Asgard-Tim" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/u/6315188431"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/171895120"><i class="fab fa-bilibili"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://jaguarliu.me/ai-projects" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">AI-Tools</span></span><span class="level-right"><span class="level-item tag">jaguarliu.me</span></span></a></li><li><a class="level is-mobile" href="https://zlibrary-east.se/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Zlibrary</span></span><span class="level-right"><span class="level-item tag">zlibrary-east.se</span></span></a></li><li><a class="level is-mobile" href="https://www.cnki.net/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CNKI</span></span><span class="level-right"><span class="level-item tag">www.cnki.net</span></span></a></li><li><a class="level is-mobile" href="https://chat.openai.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">ChatGPT</span></span><span class="level-right"><span class="level-item tag">chat.openai.com</span></span></a></li><li><a class="level is-mobile" href="https://www.iodraw.com/tool/sketch" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">照片转素描</span></span><span class="level-right"><span class="level-item tag">www.iodraw.com</span></span></a></li><li><a class="level is-mobile" href="https://www.integral-calculator.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">积分计算器</span></span><span class="level-right"><span class="level-item tag">www.integral-calculator.com</span></span></a></li><li><a class="level is-mobile" href="https://cli.im/text" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">二维码生成器</span></span><span class="level-right"><span class="level-item tag">cli.im</span></span></a></li><li><a class="level is-mobile" href="https://tool.sacdr.net/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">音乐解锁</span></span><span class="level-right"><span class="level-item tag">tool.sacdr.net</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/About-XJH/"><span class="level-start"><span class="level-item">About XJH</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"><span class="level-start"><span class="level-item">碎碎念</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/"><span class="level-start"><span class="level-item">CQU</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">个人项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">动手学深度学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">课程项目</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95I/"><span class="level-start"><span class="level-item">定量工程设计方法I</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">工程原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="level-start"><span class="level-item">线性代数</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">软件设计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2023/08/02/index/"><img src="/images/book.jpeg" alt="Welcome to XJH&#039;s Secret Base!"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-08-02T11:52:30.000Z">2023-08-02</time></p><p class="title"><a href="/2023/08/02/index/">Welcome to XJH&#039;s Secret Base!</a></p><p class="categories"><a href="/categories/About-XJH/">About XJH</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/07/05/20230705/"><img src="/images/story/1.jpg" alt="20230705"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-07-05T01:43:03.000Z">2023-07-05</time></p><p class="title"><a href="/2023/07/05/20230705/">20230705</a></p><p class="categories"><a href="/categories/About-XJH/">About XJH</a> / <a href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a> / <a href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/07/03/20230703/"><img src="/images/story/2.jpg" alt="20230703"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-07-03T08:37:03.000Z">2023-07-03</time></p><p class="title"><a href="/2023/07/03/20230703/">20230703</a></p><p class="categories"><a href="/categories/About-XJH/">About XJH</a> / <a href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/">碎碎念</a> / <a href="/categories/About-XJH/%E7%A2%8E%E7%A2%8E%E5%BF%B5/CQU/">CQU</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/07/02/ROS%20Task/"><img src="/images/14.png" alt="基于ROS（机器人操作系统）的数据展示系统"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-07-02T13:42:58.000Z">2023-07-02</time></p><p class="title"><a href="/2023/07/02/ROS%20Task/">基于ROS（机器人操作系统）的数据展示系统</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1/">软件设计</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2023/06/27/chatbot/"><img src="/images/head.jpg" alt="QQ聊天机器人(接入ChatGPT)"></a></figure><div class="media-content"><p class="date"><time dateTime="2023-06-27T04:22:03.000Z">2023-06-27</time></p><p class="title"><a href="/2023/06/27/chatbot/">QQ聊天机器人(接入ChatGPT)</a></p><p class="categories"><a href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/">个人项目</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">八月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">七月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">六月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">三月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">十月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">九月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C51/"><span class="tag">C51</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CQU/"><span class="tag">CQU</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChatGPT/"><span class="tag">ChatGPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FPGA/"><span class="tag">FPGA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MATLAB/"><span class="tag">MATLAB</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QQbot/"><span class="tag">QQbot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RANSAC/"><span class="tag">RANSAC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/STM32/"><span class="tag">STM32</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XJH/"><span class="tag">XJH</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%9B%E8%AE%AD/"><span class="tag">军训</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">动手学深度学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"><span class="tag">单片机</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"><span class="tag">图像识别</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="tag">学习笔记</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90/"><span class="tag">定量分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E4%BD%9C%E6%96%87/"><span class="tag">小作文</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E8%BD%A6/"><span class="tag">小车</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"><span class="tag">年终总结</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%97%A5/"><span class="tag">生日</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"><span class="tag">碎碎念</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="tag">线性代数</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%88%B9/"><span class="tag">船</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"><span class="tag">路径规划</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/title.png" alt="XJH&#039;s Secret Base" height="28"></a><p class="is-size-7"><span>&copy; 2023 明诚</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© Copyright by XJH 此心安处是吾乡。</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>
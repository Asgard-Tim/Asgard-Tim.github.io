<!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>标签: Python - Homepage of Jinghua Xu</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Homepage of Jinghua Xu"><meta name="msapplication-TileImage" content="/img/photo.jpg"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Homepage of Jinghua Xu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="/img/photo.jpg"><meta name="description" content="重庆大学2022级明月科创实验班人工智能专业本科在读"><meta property="og:type" content="blog"><meta property="og:title" content="Homepage of Jinghua Xu"><meta property="og:url" content="http://asgard-tim.github.io/"><meta property="og:site_name" content="Homepage of Jinghua Xu"><meta property="og:description" content="重庆大学2022级明月科创实验班人工智能专业本科在读"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://asgard-tim.github.io/img/og_image.png"><meta property="article:author" content="Tim"><meta property="article:tag" content="Blog"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://asgard-tim.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://Asgard-Tim.github.io"},"headline":"Homepage of Jinghua Xu","image":["http://asgard-tim.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Tim"},"publisher":{"@type":"Organization","name":"Homepage of Jinghua Xu","logo":{"@type":"ImageObject","url":"http://asgard-tim.github.io/img/title1.png"}},"description":"重庆大学2022级明月科创实验班人工智能专业本科在读"}</script><link rel="icon" href="/img/photo.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/xt256.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com">GitHub</a><a class="navbar-item" target="_blank" rel="noopener" title="Contect me on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">Python</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2025-04-22T18:07:03.000Z" title="2025/4/23 02:07:03">2025-04-23</time>发表</span><span class="level-item"><time datetime="2025-04-29T15:58:08.821Z" title="2025/4/29 23:58:08">2025-04-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a><span>&nbsp;/&nbsp;</span><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">工程数值分析</a></span><span class="level-item">1 小时读完 (大约8883个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/04/23/project02/">图像插值算法及其优化</a></p><div class="content"><div id="postchat_postcontent"><h2 id="研究背景及其意义"><a href="#研究背景及其意义" class="headerlink" title="研究背景及其意义"></a>研究背景及其意义</h2><p>图像<strong>放大</strong>与<strong>旋转</strong>是数字图像处理中最基础的几何变换操作，其核心在于如何通过插值算法重建原始图像中不存在的像素信息。当对图像进行放大操作时，输出图像的像素网格会超出原始图像的采样范围，需要通过插值来填补这些新增像素点的颜色值；而在旋转操作中，即使保持图像尺寸不变，原始像素的整数坐标经过旋转变换后也会落在新图像的非整数位置，同样需要通过插值来重新确定每个输出像素的颜色值。</p>
<p>图像插值是利用原图像中的颜色值通过一定的方法计算出待插入像素点的颜色值的过程。对图像进行插值一般有两个步骤：首先定义一个图像插值公式，然后利用该插值公式计算待插入点的颜色值。常见的图像插值算法有双线性法、最近邻法、非均匀法、双三次卷积插值法、双立方法、Lagrange法、 样条插值法、 克里金（Krijing） 插值法等。这些插值方法通常定义一个插值数据点的隐式函数，再提取该函数的等值面作为图像插值方法，常用的插值核包括线性插值核、样条插值核等。</p>
<ul>
<li><strong>最近邻插值</strong>作为最简单的算法，直接将距离待插值点最近的已知像素值作为结果，虽然计算效率极高（时间复杂度O(1)），但会产生明显的块状伪影（“马赛克”）和锯齿形边缘；</li>
<li><strong>双线性插值</strong>通过考虑2×2邻域内四个像素的加权平均，在计算成本（O(n)）和视觉效果之间取得平衡，但仍会导致高频信息丢失和边缘模糊；</li>
<li>更高阶的<strong>双三次插值</strong>（使用4×4邻域）和样条插值虽然能提供更平滑的结果，但计算复杂度显著增加（O(n²)），且可能引入不必要的振铃效应。</li>
</ul>
<p>现有算法的根本<strong>局限</strong>在于<strong>采用统一的插值核函数处理整幅图像，忽视了图像不同区域的特征差异</strong>。例如，在平坦区域使用复杂插值会造成计算资源浪费，而在纹理丰富区域使用简单插值又会导致细节损失。基于此，我们希望通过改良的<strong>四平面插值</strong>算法对图像的放大与旋转效果进行优化，<strong>根据图像局部特征自适应地选择不同的插值策略</strong>，以规避用同一个插值公式对所有像素进行插值存在的不足。</p>
<h2 id="常用图像插值算法"><a href="#常用图像插值算法" class="headerlink" title="常用图像插值算法"></a>常用图像插值算法</h2><p>课本在6.5节中提到，在插值节点数量较多时，为避免Runge振荡现象的发生，并不提倡用高次多项式进行插值，而宁可用低次多项式作分段插值。在图像处理这一特定的应用场景中，需要处理的图像尺寸规模往往较大，且同一行（列）的所有像素颜色值显然并不具有可以用一个多项式函数显式表达的规律，但相邻的像素点颜色值之间又存在一定的关联性，因此分段插值仅考虑局部特征的特性在这里能够良好地契合所需性能。根据对于待插入像素点周围已有的像素点信息的利用情况，这里列举了几种常见的图像插值算法：</p>
<ul>
<li>最近邻法：仅利用待插值像素点转换至原图像坐标后距离其最近的一个像素点的颜色值，将其直接作为待插值像素点的颜色值</li>
<li>双线性法：利用待插值像素点转换至原图像坐标后距离其最近的四个像素点的颜色值，加权平均后作为待插值像素点的颜色值</li>
<li>双立方法：利用待插值像素点转换至原图像坐标后距离其最近的十六个像素点的颜色值，加权平均后作为待插值像素点的颜色值</li>
</ul>
<h3 id="最近邻法"><a href="#最近邻法" class="headerlink" title="最近邻法"></a>最近邻法</h3><p><img src="/images/project2/3.png" alt="一维最近邻插值示意图"></p>
<p>如上图所示，在一维最近邻插值中，坐标轴上各点 xi-1，xi，xi+1 … 两两对半等分间隔 (红色虚线划分)，从而非边界的各坐标点都有一个等宽的邻域，并根据每个坐标点的值构成一个类似分段函数的函数约束，从而使各插值坐标点的值等同于所在邻域原坐标点的值。例如，插值点 x 坐落于 坐标点 xi 的邻域，那么其值 f(x) 就等于 f(xi)。</p>
<p>在二维的图像插值场景中，可以对上述一维最近邻插值进行推广，如下图所示：</p>
<p><img src="/images/project2/4.png" alt="二维最近邻插值示意图"></p>
<p>可以看到，(x0, y0)、(x0, y1)、(x1, y0)、(x1, y1) 都是原图像上的坐标点，颜色值分别对应为 Q11、Q12、Q21、Q22。而颜色值未知的插值点 (x, y)（需转换至原图像坐标），根据最近邻插值方法的约束，其与坐标点 (x0, y0) 位置最接近 (即位于  (x0, y0) 的邻域内)，故插值点 (x, y) 的颜色值 P = Q11。</p>
<p>总而言之，最近邻法的基本思想即：<strong>将待插入点的坐标进行四舍五入，再以该行列坐标都是整数点的颜色值（灰度值）替代待插入点(x, y)处的颜色值。</strong>事实上，这也正是机器学习中KNN（K-Nearest Neighbor）算法在K=1时的情形。</p>
<p>基于以上算法思想，编写python函数代码实现图像放缩与旋转过程中的最近邻法插值：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最近邻法插值实现图像放缩</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nearest_neighbor_interpolation</span>(<span class="params">image, scale_factor</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    new_h, new_w = <span class="built_in">int</span>(h * scale_factor), <span class="built_in">int</span>(w * scale_factor)</span><br><span class="line">    resized_image = np.zeros((new_h, new_w, <span class="built_in">int</span>(channel)), dtype=image.dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            src_i = <span class="built_in">int</span>(<span class="built_in">round</span>((i + <span class="number">1</span>) / scale_factor, <span class="number">0</span>))</span><br><span class="line">            src_j = <span class="built_in">int</span>(<span class="built_in">round</span>((j + <span class="number">1</span>) / scale_factor, <span class="number">0</span>))</span><br><span class="line">            resized_image[i, j] = image[src_i - <span class="number">1</span>, src_j - <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> resized_image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最近邻法插值实现图像旋转</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nearest_neighbor_rotation</span>(<span class="params">image, angle</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    angle_rad = math.radians(angle)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算旋转后的图像尺寸</span></span><br><span class="line">    cos_theta = <span class="built_in">abs</span>(math.cos(angle_rad))</span><br><span class="line">    sin_theta = <span class="built_in">abs</span>(math.sin(angle_rad))</span><br><span class="line">    new_w = <span class="built_in">int</span>(h * sin_theta + w * cos_theta)</span><br><span class="line">    new_h = <span class="built_in">int</span>(h * cos_theta + w * sin_theta)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 旋转中心</span></span><br><span class="line">    cx, cy = w / <span class="number">2</span>, h / <span class="number">2</span></span><br><span class="line">    new_cx, new_cy = new_w / <span class="number">2</span>, new_h / <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    rotated_image = np.zeros((new_h, new_w, channel), dtype=image.dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            <span class="comment"># 将新图像坐标转换回原图像坐标</span></span><br><span class="line">            x = (j - new_cx) * math.cos(angle_rad) + (i - new_cy) * math.sin(angle_rad) + cx</span><br><span class="line">            y = -(j - new_cx) * math.sin(angle_rad) + (i - new_cy) * math.cos(angle_rad) + cy</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 最近邻插值</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= x &lt; w <span class="keyword">and</span> <span class="number">0</span> &lt;= y &lt; h:</span><br><span class="line">                src_x = <span class="built_in">int</span>(<span class="built_in">round</span>(x))</span><br><span class="line">                src_y = <span class="built_in">int</span>(<span class="built_in">round</span>(y))</span><br><span class="line">                rotated_image[i, j] = image[src_y - <span class="number">1</span>, src_x - <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rotated_image</span><br></pre></td></tr></tbody></table></figure>

<h3 id="双线性法"><a href="#双线性法" class="headerlink" title="双线性法"></a>双线性法</h3><p><img src="/images/project2/5.png" alt="一维线性插值示意图"></p>
<p>如上图所示，在一维的线性插值中，坐标轴上各点 xi-1，xi，xi+1 … 的值“两两直接相连”为线段，从而构成了一条连续的约束函数。而插值坐标点例如 x，根据约束函数其值应为 f(x)。因为每两个坐标点之间的约束函数曲线是一次线性的线段，对插值结果而言是“线性” 的，所以该方法称为线性插值。基于线性函数的特性，可以便捷地求取原图像上的两个像素点间任一待插值点的颜色值：</p>
<p><img src="/images/project2/6.png" alt="一维线性插值计算示意图"></p>
<p>可以看到，图中 x0 和 x1 都是原有的坐标点，颜色值分别对应为 y0 和 y1，此时根据线性插值法约束，在 (x0, y0) 和 (x1, y1) 构成的一次函数上，颜色值未知的插值点 x的颜色值 y 即为：<br>$$<br>y=y_0+(x-x_0)\frac{y_1-y_0}{x_1-x_0}=y_0+\frac{(x-x_0)y_1-(x-x_0)y_0}{x_1-x_0}<br>$$<br>实际上，即便 x 不在 x0 与 x1 之间，该公式也成立（此时为线性外插），但图像处理中不需涉及此情形。 </p>
<p>从一维的线性插值出发，很容易拓展到二维图像的双线性插值，通过三次一阶线性插值（本质为加权求和）获得最终结果，下图便展示了该过程的定性斜视与定量俯视示意图：</p>
<p><img src="/images/project2/7.png" alt="二维线性插值定性斜视示意图"></p>
<p><img src="/images/project2/8.png" alt="二维线性插值定量俯视示意图"></p>
<p>其中，(x0, y0)、(x0, y1)、(x1, y0)、(x1, y1) 均为原图像上的像素坐标点，颜色值分别对应为 f(x0, y0)、f(x0, y1)、f(x1, y0)、f(x1, y1)。而颜色值未知的插值点 (x, y)，根据双线性插值法的约束，可以先由像素坐标点 (x0, y0) 和 (x0, y1) 在 y 轴向作一维线性插值得到 f(x0, y)、由像素坐标点 (x1, y0) 和 (x1, y1) 在 y 轴向作一维线性插值得到 f(x1, y)，然后再由 (x0, y) 和 (x1, y) 在 x 轴向作一维线性插值得到插值点 (x, y) 的灰度值 f(x, y)。</p>
<p>事实上，一维线性插值先作 x 轴向再作 y 轴向，得到的结果完全相同，仅为顺序先后的区别。这里不妨先由像素坐标点 (x0, y0) 和 (x1, y0) 在 x 轴向作一维线性插值得到 f(x, y0)、由像素坐标点 (x0, y1) 和 (x1, y1) 在 x 轴向作一维线性插值得到 f(x, y1)：<br>$$<br>f(x,y_0)=\frac{x_1-x}{x_1-x_0}f(x_0,y_0)+\frac{x-x_0}{x_1-x_0}f(x_1,y_0)<br>$$</p>
<p>$$<br>f(x,y_1)=\frac{x_1-x}{x_1-x_0}f(x_0,y_1)+\frac{x-x_0}{x_1-x_0}f(x_1,y_1)<br>$$</p>
<p>然后再由 (x, y0) 和 (x, y1) 在 y 轴向作一维线性插值得到插值点 (x, y) 的灰度值 f(x, y)：<br>$$<br>f(x,y)=\frac{y_1-y}{y_1-y_0}f(x,y_0)+\frac{y-y_0}{y_1-y_0}f(x,y_1)<br>$$<br>合并上述式子，得到最终的双线性插值结果：<br>$$<br>f(x,y)=\frac{(y_1-y)(x_1-x)}{(y_1-y_0)(x_1-x_0)}f(x_0,y_0)+\frac{(y_1-y)(x-x_0)}{(y_1-y_0)(x_1-x_0)}f(x_1,y_0)+\frac{(y-y_0)(x_1-x)}{(y_1-y_0)(x_1-x_0)}f(x_0,y_1)+\frac{(y-y_0)(x-x_0)}{(y_1-y_0)(x_1-x_0)}<br>$$<br>值得注意的是，在实际的图像插值处理过程中，为尽量保证插值效果的准确性，往往仅采用距离待插值点（转换至原图像坐标）最近的四个点，即:（[]符号表示待插值点转换至原图像坐标后向下取整）<br>$$<br>x_0=[x]，y_0=[y]<br>$$</p>
<p>$$<br>x_1=x_0+1，y_1=y_0+1<br>$$</p>
<p>从加权求和的角度理解，可以进一步地将双线性插值结果改写为如下形式：<br>$$<br>p=x-[x], q=y-[y]<br>$$</p>
<p>$$<br>\begin{array}{rcl}f(x,y)=(1-q){(1-p)f([x][y])+pf([x]+1,[y])}+q{(1-p)f([x],[y]+1)+pf([x]+1,[y]+1)}\end{array}<br>$$</p>
<p><img src="/images/project2/9.png" alt="二维线性插值加权求和角度示意图"></p>
<p>基于以上算法思想，编写python函数代码实现图像放缩与旋转过程中的双线性法插值：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 双线性法插值实现图像放缩</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bilinear_interpolation</span>(<span class="params">image, scale_factor</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    new_h, new_w = <span class="built_in">int</span>(h * scale_factor), <span class="built_in">int</span>(w * scale_factor)</span><br><span class="line">    resized_image = np.zeros((new_h, new_w, <span class="built_in">int</span>(channel)), dtype=image.dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            x = (j + <span class="number">1</span>) / scale_factor</span><br><span class="line">            y = (i + <span class="number">1</span>) / scale_factor</span><br><span class="line">            x1 = <span class="built_in">int</span>(x)</span><br><span class="line">            y1 = <span class="built_in">int</span>(y)</span><br><span class="line">            x2 = x1 + <span class="number">1</span></span><br><span class="line">            y2 = y1 + <span class="number">1</span></span><br><span class="line">            p = x - x1</span><br><span class="line">            q = y - y1</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 边界问题处理</span></span><br><span class="line">            <span class="keyword">if</span> x2 == w + <span class="number">1</span>:</span><br><span class="line">                x2 = x1</span><br><span class="line">            <span class="keyword">if</span> y2 == h + <span class="number">1</span>:</span><br><span class="line">                y2 = y1</span><br><span class="line">                </span><br><span class="line">            resized_image[i ,j] = (<span class="number">1</span> - q) * ((<span class="number">1</span> - p) * image[y1 - <span class="number">1</span>, x1 - <span class="number">1</span>] + p * image[y1 - <span class="number">1</span>, x2 - <span class="number">1</span>]) + q * ((<span class="number">1</span> - p) * image[y2 - <span class="number">1</span>, x1 - <span class="number">1</span>] + p * image[y2 - <span class="number">1</span>, x2 - <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> resized_image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 双线性法插值实现图像旋转</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bilinear_rotation</span>(<span class="params">image, angle</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    angle_rad = math.radians(angle)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算旋转后的图像尺寸</span></span><br><span class="line">    cos_theta = <span class="built_in">abs</span>(math.cos(angle_rad))</span><br><span class="line">    sin_theta = <span class="built_in">abs</span>(math.sin(angle_rad))</span><br><span class="line">    new_w = <span class="built_in">int</span>(h * sin_theta + w * cos_theta)</span><br><span class="line">    new_h = <span class="built_in">int</span>(h * cos_theta + w * sin_theta)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 旋转中心</span></span><br><span class="line">    cx, cy = w / <span class="number">2</span>, h / <span class="number">2</span></span><br><span class="line">    new_cx, new_cy = new_w / <span class="number">2</span>, new_h / <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    rotated_image = np.zeros((new_h, new_w, channel), dtype=image.dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            <span class="comment"># 将新图像坐标转换回原图像坐标</span></span><br><span class="line">            x = (j - new_cx) * math.cos(angle_rad) + (i - new_cy) * math.sin(angle_rad) + cx</span><br><span class="line">            y = -(j - new_cx) * math.sin(angle_rad) + (i - new_cy) * math.cos(angle_rad) + cy</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 双线性插值</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= x &lt; w-<span class="number">1</span> <span class="keyword">and</span> <span class="number">0</span> &lt;= y &lt; h-<span class="number">1</span>:</span><br><span class="line">                x1, y1 = <span class="built_in">int</span>(x), <span class="built_in">int</span>(y)</span><br><span class="line">                x2, y2 = <span class="built_in">min</span>(x1 + <span class="number">1</span>, w - <span class="number">1</span>), <span class="built_in">min</span>(y1 + <span class="number">1</span>, h - <span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 计算权重</span></span><br><span class="line">                a = x - x1</span><br><span class="line">                b = y - y1</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 边界处理</span></span><br><span class="line">                <span class="keyword">if</span> x2 &gt;= w:</span><br><span class="line">                    x2 = x1</span><br><span class="line">                <span class="keyword">if</span> y2 &gt;= h:</span><br><span class="line">                    y2 = y1</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 插值计算</span></span><br><span class="line">                rotated_image[i, j] = (<span class="number">1</span> - a) * (<span class="number">1</span> - b) * image[y1, x1] + \</span><br><span class="line">                                     a * (<span class="number">1</span> - b) * image[y1, x2] + \</span><br><span class="line">                                     (<span class="number">1</span> - a) * b * image[y2, x1] + \</span><br><span class="line">                                     a * b * image[y2, x2]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rotated_image    </span><br></pre></td></tr></tbody></table></figure>

<h3 id="双立方法"><a href="#双立方法" class="headerlink" title="双立方法"></a>双立方法</h3><p>双立方法插值又称立方卷积插值/双三次插值，这也是数值分析中最常用的二维插值方法。在这种方法中，插值点 (x, y) 的像素颜色值 f(x, y) 通过矩形网格中最近的十六个采样点的加权平均得到，而各采样点的权重由该点到待求插值点的距离确定，此距离包括水平和竖直两个方向上的距离。相比之下，双线性插值仅由周围的四个采样点加权得到。</p>
<p><img src="/images/project2/10.png" alt="双立方法插值示意图"></p>
<p>如上图所示，设（转换至原图像中）待求插值点坐标为 (i+u, j+v)【i、j为整数部分，u、v为小数部分】，已知其周围的 16 个像素坐标点 (网格) 的颜色值，还需要计算 16 个点各自的权重。以像素坐标点 (i, j) 为例，因为该点在 y 轴和 x 轴方向上与待求插值点 (i+u, j+v) 的距离分别为 u 和 v，所以其权重为 w(u) × w(v)，其中 w(·) 是插值权重核 (可以理解为定义的权重函数)。同理可得其余 15 个像素坐标点各自的权重。那么，待求插值点 (i+u, j+v) 的颜色值 f(i+u, j+v) 将通过如下计算得到：<br>$$<br>f(i+u,j+v)=A\times B\times C<br>$$<br>其中各项由向量或矩阵表示为：<br>$$<br>\mathrm{A}=[w(1+u)w(u)w(1-u)w(2-u)]<br>$$</p>
<p>$$<br>\mathrm{B}=\begin{bmatrix}f(i-1,j-1)&amp;f(i-1,j+0)&amp;f(i-1,j+1)&amp;f(i-1,j+2)\f(i+0,j-1)&amp;f(i+0,j+0)&amp;f(i+0,j+1)&amp;f(i+0,j+2)\f(i+1,j-1)&amp;f(i+1,j+0)&amp;f(i+1,j+1)&amp;f(i+1,j+2)\f(i+2,j-1)&amp;f(i+2,j+0)&amp;f(i+2,j+1)&amp;f(i+2,j+2)\end{bmatrix}<br>$$</p>
<p>$$<br>\mathbb{C}=[w(1+v)w(v)w(1-v)w(2-v)]^T<br>$$</p>
<p>插值权重核 w(·) 为：<br>$$<br>w(x)=\begin{cases}1-2|x|^2+|x|^3&amp;,|x|&lt;1\4-8|x|+5|x|^2-|x|^3&amp;,1\leq|x|&lt;2\0&amp;,|x|\geq2&amp;\end{cases}<br>$$<br>插值权重核 w(·) 的函数图像：</p>
<p><img src="/images/project2/11.png" alt="双立方法插值权重核函数图像"></p>
<p>为方便后续算法实现，将以上加权求和过程各步骤展开，合并后化简得到待插入点的颜色值计算公式：<br>$$<br>f(i+u,j+v)=\sum_{m=0}^{3}\sum_{n=0}^{3}a_{mn}u^{m}v^{n}<br>$$<br>其中多项式的系数a_{mn}计算公式如下：(式中p <em>{qr}与上述矩阵B中元素一一对应，如p <em>00=f(i-1,j-1))<br>$$<br>\begin{aligned}<br>&amp;a</em>{00}=p</em>{11}\&amp;a_{01}=-\frac{1}{2}p_{10}+\frac{1}{2}p_{12}\&amp;a_{02}=p_{10}-\frac{5}{2}p_{11}+2p_{12}-\frac{1}{2}p_{13}\&amp;a_{03}=-\frac{1}{2}p_{10}+\frac{3}{2}p_{11}-\frac{3}{2}p_{12}+\frac{1}{2}p_{13}\&amp;a_{10}=-\frac{1}{2}p_{01}+\frac{1}{2}p_{21}\&amp;a_{11}=\frac{1}{4}p_{00}-\frac{1}{4}p_{02}-\frac{1}{4}p_{20}+\frac{1}{4}p_{22}\&amp;a_{12}=-\frac{1}{2}p_{00}+\frac{1}{4}p_{01}-p_{02}+\frac{1}{4}p_{03}+\frac{1}{2}p_{20}-\frac{5}{4}p_{21}+p_{22}-\frac{1}{4}p_{23}\&amp;a_{13}=\frac{1}{4}p_{00}-\frac{3}{4}p_{01}+\frac{3}{4}p_{02}-\frac{1}{4}p_{03}-\frac{1}{4}p_{20}+\frac{3}{4}p_{21}-\frac{3}{4}p_{22}+\frac{1}{4}p_{23}\<br>&amp;a_{20}=p_{01}-\frac{5}{2}p_{11}+2p_{21}-\frac{1}{2}p_{31}\<br>&amp;a_{21}=-\frac{1}{2}p_{00}+\frac{1}{2}p_{02}+\frac{5}{4}p_{10}-\frac{5}{4}p_{12}-p_{20}+p_{22}+\frac{1}{4}p_{30}-\frac{1}{4}p_{32}\&amp;a_{22}=p_{00}-\frac{5}{2}p_{01}+2p_{02}-\frac{1}{2}p_{03}-\frac{5}{2}p_{10}+\frac{25}{4}p_{11}-5p_{12}+\frac{5}{4}p_{13}+2p_{20}-5p_{21}+4p_{22}-p_{23}-\frac{1}{2}p_{30}+\frac{5}{4}p_{31}-p_{32}+\frac{1}{4}p_{33}\<br>&amp;a_{23}=-\frac{1}{2}p_{00}+\frac{3}{2}p_{01}-\frac{3}{2}p_{02}+\frac{1}{2}p_{03}+\frac{5}{4}p_{10}-\frac{15}{4}p_{11}+\frac{15}{4}p_{12}-\frac{5}{4}p_{13}-p_{20}+3p_{21}-3p_{22}+p_{23}+\frac{1}{4}p_{30}-\frac{3}{4}p_{31}+\frac{3}{4}p_{32}-\frac{1}{4}p_{33}\<br>&amp;a_{30}=-\frac{1}{2}p_{01}+\frac{3}{2}p_{11}-\frac{3}{2}p_{21}+\frac{1}{2}p_{31}\<br>&amp;a_{31}=\frac{1}{4}p_{00}-\frac{1}{4}p_{02}-\frac{3}{4}p_{10}+\frac{3}{4}p_{12}+\frac{3}{4}p_{20}-\frac{3}{4}p_{22}-\frac{1}{4}p_{30}+\frac{1}{4}p_{32}\&amp;a_{32}=-\frac{1}{2}p_{00}+\frac{5}{4}p_{01}-p_{02}+\frac{1}{4}p_{03}+\frac{3}{2}p_{10}-\frac{15}{4}p_{11}+3p_{12}-\frac{3}{4}p_{13}-\frac{3}{2}p_{20}+\frac{15}{4}p_{21}-3p_{22}+\frac{3}{4}p_{23}+\frac{1}{2}p_{30}-\frac{5}{4}p_{31}+p_{32}-\frac{1}{4}p_{33}\&amp;a_{33}=\frac{1}{4}p_{00}-\frac{3}{4}p_{01}+\frac{3}{4}p_{02}-\frac{1}{4}p_{03}-\frac{3}{4}p_{10}+\frac{9}{4}p_{11}-\frac{9}{4}p_{12}+\frac{3}{4}p_{13}+\frac{3}{4}p_{20}-\frac{9}{4}p_{21}+\frac{9}{4}p_{22}-\frac{3}{4}p_{23}-\frac{1}{4}p_{30}+\frac{3}{4}p_{31}-\frac{3}{4}p_{32}+\frac{1}{4}p_{33}<br>\end{aligned}<br>$$<br>基于以上算法思想，编写python函数代码实现图像放缩与旋转过程中的双立方法插值：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 双立方法插值实现图像放缩</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bicubic_interpolation</span>(<span class="params">image, scale_factor</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    new_h, new_w = <span class="built_in">int</span>(h * scale_factor), <span class="built_in">int</span>(w * scale_factor)</span><br><span class="line">    resized_image = np.zeros((new_h, new_w, channel))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            x = i / scale_factor</span><br><span class="line">            y = j / scale_factor</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 确定16个邻域像素的坐标</span></span><br><span class="line">            x0 = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">int</span>(np.floor(x)) - <span class="number">1</span>)</span><br><span class="line">            x1 = x0 + <span class="number">1</span></span><br><span class="line">            x2 = x0 + <span class="number">2</span></span><br><span class="line">            x3 = <span class="built_in">min</span>(w-<span class="number">1</span>, x0 + <span class="number">3</span>)</span><br><span class="line">            </span><br><span class="line">            y0 = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">int</span>(np.floor(y)) - <span class="number">1</span>)</span><br><span class="line">            y1 = y0 + <span class="number">1</span></span><br><span class="line">            y2 = y0 + <span class="number">2</span></span><br><span class="line">            y3 = <span class="built_in">min</span>(h-<span class="number">1</span>, y0 + <span class="number">3</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取16个邻域像素的值</span></span><br><span class="line">            p = np.zeros((<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                    xi = x0 + n</span><br><span class="line">                    yi = y0 + m</span><br><span class="line">                    xi = <span class="built_in">min</span>(<span class="built_in">max</span>(xi, <span class="number">0</span>), w-<span class="number">1</span>)  <span class="comment"># 边界处理</span></span><br><span class="line">                    yi = <span class="built_in">min</span>(<span class="built_in">max</span>(yi, <span class="number">0</span>), h-<span class="number">1</span>)</span><br><span class="line">                    p[m, n] = image[yi, xi]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算相对位置</span></span><br><span class="line">            dx = x - x1</span><br><span class="line">            dy = y - y1</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 系数</span></span><br><span class="line">            a = np.zeros((<span class="number">4</span>, <span class="number">4</span>, channel))</span><br><span class="line">            a[<span class="number">0</span>, <span class="number">0</span>] = p[<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">            a[<span class="number">0</span>, <span class="number">1</span>] = -<span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">            a[<span class="number">0</span>, <span class="number">2</span>] = p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">2.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">2</span>*p[<span class="number">1</span>, <span class="number">2</span>] - <span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">            a[<span class="number">0</span>, <span class="number">3</span>] = -<span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">            </span><br><span class="line">            a[<span class="number">1</span>, <span class="number">0</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">0.5</span>*p[<span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">            a[<span class="number">1</span>, <span class="number">1</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">            a[<span class="number">1</span>, <span class="number">2</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">1.25</span>*p[<span class="number">0</span>, <span class="number">1</span>] - p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] + <span class="number">0.5</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">1.25</span>*p[<span class="number">2</span>, <span class="number">1</span>] + p[<span class="number">2</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">            a[<span class="number">1</span>, <span class="number">3</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] - <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">            </span><br><span class="line">            a[<span class="number">2</span>, <span class="number">0</span>] = p[<span class="number">0</span>, <span class="number">1</span>] - <span class="number">2.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">2</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">            a[<span class="number">2</span>, <span class="number">1</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">2</span>] - p[<span class="number">2</span>, <span class="number">0</span>] + p[<span class="number">2</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">            a[<span class="number">2</span>, <span class="number">2</span>] = p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">2.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">2</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">3</span>] - <span class="number">2.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">6.25</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">5</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">3</span>] + <span class="number">2</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">5</span>*p[<span class="number">2</span>, <span class="number">1</span>] + <span class="number">4</span>*p[<span class="number">2</span>, <span class="number">2</span>] - p[<span class="number">2</span>, <span class="number">3</span>] - <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">0</span>] + <span class="number">1.25</span>*p[<span class="number">3</span>, <span class="number">1</span>] - p[<span class="number">3</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">            a[<span class="number">2</span>, <span class="number">3</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">1.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] - <span class="number">1.5</span>*p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">3</span>] + <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">3.75</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">3.75</span>*p[<span class="number">1</span>, <span class="number">2</span>] - <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">3</span>] - p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">3</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">3</span>*p[<span class="number">2</span>, <span class="number">2</span>] + p[<span class="number">2</span>, <span class="number">3</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">1</span>] + <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">            </span><br><span class="line">            a[<span class="number">3</span>, <span class="number">0</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">1.5</span>*p[<span class="number">2</span>, <span class="number">1</span>] + <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">            a[<span class="number">3</span>, <span class="number">1</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">            a[<span class="number">3</span>, <span class="number">2</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">1.25</span>*p[<span class="number">0</span>, <span class="number">1</span>] - p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] + <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">3.75</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">3</span>*p[<span class="number">1</span>, <span class="number">2</span>] - <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">3</span>] - <span class="number">1.5</span>*p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">3.75</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">3</span>*p[<span class="number">2</span>, <span class="number">2</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">3</span>] + <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">0</span>] - <span class="number">1.25</span>*p[<span class="number">3</span>, <span class="number">1</span>] + p[<span class="number">3</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">            a[<span class="number">3</span>, <span class="number">3</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] - <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">2.25</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">2.25</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">3</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">2.25</span>*p[<span class="number">2</span>, <span class="number">1</span>] + <span class="number">2.25</span>*p[<span class="number">2</span>, <span class="number">2</span>] - <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">3</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] + <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">1</span>] - <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算插值结果</span></span><br><span class="line">            value = np.zeros(channel)</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                    value += a[m, n] * (dx**n) * (dy**m)</span><br><span class="line">            </span><br><span class="line">            resized_image[i, j] = np.clip(value, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> resized_image.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 双立方法插值实现图像旋转</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bicubic_rotation</span>(<span class="params">image, angle</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    angle_rad = math.radians(angle)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算旋转后的图像尺寸</span></span><br><span class="line">    cos_theta = <span class="built_in">abs</span>(math.cos(angle_rad))</span><br><span class="line">    sin_theta = <span class="built_in">abs</span>(math.sin(angle_rad))</span><br><span class="line">    new_w = <span class="built_in">int</span>(h * sin_theta + w * cos_theta)</span><br><span class="line">    new_h = <span class="built_in">int</span>(h * cos_theta + w * sin_theta)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 旋转中心</span></span><br><span class="line">    cx, cy = w / <span class="number">2</span>, h / <span class="number">2</span></span><br><span class="line">    new_cx, new_cy = new_w / <span class="number">2</span>, new_h / <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    rotated_image = np.zeros((new_h, new_w, channel))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            <span class="comment"># 将新图像坐标转换回原图像坐标</span></span><br><span class="line">            x = (j - new_cx) * math.cos(angle_rad) + (i - new_cy) * math.sin(angle_rad) + cx</span><br><span class="line">            y = -(j - new_cx) * math.sin(angle_rad) + (i - new_cy) * math.cos(angle_rad) + cy</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= x &lt; w <span class="keyword">and</span> <span class="number">0</span> &lt;= y &lt; h:</span><br><span class="line">                <span class="comment"># 确定16个邻域像素的坐标</span></span><br><span class="line">                x0 = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">int</span>(np.floor(x)) - <span class="number">1</span>)</span><br><span class="line">                x1 = x0 + <span class="number">1</span></span><br><span class="line">                x2 = x0 + <span class="number">2</span></span><br><span class="line">                x3 = <span class="built_in">min</span>(w-<span class="number">1</span>, x0 + <span class="number">3</span>)</span><br><span class="line">                </span><br><span class="line">                y0 = <span class="built_in">max</span>(<span class="number">0</span>, <span class="built_in">int</span>(np.floor(y)) - <span class="number">1</span>)</span><br><span class="line">                y1 = y0 + <span class="number">1</span></span><br><span class="line">                y2 = y0 + <span class="number">2</span></span><br><span class="line">                y3 = <span class="built_in">min</span>(h-<span class="number">1</span>, y0 + <span class="number">3</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取16个邻域像素的值</span></span><br><span class="line">                p = np.zeros((<span class="number">4</span>, <span class="number">4</span>, channel))</span><br><span class="line">                <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                        xi = x0 + n</span><br><span class="line">                        yi = y0 + m</span><br><span class="line">                        xi = <span class="built_in">min</span>(<span class="built_in">max</span>(xi, <span class="number">0</span>), w-<span class="number">1</span>)  <span class="comment"># 边界处理</span></span><br><span class="line">                        yi = <span class="built_in">min</span>(<span class="built_in">max</span>(yi, <span class="number">0</span>), h-<span class="number">1</span>)</span><br><span class="line">                        p[m, n] = image[yi, xi]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 计算相对位置</span></span><br><span class="line">                dx = x - x1</span><br><span class="line">                dy = y - y1</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 系数</span></span><br><span class="line">                a = np.zeros((<span class="number">4</span>, <span class="number">4</span>, channel))</span><br><span class="line">                a[<span class="number">0</span>, <span class="number">0</span>] = p[<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">                a[<span class="number">0</span>, <span class="number">1</span>] = -<span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">                a[<span class="number">0</span>, <span class="number">2</span>] = p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">2.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">2</span>*p[<span class="number">1</span>, <span class="number">2</span>] - <span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">                a[<span class="number">0</span>, <span class="number">3</span>] = -<span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">0.5</span>*p[<span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">                </span><br><span class="line">                a[<span class="number">1</span>, <span class="number">0</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">0.5</span>*p[<span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">                a[<span class="number">1</span>, <span class="number">1</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">                a[<span class="number">1</span>, <span class="number">2</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">1.25</span>*p[<span class="number">0</span>, <span class="number">1</span>] - p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] + <span class="number">0.5</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">1.25</span>*p[<span class="number">2</span>, <span class="number">1</span>] + p[<span class="number">2</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">                a[<span class="number">1</span>, <span class="number">3</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] - <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">                </span><br><span class="line">                a[<span class="number">2</span>, <span class="number">0</span>] = p[<span class="number">0</span>, <span class="number">1</span>] - <span class="number">2.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">2</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">                a[<span class="number">2</span>, <span class="number">1</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">2</span>] - p[<span class="number">2</span>, <span class="number">0</span>] + p[<span class="number">2</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">                a[<span class="number">2</span>, <span class="number">2</span>] = p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">2.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">2</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">3</span>] - <span class="number">2.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">6.25</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">5</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">3</span>] + <span class="number">2</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">5</span>*p[<span class="number">2</span>, <span class="number">1</span>] + <span class="number">4</span>*p[<span class="number">2</span>, <span class="number">2</span>] - p[<span class="number">2</span>, <span class="number">3</span>] - <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">0</span>] + <span class="number">1.25</span>*p[<span class="number">3</span>, <span class="number">1</span>] - p[<span class="number">3</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">                a[<span class="number">2</span>, <span class="number">3</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">1.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] - <span class="number">1.5</span>*p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">3</span>] + <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">3.75</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">3.75</span>*p[<span class="number">1</span>, <span class="number">2</span>] - <span class="number">1.25</span>*p[<span class="number">1</span>, <span class="number">3</span>] - p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">3</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">3</span>*p[<span class="number">2</span>, <span class="number">2</span>] + p[<span class="number">2</span>, <span class="number">3</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">1</span>] + <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">                </span><br><span class="line">                a[<span class="number">3</span>, <span class="number">0</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">1.5</span>*p[<span class="number">2</span>, <span class="number">1</span>] + <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">                a[<span class="number">3</span>, <span class="number">1</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">                a[<span class="number">3</span>, <span class="number">2</span>] = -<span class="number">0.5</span>*p[<span class="number">0</span>, <span class="number">0</span>] + <span class="number">1.25</span>*p[<span class="number">0</span>, <span class="number">1</span>] - p[<span class="number">0</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] + <span class="number">1.5</span>*p[<span class="number">1</span>, <span class="number">0</span>] - <span class="number">3.75</span>*p[<span class="number">1</span>, <span class="number">1</span>] + <span class="number">3</span>*p[<span class="number">1</span>, <span class="number">2</span>] - <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">3</span>] - <span class="number">1.5</span>*p[<span class="number">2</span>, <span class="number">0</span>] + <span class="number">3.75</span>*p[<span class="number">2</span>, <span class="number">1</span>] - <span class="number">3</span>*p[<span class="number">2</span>, <span class="number">2</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">3</span>] + <span class="number">0.5</span>*p[<span class="number">3</span>, <span class="number">0</span>] - <span class="number">1.25</span>*p[<span class="number">3</span>, <span class="number">1</span>] + p[<span class="number">3</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">                a[<span class="number">3</span>, <span class="number">3</span>] = <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">0</span>] - <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">1</span>] + <span class="number">0.75</span>*p[<span class="number">0</span>, <span class="number">2</span>] - <span class="number">0.25</span>*p[<span class="number">0</span>, <span class="number">3</span>] - <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">0</span>] + <span class="number">2.25</span>*p[<span class="number">1</span>, <span class="number">1</span>] - <span class="number">2.25</span>*p[<span class="number">1</span>, <span class="number">2</span>] + <span class="number">0.75</span>*p[<span class="number">1</span>, <span class="number">3</span>] + <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">0</span>] - <span class="number">2.25</span>*p[<span class="number">2</span>, <span class="number">1</span>] + <span class="number">2.25</span>*p[<span class="number">2</span>, <span class="number">2</span>] - <span class="number">0.75</span>*p[<span class="number">2</span>, <span class="number">3</span>] - <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">0</span>] + <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">1</span>] - <span class="number">0.75</span>*p[<span class="number">3</span>, <span class="number">2</span>] + <span class="number">0.25</span>*p[<span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 计算插值结果</span></span><br><span class="line">                value = np.zeros(channel)</span><br><span class="line">                <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                        value += a[m, n] * (dx**n) * (dy**m)</span><br><span class="line">                </span><br><span class="line">                rotated_image[i, j] = np.clip(value, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rotated_image.astype(np.uint8)</span><br></pre></td></tr></tbody></table></figure>

<h2 id="图像插值算法优化：基于四平面"><a href="#图像插值算法优化：基于四平面" class="headerlink" title="图像插值算法优化：基于四平面"></a>图像插值算法优化：基于四平面</h2><p>在上述的多种基于分段插值的图像插值算法中，均采用f(i, j)来表示图像的像素点坐标处的颜色值，其中ｉ表示行坐标，ｊ表示列坐标。为进一步地体现图像的局部特征差异并将其用于插值过程，我们引入“平面”的概念，并对图像数据进行升维处理，用三维空间点(i, j, f(i, j))来表示一个像素，并将其对应至空间坐标系中的一个点(x, y, z)。</p>
<p>对一个待插入点而言，可以通过坐标平移将其周围4 个像素点转换为：（注意：此处z0<del>z3为像素坐标点s0</del>s3的颜色值，下同）<br>$$<br>s_0(0,0,z_0),s_1(0,1,z_1),s_2(1,0,z_2),s_3(1,1,z_3)<br>$$<br>从上述４个点的坐标可以看出它们任意３个点一定不在同一条直线上， 不在同一直线上的３个点可以确定一个平面， 下面讨论具体的插值方法：</p>
<ol>
<li><p>先求出这４个点可能的４个平面方程</p>
<p>已知空间平面的一般方程为：<br>$$<br>Ax+By+Cz+D=0<br>$$<br>将s0、s1、s2分别带入上式可得：<br>$$<br>\begin{cases}Cz_0+D=0\B+Cz_1+D=0\A+Cz_2+D=0&amp;\end{cases}<br>$$<br>则有：<br>$$<br>D=-Cz_0,B=C(z_0-z_1),A=C(z_0-z_2)<br>$$<br>再将其带回空间平面方程，整理后用f(x, y)代替z得到插值公式：<br>$$<br>f(x,y)=(z_{2}-z_{0})x+(z_{1}-z_{2})y+z_{0}<br>$$<br>同理，将s0、s1、s3带入空间平面方程可得插值公式：<br>$$<br>f(x,y)=(z_{3}-z_{1})x+(z_{1}-z_{0})y+z_{0}<br>$$<br>将s0、s2、s3带入空间平面方程可得插值公式：<br>$$<br>f(x,y)=(z_{2}-z_{0})x+(z_{3}-z_{2})y+z_{0}<br>$$<br>将s1、s2、s3带入空间平面方程可得插值公式：<br>$$<br>f(x,y)=(z_{3}-z_{1})x+(z_{3}-z_{2})y+(z_{2}+z_{1}-z_{3})<br>$$</p>
</li>
<li><p>如果s0、s1、s2、s3这４ 个点在同一平面上， 则使用上述任意一个插值公式进行插值均可。 【平面法】</p>
<blockquote>
<p>判断这４个点是否在同一平面上， 只需要比较z1+z2 与 z0+z3是否相等：</p>
<p>线段s0s3中点坐标为<br>$$<br>(\frac12,\frac12,\frac{z_0+z_3}2)<br>$$<br>线段s1s2中点坐标为<br>$$<br>(\frac12,\frac12,\frac{z_1+z_2}2)<br>$$<br>如果它们的中点坐标相同，则说明两条线段相交，相交的两条直线可以决定一个平面，即如果待插人点周围的四个点满足：<br>$$<br>z_1+z_2=z_0+z_3<br>$$<br>则这它们就是同一平面上的 4 个点，否则就不是同一平面上的 4 个点。</p>
</blockquote>
</li>
<li><p>从４个可能的平面中选择一个平面进行插值【四平面法】</p>
<p>如果它们不是同一平面上的４个点， 情况比较复杂， 需认真讨论，s0、s1、s2、s3４个点的位置关系如下图所示：</p>
<p><img src="/images/project2/12.png" alt="四点不在同一平面"></p>
<p>在插值的过程中如果一半的区域选择由s0、s1、s2 所确定的平面进行插值， 则另一半必须选择由s1、s2、s3所确定的平面进行插值， 以保证对角线的每一边都是在同一个平面上， 避免出现 “锯齿形” 边缘，为了便于描述， 称s0、s1、s2所确定的平面为 “左下平面”，s1、s2、s3 所确定的平面为 “右上平面”，s0、s1、s3 所确定的平面 “左上平面”，s0、s2、s3所确定的平面 “右下平面”。 为此， 需要参考周围其他点的情况以决定选择哪个平面进行插值。 具体情况如下图所示（黑点是待插入点周围的４个点，白点是参考点）：</p>
<p><img src="/images/project2/13.png" alt="待插入点周围的像素点"></p>
<ol>
<li>对于“左下平面”， 只能参考s0、s1、s2三点左面和下面的点， 即s0、s1、s2三点与s4、s5、s6、s8四个点中的任意一点在同一平面上即可。 </li>
<li>对于“右上平面”，只能参考s1、s2、s3三点右面和上面的点， 即s1、s2、s3三点与s7、s9、s10、s11四个点中的任意一点在同一平面上即可。</li>
<li>对于 “左上平面”，只能参考s0、s1、s3三点左面和上面的点， 即s0、s1、s3三点与s6、s8、s10、s11四个点中的任意一点在同一平面上即可。 </li>
<li>对于 “右下平面”，只能参考s0、s2、s3三点右面和下面的点， 即s0、s2、s3三点与s4、s5、s7、s9四 个点中的任意一点在同一平面上即可。</li>
</ol>
<p>针对1、2两种情况， 当y = 1 + x时，用 “左下平面” 进行插值， 否则用 “右上平面” 进行插值；针对3、4两种情况， 当y = x ^ 3时，用 “左上平面” 进行插值， 否则用 “右下平面” 进行插值。</p>
<blockquote>
<p>判断４个点在同一平面上的方法：（以情况1为例）</p>
<ul>
<li><p>对于判断s0、s2、s1、s8 ４ 点是否在同一平面上， 只需要判断z0 + z1与z2 + z8是否相等即可； </p>
</li>
<li><p>对于s0、s1、s2、s5 ４点， 只需要判断z0 + z2与z1 + z5是否相等即可； </p>
</li>
<li><p>对于s0、s1、s2、s6 ４点：如果s0、s2、s6 ３点在同一直线上， 则直线外一点s1与该直线就可以确定一个平面，而要判断这三点是否在同一直线上，只需判断z2 + z6与2 * z0是否相等即可【线段s2(1, 0, z2) s6(-1, 0, z6) 的中点坐标为(0, 0, z2 + z6)，若z2 + z6 = 2 * z0， 则点s0(0, 0, z0)就是它们的中点坐标，当然这３点就在同一条直线上】； </p>
</li>
<li><p>对于s0、s1、s2、s4   ４点， 与s0、s1、s2、s6 ４ 点的情况相同。</p>
</li>
</ul>
</blockquote>
</li>
<li><p>如果2和3两点中的情形均不满足， 说明待插入点周围的情况太复杂（不符合平面插值）， 此时采用<strong>双线性法</strong>进行插值。</p>
</li>
</ol>
<p>基于以上算法思想，编写python函数代码实现图像放缩与旋转过程中的四平面法插值：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 四平面法插值实现图像放缩</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">four_plane_interpolation</span>(<span class="params">img, scale</span>):</span><br><span class="line">    H, W, C = img.shape</span><br><span class="line">    new_H, new_W = <span class="built_in">int</span>(H * scale), <span class="built_in">int</span>(W * scale)</span><br><span class="line">    output = np.zeros((new_H, new_W, C), dtype=img.dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(new_H):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(new_W):</span><br><span class="line">            <span class="comment"># 计算原图对应坐标（浮点数）</span></span><br><span class="line">            src_x = x / scale</span><br><span class="line">            src_y = y / scale</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取周围4个整数坐标点</span></span><br><span class="line">            x0, y0 = <span class="built_in">int</span>(np.floor(src_x)), <span class="built_in">int</span>(np.floor(src_y))</span><br><span class="line">            x1, y1 = <span class="built_in">min</span>(x0 + <span class="number">1</span>, W - <span class="number">1</span>), <span class="built_in">min</span>(y0 + <span class="number">1</span>, H - <span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取4个点的颜色值（z坐标）</span></span><br><span class="line">            s0 = img[y0, x0]</span><br><span class="line">            s1 = img[y0, x1]</span><br><span class="line">            s2 = img[y1, x0]</span><br><span class="line">            s3 = img[y1, x1]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算相对位置（归一化到[0,1]）</span></span><br><span class="line">            dx = src_x - x0</span><br><span class="line">            dy = src_y - y0</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 判断四点是否共面（z1 + z2 ≈ z0 + z3）</span></span><br><span class="line">            <span class="keyword">if</span> np.allclose(s1 + s2, s0 + s3, atol=<span class="number">1e-6</span>):</span><br><span class="line">                <span class="comment"># 共面时，选择任意平面（此处用左下平面）</span></span><br><span class="line">                interpolated = s0 + (s2 - s0) * dx + (s1 - s0) * dy</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 不共面时，动态选择平面</span></span><br><span class="line">                <span class="comment"># 获取周围12个参考点（简化实现，仅取最近邻）</span></span><br><span class="line">                <span class="comment"># 注：论文中需判断参考点是否共面，此处简化逻辑</span></span><br><span class="line">                <span class="keyword">if</span> dy &gt; <span class="number">1</span> - dx:  <span class="comment"># 对角线 y = 1 - x 上方</span></span><br><span class="line">                    <span class="comment"># 选择右上平面</span></span><br><span class="line">                    interpolated = (s3 - s1) * dx + (s3 - s2) * dy + (s2 + s1 - s3)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 选择左下平面</span></span><br><span class="line">                    interpolated = s0 + (s2 - s0) * dx + (s1 - s0) * dy</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 边界检查</span></span><br><span class="line">            interpolated = np.clip(interpolated, <span class="number">0</span>, <span class="number">255</span> <span class="keyword">if</span> img.dtype == np.uint8 <span class="keyword">else</span> <span class="number">1.0</span>)</span><br><span class="line">            output[y, x] = interpolated</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 四平面法插值实现图像旋转</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">four_plane_rotation</span>(<span class="params">image, angle</span>):</span><br><span class="line">    h, w, channel = image.shape</span><br><span class="line">    angle_rad = math.radians(angle)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算旋转后的图像尺寸</span></span><br><span class="line">    cos_theta = <span class="built_in">abs</span>(math.cos(angle_rad))</span><br><span class="line">    sin_theta = <span class="built_in">abs</span>(math.sin(angle_rad))</span><br><span class="line">    new_w = <span class="built_in">int</span>(h * sin_theta + w * cos_theta)</span><br><span class="line">    new_h = <span class="built_in">int</span>(h * cos_theta + w * sin_theta)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 旋转中心</span></span><br><span class="line">    cx, cy = w / <span class="number">2</span>, h / <span class="number">2</span></span><br><span class="line">    new_cx, new_cy = new_w / <span class="number">2</span>, new_h / <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    rotated_image = np.zeros((new_h, new_w, channel), dtype=image.dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(new_h):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(new_w):</span><br><span class="line">            <span class="comment"># 将新图像坐标转换回原图像坐标</span></span><br><span class="line">            x = (j - new_cx) * math.cos(angle_rad) + (i - new_cy) * math.sin(angle_rad) + cx</span><br><span class="line">            y = -(j - new_cx) * math.sin(angle_rad) + (i - new_cy) * math.cos(angle_rad) + cy</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 边界检查</span></span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= x &lt; w <span class="keyword">and</span> <span class="number">0</span> &lt;= y &lt; h:</span><br><span class="line">                <span class="comment"># 获取周围4个整数坐标点</span></span><br><span class="line">                x0, y0 = <span class="built_in">int</span>(np.floor(x)), <span class="built_in">int</span>(np.floor(y))</span><br><span class="line">                x1, y1 = <span class="built_in">min</span>(x0 + <span class="number">1</span>, w - <span class="number">1</span>), <span class="built_in">min</span>(y0 + <span class="number">1</span>, h - <span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取4个点的颜色值</span></span><br><span class="line">                s0 = image[y0, x0]</span><br><span class="line">                s1 = image[y0, x1]</span><br><span class="line">                s2 = image[y1, x0]</span><br><span class="line">                s3 = image[y1, x1]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 计算相对位置</span></span><br><span class="line">                dx = x - x0</span><br><span class="line">                dy = y - y0</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 判断四点是否共面</span></span><br><span class="line">                <span class="keyword">if</span> np.allclose(s1 + s2, s0 + s3, atol=<span class="number">1e-6</span>):</span><br><span class="line">                    <span class="comment"># 共面时，选择任意平面（此处用左下平面）</span></span><br><span class="line">                    interpolated = s0 + (s2 - s0) * dy + (s1 - s0) * dx</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 不共面时，动态选择平面</span></span><br><span class="line">                    <span class="keyword">if</span> dy &gt; <span class="number">1</span> - dx:  <span class="comment"># 对角线 y = 1 - x 上方</span></span><br><span class="line">                        <span class="comment"># 选择右上平面</span></span><br><span class="line">                        interpolated = (s3 - s1) * dx + (s3 - s2) * dy + (s2 + s1 - s3)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># 选择左下平面</span></span><br><span class="line">                        interpolated = s0 + (s2 - s0) * dy + (s1 - s0) * dx</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 边界检查</span></span><br><span class="line">                interpolated = np.clip(interpolated, <span class="number">0</span>, <span class="number">255</span> <span class="keyword">if</span> image.dtype == np.uint8 <span class="keyword">else</span> <span class="number">1.0</span>)</span><br><span class="line">                rotated_image[i, j] = interpolated</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> rotated_image</span><br></pre></td></tr></tbody></table></figure>

<h2 id="实验测试结果分析"><a href="#实验测试结果分析" class="headerlink" title="实验测试结果分析"></a>实验测试结果分析</h2><p>一个理想的插值算法对一幅图像逆时针旋转若干度，再顺时针旋转若干度，应该与原图像相同；同理，对一幅图像放大若干倍，再缩小若干倍，也应该与原图像相同。 基于此，将下面的4幅图像分别用4种算法先逆时针旋转45°，再顺时针旋转45°；先放大４倍，再缩小４倍，然后分别用峰值信噪比（PSNR）验证各算法的优劣。 </p>
<p><img src="/images/project2/5.jpg" alt="1琳娜"></p>
<p><img src="/images/project2/6.jpg" alt="2辣椒"></p>
<p><img src="/images/project2/7.jpg" alt="3狒狒"></p>
<p><img src="/images/project2/8.jpg" alt="4房子"></p>
<p>从定性实验的效果角度，上述四幅图像通过常用的三种分段插值算法完成上述的放大与旋转任务后得到的结果如下图所示：</p>
<p><img src="/images/project2/Figure_1.png" alt="1琳娜传统result"></p>
<p><img src="/images/project2/Figure_2.png" alt="2辣椒传统result"></p>
<p><img src="/images/project2/Figure_3.png" alt="3狒狒传统result"></p>
<p><img src="/images/project2/Figure_4.png" alt="4房子传统result"></p>
<p>从实验结果上来看，最近邻算法的边缘颜色“最醒目”，且出现了较为严重的“锯齿形”边缘现象；双线性算法的边缘颜色“最暗淡”；双线性算法和双三次算法也有“锯齿形”边缘现象， 但视觉效果相比最近邻算法而言并不明显。</p>
<p>通过改进的四平面插值算法，对上述四幅图像完成上述的放大与旋转任务后得到的结果如下图所示：</p>
<p><img src="/images/project2/Figure_5.png" alt="1琳娜四平面result"></p>
<p><img src="/images/project2/Figure_6.png" alt="2辣椒四平面result"></p>
<p><img src="/images/project2/Figure_7.png" alt="3狒狒四平面result"></p>
<p><img src="/images/project2/Figure_8.png" alt="4房子四平面result"></p>
<p>可以看到，四平面插值算法处理后的图像斜线边缘部分是 “光滑连续” 的， 视觉效果比较好，同时有效避免了“锯齿形”边缘现象和“马赛克”现象。</p>
<p>从定量实验的数据角度，我们对于各图像用不同算法完成上述旋转与放缩任务后得到的图像峰值信噪比与算法运行时间进行了计算与统计，结果如下表所示：</p>
<blockquote>
<p>峰值信噪比(PSNR)用于表示信号的最大可能功率与影响其表示的保真度的破坏噪声的功率之间的比率。PSNR在图像处理上主要用于量化受有损压缩影响的图像和视频的重建质量。</p>
<p>PSNR 通过均方误差( MSE ) 定义。</p>
<p>给定一个无噪声的m×n单色图像I及其噪声近似值K，MSE定义为：<br>$$<br>MSE=\frac{1}{mn}\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}[I(i,j)-K(i,j)]^2.<br>$$<br>故PSNR定义为：<br>$$<br>\begin{aligned}\mathrm{PSNR}&amp;=10\cdot\log_{10}\left(\frac{MAX_I^2}{MSE}\right)\&amp;=20\cdot\log_{10}\left(\frac{MAX_I}{\sqrt{MSE}}\right)\&amp;=20\cdot\log_{10}(MAX_I)-10\cdot\log_{10}(MSE).\end{aligned}<br>$$<br>一般而言，通过PSNR来判断处理后图像的失真情况有如下通用结论：</p>
<ul>
<li>PSNR &gt; 30 dB：图像质量较好，失真不明显。</li>
<li>PSNR 20~30 dB：中等质量，存在可察觉失真。</li>
<li>PSNR &lt; 20 dB：质量较差，失真显著。</li>
</ul>
<p>实际计算时，采用opencv自带的PSNR方法cv2.PSNR(img, output)对原始图像与处理后图像的PSNR进行比较计算。</p>
</blockquote>
<table>
<thead>
<tr>
<th>测试图像</th>
<th>最近邻插值PSNR</th>
<th>双线性插值PSNR</th>
<th>双立方插值PSNR</th>
<th>四平面插值PSNR</th>
</tr>
</thead>
<tbody><tr>
<td>琳娜（269*269）</td>
<td>20.74217399</td>
<td>27.11906575</td>
<td>29.36532325</td>
<td>36.70765842</td>
</tr>
<tr>
<td>辣椒（268*268）</td>
<td>22.92424674</td>
<td>27.91435345</td>
<td>31.04713312</td>
<td>39.25866529</td>
</tr>
<tr>
<td>狒狒（268*268）</td>
<td>21.8194312</td>
<td>28.06968286</td>
<td>29.12614241</td>
<td>38.2193871</td>
</tr>
<tr>
<td>房子（256*256）</td>
<td>22.34146151</td>
<td>26.21366716</td>
<td>30.67389681</td>
<td>38.8204405</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>插值算法</th>
<th>最近邻法</th>
<th>双线性法</th>
<th>双立方法</th>
<th>四平面法</th>
</tr>
</thead>
<tbody><tr>
<td>算法运行平均用时</td>
<td>0.678485751</td>
<td>3.293492556</td>
<td>92.66596091</td>
<td>15.02119243</td>
</tr>
</tbody></table>
<p>通过对比上述定量实验结果可以发现，在传统的三种分段插值算法中，随着运算阶数（采样待插值点周围的原图像像素点颜色值信息）的增加，图像经过放缩与旋转处理后的失真程度有明显降低，但仍大致处于存在可察觉失真的区间，且算法运行用时也逐渐增加（事实上双立方法的实现可以在编程层面实现优化，这里只是为更直观地展现O（n^2）时间复杂度在图像大小达到一定规模时的显著影响）；而引入的四平面算法不仅在失真程度上较传统的插值算法均有显著改善，算法运行用时也明显优于传统算法中效果最好的双立方法。</p>
<p>综合以上的定性与定量实验结果及分析，本文提出的基于四平面的图像插值算法在图像处理效果（失真）与运行效率上均较传统算法有明显提升，这充分证明了该算法的有效性。</p>
<p>将上文提到的全部四种算法及旋转与放缩两种功能集成到基于python的gui可视化系统中，并打包成exe可执行文件，制作了一个基于插值的图像处理系统，基本功能演示如下图所示：</p>
<p><img src="/images/project2/1.png" alt="gui演示1"></p>
<p><img src="/images/project2/2.png" alt="gui演示2"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 王开荣,杨大地编著.应用数值分析[M].高等教育出版社,2010.</p>
<p>[2] 毛伟伟,于素萍,石念峰.一种基于四平面的图像插值算法[J].洛阳理工学院学报(自然科学版),2024,34(01):76-81.</p>
<p>[3] 刘显德,李笑.任意大小图像的量子描述及双线性插值方法[J].计算机工程与设计,2024,45(08):2423-2432.</p>
<p>[4] 张喜民,詹海生.基于双三次插值的Canny-Devernay亚像素图像边缘检测算法[J].现代制造工程,2025,(03):107-114.</p>
<p>[5] 陈玲玲,周宁,殷永,等.插值方法在光声图像重建中的应用[J].计算机与数字工程,2013,41(10):1676-1677+1694.</p>
</div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2025-01-04T17:02:03.000Z" title="2025/1/5 01:02:03">2025-01-05</time>发表</span><span class="level-item"><time datetime="2025-03-01T18:06:45.232Z" title="2025/3/2 02:06:45">2025-03-02</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a><span>&nbsp;/&nbsp;</span><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">智能图像处理</a></span><span class="level-item">1 小时读完 (大约7630个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/01/05/graph/">基于自编码器和卷积网络的肺炎图像识别</a></p><div class="content"><div id="postchat_postcontent"><h2 id="1-项目背景与研究意义"><a href="#1-项目背景与研究意义" class="headerlink" title="1 项目背景与研究意义"></a>1 项目背景与研究意义</h2><h3 id="1-1-项目背景"><a href="#1-1-项目背景" class="headerlink" title="1.1 项目背景"></a>1.1 项目背景</h3><p>肺炎作为一种常见的呼吸系统疾病，对人类健康构成了长期威胁，特别是随着COVID-19新冠肺炎疫情的全球爆发，其公共健康影响更为显著。COVID-19肺炎具有传播速度快、感染范围广、诊断难度大的特点，对全球医疗系统和社会经济产生了深远影响。特别是在疫情高峰期，医疗资源的短缺和诊断效率的瓶颈，进一步突显了快速、准确诊断工具的重要性。</p>
<p>传统肺炎诊断方法主要依赖医生对胸部X光片或CT图像的人工分析，既耗时又容易受到经验和疲劳的影响，尤其在COVID-19疫情期间，大量影像数据的涌现使得人工诊断难以满足需求。与此同时，COVID-19的影像表现与其他类型肺炎的重叠性增加了诊断的复杂性，这进一步加剧了对智能化诊断系统的需求。</p>
<p>随着人工智能技术的快速发展，深度学习为医疗影像分析带来了全新的解决方案。卷积神经网络（Convolutional Neural Network, CNN）凭借其强大的图像特征提取能力，在自动化诊断中展现了巨大潜力。同时，由于不同医疗机构的CT扫描设备性能差异显著，特别是在医疗资源较为匮乏的地区，CT影像常常受到设备老化、分辨率低或操作不规范等因素的影响，图像质量参差不齐，这不仅增加了诊断的复杂性，还对自动化系统的鲁棒性提出了更高要求；而自编码器（Autoencoder）作为一种有效的降噪工具，为医疗影像数据预处理提供了重要支持。通过自编码器的引入，可以有效消除图像中的噪声干扰，减少不同设备间的成像差异，为后续的分类和识别模型提供高质量的输入数据。因此，本项目提出结合自编码器和卷积神经网络的深度学习框架，开发一套针对肺炎（包括COVID-19）CT影像识别的智能诊断系统。</p>
<p><img src="/images/graph/media/image1.jpeg" alt="图1.1：新冠肺炎疫情概况（主要症状、防治措施与传播状况）"></p>
<p><img src="/images/graph/media/image2.jpeg" alt="图1.2：新冠肺炎患者的肺部CT影像"></p>
<h3 id="1-2-研究意义"><a href="#1-2-研究意义" class="headerlink" title="1.2 研究意义"></a>1.2 研究意义</h3><p>本项目以新型冠状病毒肺炎为切入点，面向未来医学智能化需求，开发的诊断系统不仅能够应对当下疫情挑战，还具有推广至其他医学影像诊断场景的潜力，从而为全球公共健康事业的发展提供有力支持。</p>
<p>面向新冠肺炎疫情期间大规模肺部影像数据的快速诊断需求，本系统依托深度学习技术，有效提升了诊断效率，为疫情防控和患者管理提供重要的技术支持。通过先进的模型算法，系统能够精准识别肺部CT影像中的病变特征，减少人为误差，确保诊断结果的准确性和一致性，大幅降低不同医疗机构和医生之间的诊断差异，避免误诊和漏诊风险，从而更好地保障患者安全。</p>
<p>针对基层医院或偏远地区医疗资源匮乏的现状，本系统可作为一种可靠的辅助诊断工具，为医生提供科学的决策支持，帮助缓解诊断能力不足带来的压力。其高效的处理能力不仅提高了基层医疗服务水平，也为疫情防控的全面推进提供了技术保障，为应对紧急医疗需求的地区解决实际困难。</p>
<p>此外，本系统在高效处理和分析海量肺部CT影像数据的基础上，还为研究新冠肺炎的病理特征及流行规律提供了宝贵的数据支持。这些分析结果可进一步应用于疫情传播趋势预测和公共卫生政策制定，为疫情防控策略的科学性和有效性奠定了坚实基础。</p>
<p>同时，本系统也为患者病情的动态管理提供了重要帮助。通过智能分析新冠肺炎影像特征的变化趋势，系统能够为临床医生提供精确的病情评估建议，有助于及时调整治疗方案。这种基于影像数据的技术支持，不仅提高了患者管理的科学性和有效性，还为医疗资源的合理分配提供了重要依据，进一步推动了疫情防控工作的高效开展。</p>
<h2 id="2-数据集获取与预处理"><a href="#2-数据集获取与预处理" class="headerlink" title="2 数据集获取与预处理"></a>2 数据集获取与预处理</h2><h3 id="2-1-数据集介绍"><a href="#2-1-数据集介绍" class="headerlink" title="2.1 数据集介绍"></a>2.1 数据集介绍</h3><p>本项目使用的肺部X-光片数据集从Kaggle网站（链接：<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/alsaniipe/chest-x-ray-image">https://www.kaggle.com/datasets/alsaniipe/chest-x-ray-image</a>）获取，共分为三类标签：新冠肺炎COVID19、正常NORMAL和普通肺炎PNEUMONIA，该数据集已经事先划分好了训练集与测试集。此外，为测试模型对于不同质量CT影像的识别精度，还对测试集中的部分图像使用高斯噪声进行扰动，以模拟实际CT扫描的成像质量差异。</p>
<p><img src="/images/graph/media/image3.png" alt="图2.1：肺部CT影像数据集概况"><br><img src="/images/graph/media/image4.png" alt="图2.2：肺部CT影像数据集概况"></p>
<p><img src="/images/graph/media/image5.png" alt="图2.3：数据集中部分肺部CT影像展示（上行为训练集（干净），下行为含噪声测试集）"></p>
<p>数据分布如下表所示：</p>
<p>表2.1：数据集数据分布情况</p>
<table>
<thead>
<tr>
<th></th>
<th>COVID19</th>
<th>NORMAL</th>
<th>PNEUMONIA</th>
</tr>
</thead>
<tbody><tr>
<td>Train</td>
<td>460</td>
<td>1266</td>
<td>3418</td>
</tr>
<tr>
<td>Test</td>
<td>116</td>
<td>317</td>
<td>855</td>
</tr>
<tr>
<td>Noisy_Test</td>
<td>26</td>
<td>20</td>
<td>20</td>
</tr>
</tbody></table>
<h3 id="2-2-编程环境搭建"><a href="#2-2-编程环境搭建" class="headerlink" title="2.2 编程环境搭建"></a>2.2 编程环境搭建</h3><p>本项目中所有的代码编写与运行均是在配备NVIDIA GeForce RTX 3060显卡、16GB运行内存、12th Gen Inter(R) Core(TM) <a href="mailto:i7-12700@2.10GHz">i7-12700@2.10GHz</a>处理器与Microsoft Windows 11操作系统的工作站上使用Python编程语言完成的。</p>
<p>软件环境方面，采用Conda进行环境管理，在控制台中通过命令”conda create -n covid python=3.12”创建虚拟环境，并在激活环境后使用pip install命令依次安装所需的各种依赖库；全部安装并测试完成后，通过命令”pip freeze &gt;<br>requirements.txt”将虚拟环境中安装的所有依赖库及对应版本写入文件requirements.txt，后续移植时可在新的运行环境中运行命令”pip install -r requirements.txt”完成环境的一键配置。</p>
<p>值得注意的是，在PyTorch（包括torch、torchvision与torchaudio库）安装时需要根据自己电脑使用的CUDA版本（使用CPU则直接在命令行中使用pip install安装即可）在<a target="_blank" rel="noopener" href="https://pytorch.org/">PyTorch官网</a>中找到对应的安装命令进行安装。我使用的CUDA版本为12.6，安装命令的选取如下图所示：</p>
<p><img src="/images/graph/media/image6.png" alt="图2.4：PyTorch官网获取对应CUDA版本的安装命令"></p>
<p>下面对于项目中使用到的主要依赖库进行简要介绍：</p>
<p><img src="/images/graph/media/image7.png" alt="图2.5：项目中使用的主要依赖库"></p>
<p>其中，plt用于绘图，nn中包含了用于构建神经网络的隐藏层（全连接层、卷积层等），F中包含了各种激活函数（ReLu、Sigmoid等），DataLoader用于在训练时加载数据，datasets和transforms用于读取和处理数据集，tqdm用于进度条可视化，torchmetrics用于模型精度的测试，torchviz和torchsummary用于以图形与文字的方式描述模型架构概况。</p>
<h3 id="2-3-图像数据读取"><a href="#2-3-图像数据读取" class="headerlink" title="2.3 图像数据读取"></a>2.3 图像数据读取</h3><p>torch对于一些常用的数据集做了封装，可以直接调用，例如datasets.MNIST()。但此处我们使用的是本地的图片数据，可以使用ImageFolder将一个文件夹下的图片读取成数据集并完成数据增强工作。在读取完数据集后，还需要定义DataLoader用于加载数据为可分批次（batch）读取的迭代器以供后续使用。为使得代码更加简洁，将上述的数据读取与加载过程为封装在getDataLoader函数中，并在主函数中通过指定不同的目录加载训练集、测试集或是含噪声测试集。</p>
<p><img src="/images/graph/media/image8.png" alt="图2.6：数据加载函数getDataLoader代码"></p>
<p>可以看到，其中构建了数据增强器transform，在读取数据时进行相应处理：</p>
<ul>
<li><p>Grayscale: 指以灰度图的形式读取。</p>
</li>
<li><p>Resize: 由于图像尺寸各不相同，在训练前需将它们重塑成相同尺寸256*256。</p>
</li>
<li><p>ToTensor: 将图片格式转换成张量形式，torch的计算以张量的形式进行。</p>
</li>
</ul>
<p>除此之外，在构建数据加载器时需要指定一个批次（batch）中的图片数据数量batch_size，在模型训练时训练批次大小TRAIN_BATCH_SIZE也是会影响最终模型性能的重要超参数之一。在训练过程中，设定TRAIN_BATCH_SIZE为32，而在测试过程中，为提高测试效率，将TEST_BATCH_SIZE设置为66并对函数进行对应修改。</p>
<h3 id="2-4-叠加噪声函数"><a href="#2-4-叠加噪声函数" class="headerlink" title="2.4 叠加噪声函数"></a>2.4 叠加噪声函数</h3><p>不论是构建噪声测试集，还是在利用无噪声的训练集进行训练时，都需要手动添加噪声，故编写add_noise函数，默认的噪声强度为0.5，并在添加噪声后进行归一化以确保图像值位于[0,1]范围内。</p>
<p><img src="/images/graph/media/image9.png" alt="图2.7：加噪函数add_noise代码"></p>
<p><img src="/images/graph/media/image10.JPG" alt="图2.8：加噪前后效果对比"></p>
<h2 id="3-模型构建与网络训练"><a href="#3-模型构建与网络训练" class="headerlink" title="3 模型构建与网络训练"></a>3 模型构建与网络训练</h2><h3 id="3-1-整体模型框架"><a href="#3-1-整体模型框架" class="headerlink" title="3.1 整体模型框架"></a>3.1 整体模型框架</h3><p>整体模型框架由两个核心部分组成，分别是用于去噪的数据预处理模块和负责分类的卷积神经网络（CNN）。去噪模块采用自编码器（Autoencoder）的架构，专注于从输入数据中去除噪声，以提升后续分类的准确性；分类模块基于卷积神经网络，其强大的特征提取和模式识别能力使其成为分类任务的理想选择。</p>
<p>两个模块相辅相成，通过有效的数据处理和特征提取，确保模型能够在噪声干扰较大的环境中实现高精度分类。噪声数据首先经过自编码器处理，生成质量优化的特征表示，然后被CNN接收并完成分类任务。这一整体框架设计非常适合肺炎图像识别任务，通过结合去噪和分类两大模块的优势，模型不仅能够有效提高数据质量，还能充分挖掘数据中的有用特征，从而能够在复杂的医学影像处理中表现出卓越的鲁棒性和准确性，满足肺炎诊断的实际需求。</p>
<p><img src="/images/graph/media/image11.png" alt="图3.1：模型框架图示"></p>
<h3 id="3-2-自编码器"><a href="#3-2-自编码器" class="headerlink" title="3.2 自编码器"></a>3.2 自编码器</h3><p>自编码器模型用于处理输入数据中的噪声问题，提升后续分类的准确性。其核心思想是通过编码器将输入数据压缩至低维潜在表示（latent representation），再由解码器将其还原至去噪后的重构数据，从而实现降噪效果。</p>
<h4 id="3-2-1-网络结构设计"><a href="#3-2-1-网络结构设计" class="headerlink" title="3.2.1 网络结构设计"></a>3.2.1 网络结构设计</h4><p><img src="/images/graph/media/image12.png" alt="图3.2：自编码器模型结构"></p>
<p>自编码器网络结构由编码器encoder与解码器decoder组成：</p>
<ul>
<li><p>编码器由两层卷积（Conv2d）和两次池化（MaxPool2d）操作组成，用于提取特征；</p>
</li>
<li><p>解码器通过两次反卷积（ConvTranspose2d）和两次上采样（UpsamplingNearest2d）逐步恢复图像尺寸到原始大小；</p>
</li>
<li><p>最后使用Sigmoid激活函数将输出值限制在[0,1]区间。</p>
</li>
</ul>
<p>模型定义代码如下：</p>
<p><img src="/images/graph/media/image13.png" alt="图3.3：自编码器模型定义代码"></p>
<p>模型继承自nn.Module类，在__init__()函数中定义模型的结构，在forward()函数中定义模型的前向传播过程。</p>
<p>通过调用torchviz和torchsummary库，可以输出该模型结构的基本信息：</p>
<p><img src="/images/graph/media/image14.png" alt="图3.4：调用torchsummary库输出自编码器网络结构的文字信息"></p>
<p><img src="/images/graph/media/image15.JPG" alt="图3.5：调用torchviz库输出自编码器网络结构的架构图示"></p>
<h4 id="3-2-2-模型训练"><a href="#3-2-2-模型训练" class="headerlink" title="3.2.2 模型训练"></a>3.2.2 模型训练</h4><p>基本的训练流程集成在函数train_autoencoder_process中，如下图所示：</p>
<p><img src="/images/graph/media/image16.png" alt="图3.6：自编码器模型训练函数train_autoencoder_process代码"></p>
<p>其中指定优化器optimizer为Adam，损失函数为均方误差MSE，并使用超参数：训练轮数Epochs=50、学习率lr=0.001。每轮（Epoch）训练中均需要以多个batch的形式遍历训练集中的所有数据，并在每个batch后对模型进行更新，具体而言每次更新均需执行如下操作：</p>
<ul>
<li><p>从加载器中获取输入数据</p>
</li>
<li><p>使用add_noise函数对干净图像加噪</p>
</li>
<li><p>将加噪后图像输入自编码器模型并计算模型输出</p>
</li>
<li><p>根据模型输出和标签计算损失Loss</p>
</li>
<li><p>清空梯度</p>
</li>
<li><p>反向传播</p>
</li>
<li><p>更新模型</p>
</li>
</ul>
<p>值得注意的是，由于用于训练的图像数据没有噪声，因此训练时首先需要对输入的图像进行加噪处理，再输入自编码器模型进行训练。</p>
<p>训练过程中还利用tqdm进度条函数对训练进程进行可视化，并在每轮训练完成后打印出当轮训练过程中模型的平均损失：</p>
<p><img src="/images/graph/media/image17.png" alt="图3.7：自编码器模型训练过程进度条（前5个Epoch）"></p>
<p>在训练过程中，将每轮训练的平均损失存储在列表中，并在训练结束后将平均损失的变化过程以图像形式呈现：</p>
<p><img src="/images/graph/media/image18.JPG" alt="图3.8：自编码器模型训练损失变化"></p>
<p>可以看到，经过多轮训练，模型的损失函数值在不断减小且逐渐趋近于0，这意味着该自编码器的模型训练过程是收敛的，模型具有较稳定的工作性能。</p>
<h3 id="3-3-卷积神经网络"><a href="#3-3-卷积神经网络" class="headerlink" title="3.3 卷积神经网络"></a>3.3 卷积神经网络</h3><p>卷积神经网络负责从图像中提取多层次的空间特征，通过逐步减少图像尺寸和增加特征通道来捕捉关键信息，从而实现去噪后肺部CT图像的分类功能。CNN以其强大的特征提取能力，能够有效处理图像的局部依赖性和空间不变性，高效处理结构化数据（如图像、时序数据）。模型简单且高效，具有较强的泛化能力，适合处理小规模数据集的图像分类问题。</p>
<h4 id="3-3-1-网络结构设计"><a href="#3-3-1-网络结构设计" class="headerlink" title="3.3.1 网络结构设计"></a>3.3.1 网络结构设计</h4><p><img src="/images/graph/media/image19.png" alt="图3.9：卷积神经网络模型结构"></p>
<p>卷积神经网络结构（如上图，通过<a target="_blank" rel="noopener" href="http://alexlenail.me/NN-SVG/AlexNet.html">NN-SVG工具</a>绘制）由两层卷积层（Conv2d）和池化层（MaxPool2d）组成，激活函数均选用ReLU，逐步提取特征并将输入图像的尺寸从原始大小减小到64×64。卷积后的特征图展平后通过三个全连接层（Linear），分别将特征维度从32×64×64降至128，再降至32，最后输出3个类别（Covid19、Normal、Pneumonia）的预测结果。</p>
<p>模型定义代码如下：</p>
<p><img src="/images/graph/media/image20.png" alt="图3.10：卷积神经网络模型定义代码"></p>
<p>模型继承自nn.Module类，在__init__()函数中定义模型的结构，在forward()函数中定义模型的前向传播过程。</p>
<p>通过调用torchviz和torchsummary库，可以输出该模型结构的基本信息：</p>
<p><img src="/images/graph/media/image21.png" alt="图3.11：调用torchsummary库输出卷积神经网络结构的文字信息"></p>
<p><img src="/images/graph/media/image22.png" alt="图3.12：调用torchviz库输出卷积神经网络结构的架构图示"></p>
<h4 id="3-3-2-模型训练"><a href="#3-3-2-模型训练" class="headerlink" title="3.3.2 模型训练"></a>3.3.2 模型训练</h4><p>基本的训练流程集成在函数train_cnn_process中，如下图所示：</p>
<p><img src="/images/graph/media/image23.png" alt="图3.13：卷积神经网络模型训练函数train_cnn_process代码"></p>
<p>其中指定优化器optimizer为Adam，损失函数为交叉熵损失CrossEntropy，并使用超参数：训练轮数Epochs=50、学习率lr=0.001。每轮（Epoch）训练中均需要以多个batch的形式遍历训练集中的所有数据，并在每个batch后对模型进行更新，具体而言每次更新均需执行如下操作：</p>
<ul>
<li><p>从加载器中获取输入数据</p>
</li>
<li><p>使用add_noise函数对干净图像加噪</p>
</li>
<li><p>将加噪后图像输入训练好的自编码器模型trained_autoencoder_model</p>
</li>
<li><p>将经过自编码器去噪后的图像输入CNN模型并计算模型输出</p>
</li>
<li><p>根据模型输出和标签计算损失Loss</p>
</li>
<li><p>清空梯度</p>
</li>
<li><p>反向传播</p>
</li>
<li><p>更新模型</p>
</li>
</ul>
<p>值得注意的是，由于用于训练的图像数据没有噪声，为与实际的输入情况一致，首先需要对输入的图像进行加噪处理，再利用训练好的自编码器模型进行降噪（为了不在更新CNN的同时更新自编码器，这一步不需要产生梯度），才能输入CNN分类模型进行训练。</p>
<p>训练过程中还利用tqdm进度条函数对训练进程进行可视化，并在每轮训练完成后打印出当轮训练过程中模型的平均损失与在训练集上的测试精度：</p>
<p><img src="/images/graph/media/image24.png" alt="图3.14：卷积神经网络模型训练过程进度条（最后5个Epoch）"></p>
<p>在训练过程中，将每轮训练的平均损失与模型在训练集上的测试精度存储在列表中，并在训练结束后将两者的变化过程以图像形式呈现：</p>
<p><img src="/images/graph/media/image25.png" alt="图3.15：卷积神经网络模型训练损失变化"></p>
<p><img src="/images/graph/media/image26.png" alt="图3.16：卷积神经网络模型训练过程中在训练集上的精度变化"></p>
<p>可以看到，经过多轮训练，模型的损失函数值在不断减小且逐渐趋近于0，这意味着该自编码器的模型训练过程是收敛的，模型具有较稳定的工作性能；同时随着训练轮数增加，模型在训练集上的精度也逐渐增高（波动上升），在模型训练完成时，卷积神经网络在训练集上的分类精度已经可以达到99.59%（一度达到99.90%），接近百分之百，说明模型的分类能力较好。</p>
<h2 id="4-模型测试及应用"><a href="#4-模型测试及应用" class="headerlink" title="4 模型测试及应用"></a>4 模型测试及应用</h2><h3 id="4-1-自编码器降噪效果"><a href="#4-1-自编码器降噪效果" class="headerlink" title="4.1 自编码器降噪效果"></a>4.1 自编码器降噪效果</h3><p>在自编码器模型的训练过程中，每隔10轮对模型参数进行了一次存档；在测试过程中，分别使用训练轮数为10、20、30、40、50的自编码器模型对于加噪后的模型进行降噪处理，效果如下图所示：</p>
<p><img src="/images/graph/media/image27.png" alt="图4.1：训练轮数Epoch=10的自编码器模型降噪效果"></p>
<p><img src="/images/graph/media/image28.png" alt="图4.2：训练轮数Epoch=20的自编码器模型降噪效果"></p>
<p><img src="/images/graph/media/image29.png" alt="图4.3：训练轮数Epoch=30的自编码器模型降噪效果"></p>
<p><img src="/images/graph/media/image30.png" alt="图4.4：训练轮数Epoch=40的自编码器模型降噪效果"></p>
<p><img src="/images/graph/media/image31.png" alt="图4.5：训练轮数Epoch=50的自编码器模型降噪效果"></p>
<p>通过对比不同训练轮数的自编码器模型降噪效果可以发现，随着训练轮数的增加，自编码器模型的降噪效果在逐渐提升，但在Epoch到达30之后，训练带来的降噪效果提升就不如先前显著了。尽管由于较大的噪声强度（0.5）导致降噪后的图像仍然比较模糊，但通过肉眼还是能粗略观察处肺部骨骼的轮廓等特征，后续实验也证明了卷积神经网络确实可以从这样清晰度的图像中提取相应的特征来进行分类，该自编码器模型的设计有效。</p>
<h3 id="4-2-卷积神经网络分类精度"><a href="#4-2-卷积神经网络分类精度" class="headerlink" title="4.2 卷积神经网络分类精度"></a>4.2 卷积神经网络分类精度</h3><p>在卷积神经网络的分类精度上，训练过程中已经实时对于每一轮训练后的模型在训练集上进行了精度测试（3.2.2节中已有提及），而在测试集上，可以编写与训练过程类似的代码利用torchmetrics库对模型分类精度进行测试，只是不会更新模型，代码如下：</p>
<p><img src="/images/graph/media/image32.png" alt="图4.6：卷积神经网络分类精度在测试集上的测试函数代码"></p>
<p>可以看到，由于我们的测试集分为含噪声和不含噪声两类，因此编写了不同的函数对模型分类精度进行测试。两个函数的主要差别就在于，由于含噪声测试集是已经加噪的图片（噪声与手动通过add_noise函数添加的不同），因此在含噪声测试集的测试代码中不必再次手动添加噪声，而是直接将图像输入自编码器降噪后再输入CNN分类模型中进行分类；而对于不含噪声的测试集而言，为模拟与训练集同样的处理流程，会先进行手动加噪再通过自编码器降噪之后才输入CNN分类模型中进行分类。</p>
<p>运行测试代码后，得到模型在含噪测试集上的分类精度为96.97%，在不含噪声的测试集上的分类精度为94.57%，在两个测试集上的分类精度水平均较高，说明该模型具有良好的分类效果。</p>
<h3 id="4-3-模型应用：基于CT影像的肺炎诊断Web服务"><a href="#4-3-模型应用：基于CT影像的肺炎诊断Web服务" class="headerlink" title="4.3 模型应用：基于CT影像的肺炎诊断Web服务"></a>4.3 模型应用：基于CT影像的肺炎诊断Web服务</h3><p>通过对比多组超参数的模型降噪与分类效果，最终选定如下的超参数：</p>
<ul>
<li><p>训练轮数Epochs=50；</p>
</li>
<li><p>学习率LR=0.001；</p>
</li>
<li><p>训练批次大小Train_Batch_Size=32。</p>
</li>
</ul>
<p>选定参数后，将整体代码抽离为model.py（包含模型定义类代码），run.py（服务端代码）和train.py（训练函数），并将模型部署到实际应用中，使用Flask作为服务端，以Web形式用户提供操作接口以上传图片进行诊断。由于主要功能是提供接口，故网页只做了很简易的一个index.html，给用户提供上传图片的按钮，并在用户上传有噪声的CT影像后返回诊断结果及去噪后的图像。除此之外，还将挂载在本地端口上的Web通过内网穿透映射到公网，以供实时访问。</p>
<p>网页初始界面如下图所示：</p>
<p><img src="/images/graph/media/image33.png" alt="图4.7：网页初始界面"></p>
<p>接下来分别测试当输入COVID19、NORMAL和PNEUMONIA三个组别的图片，模型能否正确判断：</p>
<p><img src="/images/graph/media/image34.png" alt="图4.8：输入类型为COVID19，识别为COVID19（正确）"></p>
<p><img src="/images/graph/media/image35.png" alt="图4.9：输入类型为COVID19，识别为PNEUMONIA（错误）"></p>
<p><img src="/images/graph/media/image36.png" alt="图4.10：输入类型为NORMAL，识别为NORMAL（正确）"></p>
<p><img src="/images/graph/media/image37.png" alt="图4.11：输入类型为PNEUMONIA，识别为PNEUMONIA（正确）"></p>
<p>可以发现，模型在大多数情况下可以正确识别图像来源，但也会出现错误识别的情况，这和Test 集上的Accuracy相符合；此外，在测试时还注意到，模型识别结果偶尔会出现不稳定的现象，即输入同一张图像有时识别为某一类别，有时又会识别为另一类别，这是由模型内部部分随机参数导致的，这也反映了模型在一些模棱两可的情况下（两类别概率接近）做出判断时的不稳定性。在实际应用中，为尽可能减少误诊对于患者带来的各方面影响，还需要采取更多优化措施提升模型性能，并对模型在模棱两可的情况下做出的判断进行合理的限制。</p>
<h2 id="5-总结与展望"><a href="#5-总结与展望" class="headerlink" title="5 总结与展望"></a>5 总结与展望</h2><p>本项目全部代码（不包含数据集）已上传至Github仓库，仓库URL地址：<a target="_blank" rel="noopener" href="https://github.com/Asgard-Tim/Pneumonia-Image-Recognition">https://github.com/Asgard-Tim/Pneumonia-Image-Recognition</a></p>
<h3 id="5-1-项目总结"><a href="#5-1-项目总结" class="headerlink" title="5.1 项目总结"></a>5.1 项目总结</h3><p>本项目基于深度学习技术，结合自编码器和卷积神经网络，开发了一套智能诊断系统，用于快速、高效地识别肺部的CT影像并判断该患者是否患有肺炎（包括COVID-19）。自编码器模块有效去除了噪声，提升了图像质量，而卷积神经网络以其强大的特征提取能力，实现了高精度的分类。本项目在数据预处理、模型设计、网络训练及测试等环节中均采用了创新性的技术方案，最终实现了在含噪声测试集上96.97%和在无噪声测试集上94.57%的分类精度，表现出了较高的鲁棒性和实用价值。同时，系统已通过Flask框架部署为Web服务，能够实时接收CT影像并给出诊断结果，为疫情期间大规模影像数据的快速诊断及基层医疗资源匮乏地区的医疗支持提供了重要的技术保障。</p>
<h3 id="5-2-课程收获与反思"><a href="#5-2-课程收获与反思" class="headerlink" title="5.2 课程收获与反思"></a>5.2 课程收获与反思</h3><p>本次选修《智能图像处理》这门课程确实让我学到了很多东西，其实自己之前也自己看过一些机器学习方面的内容，有一定的知识基础与环境搭建经验，但由于各方面原因总是没有系统性的去学习计算机视觉的相关知识，也缺乏足够的实战代码与项目经验。通过这门课程的学习，很大程度上锻炼了我Python的代码能力，也在Coding的过程中不断熟悉OpenCV、Pytorch等库的使用，更在实践的过程中不断加深对于各种算法模型（AlexNet、ResNet、YOLO等）的理解。</p>
<p>本次项目让我完整地经历了从数据集获取、论文调研及算法代码实现，再到代码调试与模型训练测试，最终将模型应用到实际系统中的全过程，在项目实现的过程中收获了很多课程教学与实验中涉及不到的东西，包括数据集的收集、模型的选择以及作为一个完整项目的代码实现等等多个方面，这也是我第一次使用GPU资源去进行。虽然由于时间等条件的限制，在模型选择上并没有进行深入的调研与充分的对比试验，只是基于自己已知的一些知识对于架构较为简单的自编码器模型与卷积神经网络进行了复现与设计，最终模型的分类精度还有一定的提升空间，但是这也为我后续的自主学习打下了一个良好的基础，希望未来我能在计算机视觉方面有更加深入的学习与探索，也感谢老师的耐心指导与悉心教学。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Nosa-Omoruyi M, Oghenekaro L U. AutoEncoder Convolutional Neural Network for Pneumonia Detection[J]. arXiv preprint arXiv:2409.02142, 2024.</p>
<p>[2] Ratiphaphongthon W, Panup W, Wangkeeree R. An improved technique for pneumonia infected patients image recognition based on combination algorithm of smooth generalized pinball SVM and variational autoencoders[J]. IEEE Access, 2022, 10: 107431-107445.</p>
<p>[3] Gayathri J L, Abraham B, Sujarani M S, et al. A computer-aided diagnosis system for the classification of COVID-19 and non-COVID-19 pneumonia on chest X-ray images by integrating CNN with sparse autoencoder and feed forward neural network[J]. Computers in biology and medicine, 2022, 141: 105134.</p>
<p>[4] García-Ordás M T, Benítez-Andrades J A, García-Rodríguez I, et al. Detecting respiratory pathologies using convolutional neural networks and variational autoencoders for unbalancing data[J]. Sensors, 2020,20(4): 1214.</p>
<p>[5] Xia Y. Enhanced Pneumonia Detection in Chest X-Rays Based on Integrated Denoising Autoencoders and Convolutional Neural Networks[J].</p>
<p>[6] El-Shafai W, El-Nabi S A, El-Rabaie E S M, et al. Efficient Deep-Learning-Based Autoencoder Denoising Approach for Medical Image Diagnosis[J]. Computers, Materials &amp; Continua, 2022, 70(3).</p>
<p>[7] Rana N, Marwaha H. Auto encoder-guided Feature Extraction for Pneumonia Identification from Chest X-ray Images[C]//E3S Web of Conferences. EDP Sciences, 2024, 556: 01011.</p>
<p>[8] Ankayarkanni B, Sangeetha P. An Autoencoder-BiLSTM framework for classifying multiple types of lung diseases from CXR images[J]. Multimedia Tools and Applications, 2024: 1-30.</p>
<p>[9] 孙敬,丁嘉伟,冯光辉.一种基于自编码器降维的神经卷积网络入侵检测模型[J/OL].电信科学,1-7[2025-01-05].</p>
<p>[10] 张淙越,杨晓玲.基于卷积神经网络的新冠肺炎CT图像识别系统[J].电脑与信息技术,2022,30(03):12-14+40.</p>
</div></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2024-02-11T14:13:58.000Z" title="2024/2/11 22:13:58">2024-02-11</time>发表</span><span class="level-item"><time datetime="2024-02-13T05:54:08.702Z" title="2024/2/13 13:54:08">2024-02-13</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/About-XJH/">About XJH</a><span>&nbsp;/&nbsp;</span><a class="link-muted" href="/categories/About-XJH/%E6%98%8E%E6%85%B5/">明慵</a></span><span class="level-item">34 分钟读完 (大约5057个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/02/11/QQmsganalysis/">QQ聊天记录分析 QQMsgAnalysis</a></p><div class="content"><p>从PC端QQ中以<code>txt</code>格式导出聊天记录，存为<code>message.txt</code>。</p>
<p>需要安装的库: <code>numpy, seaborn, pandas, wordcloud, tdqm, paddlepaddle, paddlenlp</code></p></div><a class="article-more button is-small is-size-7" href="/2024/02/11/QQmsganalysis/#more">阅读更多</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/head2.png" alt="Jinghua Xu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jinghua Xu</p><p class="is-size-6 is-block">明月科创实验班人工智能专业 本科大三在读</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>重庆 重庆大学国家卓越工程师学院</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">32</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">22</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">91</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Asgard-Tim" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/u/6315188431"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/171895120"><i class="fab fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:20224546@stu.cqu.edu.cn"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Phone" href="tel:+86 19132050174"><i class="fas fa-phone"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/04/23/project02/"><img src="/images/project2/1.png" alt="图像插值算法及其优化"></a></figure><div class="media-content"><p class="date"><time datetime="2025-04-22T18:07:03.000Z">2025-04-23</time></p><p class="title"><a href="/2025/04/23/project02/">图像插值算法及其优化</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">工程数值分析</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/18/3DVLA/"><img src="/images/3dvla/6.png" alt="3D-VLA： A 3DVision-Language-Action Generative World Model"></a></figure><div class="media-content"><p class="date"><time datetime="2025-04-18T11:00:03.000Z">2025-04-18</time></p><p class="title"><a href="/2025/04/18/3DVLA/">3D-VLA： A 3DVision-Language-Action Generative World Model</a></p><p class="categories"><a href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/10/project01/"><img src="/images/project01/17.png" alt="求矩阵特征值与特征向量：乘幂法及其改进算法"></a></figure><div class="media-content"><p class="date"><time datetime="2025-04-10T09:44:03.000Z">2025-04-10</time></p><p class="title"><a href="/2025/04/10/project01/">求矩阵特征值与特征向量：乘幂法及其改进算法</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">工程数值分析</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/07/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><img src="/images/phi.png" alt="第二章 数据结构"></a></figure><div class="media-content"><p class="date"><time datetime="2025-04-07T05:26:58.000Z">2025-04-07</time></p><p class="title"><a href="/2025/04/07/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">第二章 数据结构</a></p><p class="categories"><a href="/categories/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/">算法基础课</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/04/06/RT-1/"><img src="/images/rt1/1.png" alt="RT-1：Robotics Transformer for Real-world Control at Scale"></a></figure><div class="media-content"><p class="date"><time datetime="2025-04-06T09:24:03.000Z">2025-04-06</time></p><p class="title"><a href="/2025/04/06/RT-1/">RT-1：Robotics Transformer for Real-world Control at Scale</a></p><p class="categories"><a href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/About-XJH/"><span class="level-start"><span class="level-item">About XJH</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E6%85%B5/"><span class="level-start"><span class="level-item">明慵</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E8%AF%9A/"><span class="level-start"><span class="level-item">明诚</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">个人项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">具身智能论文阅读</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">动手学深度学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/"><span class="level-start"><span class="level-item">算法基础课</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">课程项目</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">产品设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95I/"><span class="level-start"><span class="level-item">定量工程设计方法I</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95II/"><span class="level-start"><span class="level-item">定量工程设计方法II</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E6%95%88%E5%AD%A6/"><span class="level-start"><span class="level-item">工效学</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">工程原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">工程数值分析</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">工程设计</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95/"><span class="level-start"><span class="level-item">数学物理方法</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">智能图像处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">机器人基础</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><span class="level-start"><span class="level-item">概率论与数理统计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="level-start"><span class="level-item">线性代数</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">自动控制原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">软件设计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">三月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">一月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">七月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">六月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">三月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-VLA/"><span class="tag">3D-VLA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ADS1292/"><span class="tag">ADS1292</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Arduino/"><span class="tag">Arduino</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Buck%E5%8F%98%E6%8D%A2%E5%99%A8/"><span class="tag">Buck变换器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C51/"><span class="tag">C51</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/COMSOL/"><span class="tag">COMSOL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChatGPT/"><span class="tag">ChatGPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FIR/"><span class="tag">FIR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FPGA/"><span class="tag">FPGA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FreeRTOS/"><span class="tag">FreeRTOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IIR/"><span class="tag">IIR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Logistic%E5%9B%9E%E5%BD%92/"><span class="tag">Logistic回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MATLAB/"><span class="tag">MATLAB</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matlab/"><span class="tag">Matlab</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PID%E9%97%AD%E7%8E%AF%E6%8E%A7%E5%88%B6/"><span class="tag">PID闭环控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QQbot/"><span class="tag">QQbot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RANSAC/"><span class="tag">RANSAC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robotics-Transformer/"><span class="tag">Robotics Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R%E8%AF%AD%E8%A8%80/"><span class="tag">R语言</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/STM32/"><span class="tag">STM32</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shewhart%E6%8E%A7%E5%88%B6%E5%9B%BE/"><span class="tag">Shewhart控制图</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLA/"><span class="tag">VLA</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XJH/"><span class="tag">XJH</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B9%98%E5%B9%82%E6%B3%95/"><span class="tag">乘幂法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/"><span class="tag">二分类</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%A7%E5%93%81%E8%B4%A8%E9%87%8F%E7%AE%A1%E7%90%86/"><span class="tag">产品质量管理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92/"><span class="tag">人机交互</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%A0%E7%83%AD%E5%AD%A6/"><span class="tag">传热学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/"><span class="tag">信号与系统</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"><span class="tag">假设检验</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"><span class="tag">傅里叶变换</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%89%E4%BC%8FMPPT/"><span class="tag">光伏MPPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/"><span class="tag">具身智能</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E5%8A%9B%E5%AD%A6%E4%BB%BF%E7%9C%9F/"><span class="tag">动力学仿真</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">动手学深度学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"><span class="tag">单片机</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="tag">卷积神经网络</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%8C%E4%B8%89%E6%AC%A1%E6%8F%92%E5%80%BC/"><span class="tag">双三次插值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC/"><span class="tag">双线性插值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"><span class="tag">可视化</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%9B%E5%B9%B3%E9%9D%A2%E6%8F%92%E5%80%BC/"><span class="tag">四平面插值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E6%8F%92%E5%80%BC/"><span class="tag">图像插值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E6%94%BE%E5%A4%A7/"><span class="tag">图像放大</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E6%97%8B%E8%BD%AC/"><span class="tag">图像旋转</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"><span class="tag">图像识别</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">多模态大模型</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="tag">学习笔记</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90/"><span class="tag">定量分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E8%BD%A6/"><span class="tag">小车</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E7%A8%8B%E7%83%AD%E5%8A%9B%E5%AD%A6/"><span class="tag">工程热力学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BF%83%E7%94%B5%E4%BF%A1%E5%8F%B7%E9%87%87%E9%9B%86/"><span class="tag">心电信号采集</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BF%AB%E9%80%9F%E6%88%AA%E6%96%ADHuber%E6%8D%9F%E5%A4%B1/"><span class="tag">快速截断Huber损失</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%89%A9%E6%95%A3%E6%96%B9%E7%A8%8B/"><span class="tag">扩散方程</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"><span class="tag">支持向量机</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%91%E7%81%BE%E6%9C%BA%E5%99%A8%E4%BA%BA/"><span class="tag">救灾机器人</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%80%BC%E8%BF%AD%E4%BB%A3%E6%B1%82%E8%A7%A3/"><span class="tag">数值迭代求解</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"><span class="tag">数字信号处理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90/"><span class="tag">数据处理分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%8F%91%E5%8A%A8%E6%9C%BA/"><span class="tag">斯特林发动机</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%BE%AA%E7%8E%AF/"><span class="tag">斯特林循环</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%80%E8%BF%91%E9%82%BB%E6%8F%92%E5%80%BC/"><span class="tag">最近邻插值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E4%BB%BF%E7%9C%9F/"><span class="tag">有限元仿真</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%AC%E5%BE%81%E5%80%BC%E6%B1%82%E8%A7%A3/"><span class="tag">本征值求解</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E8%87%82/"><span class="tag">机械臂</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E8%AE%BE%E8%AE%A1/"><span class="tag">机械设计</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9F%94%E6%80%A7%E5%A5%97%E7%B4%A2%E6%83%A9%E7%BD%9A/"><span class="tag">柔性套索惩罚</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%BB%A4%E6%B3%A2%E5%99%A8/"><span class="tag">滤波器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%83%9F%E9%9B%BE%E6%89%A9%E6%95%A3/"><span class="tag">烟雾扩散</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%B5%E6%9C%BA%E6%8E%A7%E5%88%B6/"><span class="tag">电机控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC/"><span class="tag">矩阵特征值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="tag">算法与数据结构</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="tag">线性代数</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E8%BF%87%E7%A8%8B%E6%8E%A7%E5%88%B6/"><span class="tag">统计过程控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"><span class="tag">自动控制原理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E8%B0%83%E5%85%89/"><span class="tag">自动调光</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/"><span class="tag">自编码器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%88%B9/"><span class="tag">船</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="tag">计算机视觉</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%80%9D%E7%BB%B4/"><span class="tag">设计思维</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%9D%E7%A6%BB%E7%89%B9%E6%80%A7/"><span class="tag">距离特性</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"><span class="tag">路径规划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%97%AD%E7%8E%AF%E6%8E%A7%E5%88%B6/"><span class="tag">闭环控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A2%91%E8%B0%B1%E5%88%86%E6%9E%90/"><span class="tag">频谱分析</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%AB%98%E6%96%AF%E6%A0%B8%E5%87%BD%E6%95%B0/"><span class="tag">高斯核函数</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a><p class="is-size-7"><span>© 2025 Tim</span>&nbsp;&nbsp;Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>&nbsp;&amp;&nbsp;<a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© Copyright by Jinghua Xu</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer=""></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer=""></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer=""></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer=""></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer=""></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer=""></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer=""></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer=""></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script>
    <link rel="stylesheet" href="https://ai.tianli0.top/static/public/postChatUser_summary.min.css">
    <script>
        let tianliGPT_key = 'S-TA3IX28M1ZT7TILW';
        let tianliGPT_postSelector = '#postchat_postcontent';
        let tianliGPT_Title = '文章摘要';
        let tianliGPT_postURL = '/^https?://[^/]+/[0-9]{4}/[0-9]{2}/[0-9]{2}/';
        let tianliGPT_blacklist = '';
        let tianliGPT_wordLimit = '1000';
        let tianliGPT_typingAnimate = true;
        let tianliGPT_theme = 'default';
        var postChatConfig = {
          backgroundColor: "#3e86f6",
          bottom: "16px",
          left: "16px",
          fill: "#FFFFFF",
          width: "44px",
          frameWidth: "375px",
          frameHeight: "600px",
          defaultInput: true,
          upLoadWeb: true,
          showInviteLink: true,
          userTitle: "PostChat",
          userDesc: "如果你对网站的内容有任何疑问，可以来问我哦～",
          addButton: true,
          beginningText: "这篇文章介绍了",
          userIcon: "https://ai.tianli0.top/static/img/PostChat.webp",
          userMode: "magic",
          defaultChatQuestions: ["你好","你是谁"],
          defaultSearchQuestions: ["视频压缩","设计"]
        };
    </script>
    <script data-postchat_key="S-TA3IX28M1ZT7TILW" src="https://ai.tianli0.top/static/public/postChatUser_summary.min.js"></script>
  </body></html>
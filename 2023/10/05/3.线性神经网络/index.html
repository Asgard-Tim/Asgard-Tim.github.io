<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>3.线性神经网络 - Homepage of Jinghua Xu</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Homepage of Jinghua Xu"><meta name="msapplication-TileImage" content="/img/avatar.jpg"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Homepage of Jinghua Xu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="/img/avatar.jpg"><meta name="description" content="3.1 线性回归123456789101112131415161718192021222324252627282930313233343536373839%matplotlib inlineimport mathimport timeimport numpy as npimport torchfrom d2l import torch as d2ln&amp;#x3D;10000a&amp;#x3D;torch.ones([n])b"><meta property="og:type" content="blog"><meta property="og:title" content="3.线性神经网络"><meta property="og:url" content="http://asgard-tim.github.io/2023/10/05/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><meta property="og:site_name" content="Homepage of Jinghua Xu"><meta property="og:description" content="3.1 线性回归123456789101112131415161718192021222324252627282930313233343536373839%matplotlib inlineimport mathimport timeimport numpy as npimport torchfrom d2l import torch as d2ln&amp;#x3D;10000a&amp;#x3D;torch.ones([n])b"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://asgard-tim.github.io/images/phi.png"><meta property="article:published_time" content="2023-10-05T08:20:00.000Z"><meta property="article:modified_time" content="2025-02-28T16:22:46.990Z"><meta property="article:author" content="Tim"><meta property="article:tag" content="动手学深度学习"><meta property="article:tag" content="学习笔记"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://asgard-tim.github.io/images/phi.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://asgard-tim.github.io/2023/10/05/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},"headline":"3.线性神经网络","image":["http://asgard-tim.github.io/images/phi.png"],"datePublished":"2023-10-05T08:20:00.000Z","dateModified":"2025-02-28T16:22:46.990Z","author":{"@type":"Person","name":"Tim"},"publisher":{"@type":"Organization","name":"Homepage of Jinghua Xu","logo":{"@type":"ImageObject","url":"http://asgard-tim.github.io/img/title1.png"}},"description":"3.1 线性回归123456789101112131415161718192021222324252627282930313233343536373839%matplotlib inlineimport mathimport timeimport numpy as npimport torchfrom d2l import torch as d2ln&#x3D;10000a&#x3D;torch.ones([n])b"}</script><link rel="canonical" href="http://asgard-tim.github.io/2023/10/05/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><link rel="icon" href="/img/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/xt256.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com">GitHub</a><a class="navbar-item" target="_blank" rel="noopener" title="Contect me on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-10-05T08:20:00.000Z" title="2023/10/5 16:20:00">2023-10-05</time>发表</span><span class="level-item"><time dateTime="2025-02-28T16:22:46.990Z" title="2025/3/1 00:22:46">2025-03-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a></span><span class="level-item">20 分钟读完 (大约3052个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">3.线性神经网络</h1><div class="content"><h2 id="3-1-线性回归"><a href="#3-1-线性回归" class="headerlink" title="3.1 线性回归"></a>3.1 线性回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">n=<span class="number">10000</span></span><br><span class="line">a=torch.ones([n])</span><br><span class="line">b=torch.ones([n])</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义计时器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>: <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#记录多次运行时间</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.times=[]</span><br><span class="line">        self.start()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#启动计时器</span></span><br><span class="line">        self.tik=time.time()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">stop</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#停止计时器并将时间记录在列表中</span></span><br><span class="line">        self.times.append(time.time()-self.tik)</span><br><span class="line">        <span class="keyword">return</span> self.times[-<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">avg</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#返回平均时间</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.times)/<span class="built_in">len</span>(self.times)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#返回时间总和</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(self.times)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cumsum</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#返回累计时间</span></span><br><span class="line">        <span class="keyword">return</span> np.array(self.times).cumsum().tolist()</span><br><span class="line">    </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c=torch.zeros(n)</span><br><span class="line">timer=Timer()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    c[i]=a[i]+b[i]</span><br><span class="line"><span class="string">f&#x27;<span class="subst">&#123;timer.stop():<span class="number">.5</span>f&#125;</span>sec&#x27;</span></span><br></pre></td></tr></table></figure>




<pre><code>&#39;0.14660sec&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">timer.start()</span><br><span class="line">d=a+b</span><br><span class="line"><span class="string">f&#x27;<span class="subst">&#123;timer.stop():<span class="number">.5</span>f&#125;</span>sec&#x27;</span></span><br></pre></td></tr></table></figure>




<pre><code>&#39;0.00000sec&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normal</span>(<span class="params">x,mu,sigma</span>):</span><br><span class="line">    p=<span class="number">1</span>/math.sqrt(<span class="number">2</span>*math.pi*sigma**<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> p*np.exp(-<span class="number">0.5</span>/sigma**<span class="number">2</span>*(x-mu)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#再次使用numpy进行可视化</span></span><br><span class="line">x=np.arange(-<span class="number">7</span>,<span class="number">7</span>,<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#均值和标准差对</span></span><br><span class="line">params=[(<span class="number">0</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">1</span>)]</span><br><span class="line">d2l.plot(x,[normal(x,mu,sigma)<span class="keyword">for</span> mu,sigma <span class="keyword">in</span> params],xlabel=<span class="string">&#x27;x&#x27;</span>,ylabel=<span class="string">&#x27;p(x)&#x27;</span>,figsize=(<span class="number">4.5</span>,<span class="number">2.5</span>),legend=[<span class="string">f&#x27;mean<span class="subst">&#123;mu&#125;</span>,std<span class="subst">&#123;sigma&#125;</span>&#x27;</span><span class="keyword">for</span> mu,sigma <span class="keyword">in</span> params])</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_files/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_4_0.svg" alt="svg"><br>​    </p>
<h2 id="3-2-线性回归的从零开始实现"><a href="#3-2-线性回归的从零开始实现" class="headerlink" title="3.2 线性回归的从零开始实现"></a>3.2 线性回归的从零开始实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">synthetic_data</span>(<span class="params">w,b,num_examples</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#生成y=Xw+b+噪声</span></span><br><span class="line">    X=torch.normal(<span class="number">0</span>,<span class="number">1</span>,(num_examples,<span class="built_in">len</span>(w)))</span><br><span class="line">    y=torch.matmul(X,w)+b</span><br><span class="line">    y+=torch.normal(<span class="number">0</span>,<span class="number">0.01</span>,y.shape)</span><br><span class="line">    <span class="keyword">return</span> X,y.reshape((-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">true_w=torch.tensor([<span class="number">2</span>,-<span class="number">3.4</span>])</span><br><span class="line">true_b=<span class="number">4.2</span></span><br><span class="line">features,labels=synthetic_data(true_w,true_b,<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;features:&#x27;</span>,features[<span class="number">0</span>],<span class="string">&#x27;\nlabel:&#x27;</span>,labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>features: tensor([ 0.7328, -0.5520]) 
label: tensor([7.5513])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d2l.set_figsize()</span><br><span class="line">d2l.plt.scatter(features[:,<span class="number">1</span>].detach().numpy(),labels.detach().numpy(),<span class="number">1</span>);</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_files/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_7_0.svg" alt="svg"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size,features,labels</span>):</span><br><span class="line">    num_examples=<span class="built_in">len</span>(features)</span><br><span class="line">    indices=<span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    <span class="comment">#这些样本是随机读取的，没有特定顺序</span></span><br><span class="line">    random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,num_examples,batch_size):</span><br><span class="line">        batch_indices=torch.tensor(indices[i:<span class="built_in">min</span>(i+batch_size,num_examples)])</span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices],labels[batch_indices]</span><br><span class="line">        </span><br><span class="line">batch_size=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter(batch_size,features,labels):</span><br><span class="line">    <span class="built_in">print</span>(X,<span class="string">&#x27;\n&#x27;</span>,y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<pre><code>tensor([[ 0.9175, -0.1441],
        [-0.3328, -0.4237],
        [-0.1287,  1.6801],
        [ 0.8705, -0.9030],
        [-0.4966,  1.4015],
        [ 1.3378, -1.8026],
        [ 0.5129,  1.2806],
        [ 1.1026,  1.2080],
        [ 0.6151,  0.6337],
        [-0.4683, -0.4388]]) 
 tensor([[ 6.5336],
        [ 4.9801],
        [-1.7645],
        [ 9.0089],
        [-1.5652],
        [12.9979],
        [ 0.8680],
        [ 2.2893],
        [ 3.2902],
        [ 4.7695]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#初始化模型参数</span></span><br><span class="line">w=torch.normal(<span class="number">0</span>,<span class="number">0.01</span>,size=(<span class="number">2</span>,<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">b=torch.zeros(<span class="number">1</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X,w,b</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#线性回归模型</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X,w)+b</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat,y</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#均方损失</span></span><br><span class="line">    <span class="keyword">return</span>(y_hat-y.reshape(y_hat.shape))**<span class="number">2</span>/<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义优化算法——小批量随机梯度下降</span></span><br><span class="line"><span class="comment">#lr:学习速率(梯度下降步长)；batch_size:批量大小</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params,lr,batch_size</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#小批量随机梯度下降</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param-=lr*param.grad/batch_size</span><br><span class="line">            param.grad.zero_()</span><br><span class="line">            </span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="comment">#设置超参数</span></span><br><span class="line">lr=<span class="number">0.03</span><span class="comment">#学习率</span></span><br><span class="line">num_epochs=<span class="number">3</span><span class="comment">#迭代周期个数</span></span><br><span class="line">net=linreg</span><br><span class="line">loss=squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter(batch_size,features,labels):</span><br><span class="line">        l=loss(net(X,w,b),y)<span class="comment">#X和y的小批量损失</span></span><br><span class="line">        <span class="comment">#因为l的形状是（batch_size,1），而不是一个标量。l中的所有元素被加到一起，并以此计算关于[w,b]的梯度</span></span><br><span class="line">        l.<span class="built_in">sum</span>().backward()</span><br><span class="line">        sgd([w,b],lr,batch_size)<span class="comment">#使用参数的梯度以更新参数</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        train_l=loss(net(features,w,b),labels)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss<span class="subst">&#123;<span class="built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>epoch1,loss0.036941
epoch2,loss0.000134
epoch3,loss0.000049
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;w的估计误差：<span class="subst">&#123;true_w-w.reshape(true_w.shape)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;b的估计误差：<span class="subst">&#123;true_b-b&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>w的估计误差：tensor([ 0.0002, -0.0002], grad_fn=&lt;SubBackward0&gt;)
b的估计误差：tensor([0.0002], grad_fn=&lt;RsubBackward1&gt;)
</code></pre>
<h2 id="3-3-线性回归的简洁实现"><a href="#3-3-线性回归的简洁实现" class="headerlink" title="3.3 线性回归的简洁实现"></a>3.3 线性回归的简洁实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成数据集</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">true_w=torch.tensor([<span class="number">2</span>,-<span class="number">3.4</span>])</span><br><span class="line">true_b=<span class="number">4.2</span></span><br><span class="line">features,labels=d2l.synthetic_data(true_w,true_b,<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_array</span>(<span class="params">data_arrays,batch_size,is_train=<span class="literal">True</span></span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#构造一个pytorch数据迭代器</span></span><br><span class="line">    dataset=data.TensorDataset(*data_arrays)</span><br><span class="line">    <span class="keyword">return</span> data.DataLoader(dataset,batch_size,shuffle=is_train)</span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">10</span></span><br><span class="line">data_iter=load_array((features,labels),batch_size)</span><br><span class="line"></span><br><span class="line"><span class="built_in">next</span>(<span class="built_in">iter</span>(data_iter))</span><br></pre></td></tr></table></figure>




<pre><code>[tensor([[-0.6422, -0.7470],
         [-2.1785,  0.3340],
         [ 1.4011, -1.1104],
         [-0.8083, -0.3035],
         [ 0.1077, -0.1201],
         [-0.4151, -0.1079],
         [ 1.8074,  0.0904],
         [-0.3707,  0.6197],
         [ 0.3739,  0.2972],
         [ 0.2383,  1.1791]]),
 tensor([[ 5.4457],
         [-1.3122],
         [10.7837],
         [ 3.6281],
         [ 4.8105],
         [ 3.7284],
         [ 7.5017],
         [ 1.3465],
         [ 3.9247],
         [ 0.6800]])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义模型</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn<span class="comment">#nn:神经网络</span></span><br><span class="line">net=nn.Sequential(nn.Linear(<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化模型参数</span></span><br><span class="line">net[<span class="number">0</span>].weight.data.normal_(<span class="number">0</span>,<span class="number">0.01</span>),net[<span class="number">0</span>].bias.data.fill_(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[ 0.0106, -0.0055]]), tensor([0.]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义损失函数</span></span><br><span class="line">loss=nn.MSELoss()<span class="comment">#均方误差：MSELoss类，平方L2范数</span></span><br><span class="line"><span class="comment">#定义优化算法</span></span><br><span class="line">trainer=torch.optim.SGD(net.parameters(),lr=<span class="number">0.03</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">num_epochs=<span class="number">3</span><span class="comment">#迭代周期个数</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">        l=loss(net(X),y)<span class="comment">#X和y的小批量损失</span></span><br><span class="line">        trainer.zero_grad()</span><br><span class="line">        l.backward()</span><br><span class="line">        trainer.step()<span class="comment">#使用参数的梯度以更新参数</span></span><br><span class="line">    l=loss(net(features),labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss<span class="subst">&#123;l:f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>epoch1,loss0.000223
epoch2,loss0.000112
epoch3,loss0.000112
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w=net[<span class="number">0</span>].weight.data</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w的估计误差：&#x27;</span>,true_w-w.reshape(true_w.shape))</span><br><span class="line">b=net[<span class="number">0</span>].bias.data</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b的估计误差：&#x27;</span>,true_b-b)</span><br></pre></td></tr></table></figure>

<pre><code>w的估计误差： tensor([ 0.0014, -0.0004])
b的估计误差： tensor([0.0008])
</code></pre>
<h2 id="3-5-图像分类数据集"><a href="#3-5-图像分类数据集" class="headerlink" title="3.5 图像分类数据集"></a>3.5 图像分类数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">d2l.use_svg_display()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过框架内内置函数将Fashion-MNIST数据集下载并读取到内存中</span></span><br><span class="line"><span class="comment">#通过ToTensor实例将图像数据由PIL类型变换为32位浮点数格式，并除以255使得所有像素数值均在0-1之间</span></span><br><span class="line">trans=transforms.ToTensor()</span><br><span class="line">mnist_train=torchvision.datasets.FashionMNIST(root=<span class="string">&quot;../data&quot;</span>,train=<span class="literal">True</span>,transform=trans,download=<span class="literal">True</span>)</span><br><span class="line">mnist_test=torchvision.datasets.FashionMNIST(root=<span class="string">&quot;../data&quot;</span>,train=<span class="literal">False</span>,transform=trans,download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(mnist_train),<span class="built_in">len</span>(mnist_test)</span><br></pre></td></tr></table></figure>




<pre><code>(60000, 10000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mnist_train[<span class="number">0</span>][<span class="number">0</span>].shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([1, 28, 28])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在数字标签索引与文本名称之间进行转换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_fashion_mnist_labels</span>(<span class="params">labels</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#返回Fashion-MNIST数据集的文本标签</span></span><br><span class="line">    text_labels=[<span class="string">&#x27;t-shirt&#x27;</span>,<span class="string">&#x27;trouser&#x27;</span>,<span class="string">&#x27;pullover&#x27;</span>,<span class="string">&#x27;dress&#x27;</span>,<span class="string">&#x27;coat&#x27;</span>,<span class="string">&#x27;sandal&#x27;</span>,<span class="string">&#x27;shirt&#x27;</span>,<span class="string">&#x27;sneaker&#x27;</span>,<span class="string">&#x27;bag&#x27;</span>,<span class="string">&#x27;ankle boot&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> [text_labels[<span class="built_in">int</span>(i)] <span class="keyword">for</span> i <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化样本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_images</span>(<span class="params">imgs,num_rows,num_cols,titles=<span class="literal">None</span>,scale=<span class="number">1.5</span></span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#绘制图像列表</span></span><br><span class="line">    figsize=(num_cols*scale,num_rows*scale)</span><br><span class="line">    _,axes=d2l.plt.subplots(num_rows,num_cols,figsize=figsize)</span><br><span class="line">    axes=axes.flatten()</span><br><span class="line">    <span class="keyword">for</span> i,(ax,img) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(axes,imgs)):</span><br><span class="line">        <span class="keyword">if</span> torch.is_tensor(img):</span><br><span class="line">            <span class="comment">#图片张量</span></span><br><span class="line">            ax.imshow(img.numpy())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#PIL图片</span></span><br><span class="line">            ax.imshow(img)</span><br><span class="line">        ax.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        ax.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> titles:</span><br><span class="line">            ax.set_title(titles[i])</span><br><span class="line">    <span class="keyword">return</span> axes</span><br><span class="line"></span><br><span class="line">X,y=<span class="built_in">next</span>(<span class="built_in">iter</span>(data.DataLoader(mnist_train,batch_size=<span class="number">50</span>)))</span><br><span class="line">show_images(X.reshape(<span class="number">50</span>,<span class="number">28</span>,<span class="number">28</span>),<span class="number">10</span>,<span class="number">5</span>,titles=get_fashion_mnist_labels(y));</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_files/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_22_0.svg" alt="svg"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取小批量</span></span><br><span class="line">batch_size=<span class="number">256</span> <span class="comment">#批量大小</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataloader_workers</span>():  <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#使用4个进程来读取数据</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_iter=data.DataLoader(mnist_train,batch_size,shuffle=<span class="literal">True</span>,num_workers=get_dataloader_workers())</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取训练数据所需时间</span></span><br><span class="line">timer=d2l.Timer()</span><br><span class="line"><span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"><span class="string">f&#x27;<span class="subst">&#123;timer.stop():<span class="number">.2</span>f&#125;</span>sec&#x27;</span></span><br></pre></td></tr></table></figure>




<pre><code>&#39;2.11sec&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_fashion_mnist</span>(<span class="params">batch_size,resize=<span class="literal">None</span></span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#下载Fashion-MNIST数据集，然后将其加载到内存中</span></span><br><span class="line">    trans=[transforms.ToTensor()]</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        trans.insert(<span class="number">0</span>,transforms.Resize(resize))</span><br><span class="line">    trans=transforms.Compose(trans)</span><br><span class="line">    mnist_train=torchvision.datasets.FashionMNIST(root=<span class="string">&quot;../data&quot;</span>,train=<span class="literal">True</span>,transform=trans,download=<span class="literal">True</span>)</span><br><span class="line">    mnist_test=torchvision.datasets.FashionMNIST(root=<span class="string">&quot;../data&quot;</span>,train=<span class="literal">False</span>,transform=trans,download=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span>(data.DataLoader(mnist_train,batch_size,shuffle=<span class="literal">True</span>,num_workers=get_dataloader_workers()),data.DataLoader(mnist_test,batch_size,shuffle=<span class="literal">False</span>,num_workers=get_dataloader_workers()))</span><br><span class="line"></span><br><span class="line">train_iter,test_iter=load_data_fashion_mnist(<span class="number">32</span>,resize=<span class="number">64</span>)</span><br><span class="line"><span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">    <span class="built_in">print</span>(X.shape,X.dtype,y.shape,y.dtype)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<pre><code>torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64
</code></pre>
<h2 id="3-6-softmax回归的从零开始实现"><a href="#3-6-softmax回归的从零开始实现" class="headerlink" title="3.6 softmax回归的从零开始实现"></a>3.6 softmax回归的从零开始实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">256</span></span><br><span class="line">train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#初始化模型参数</span></span><br><span class="line">num_inputs=<span class="number">784</span></span><br><span class="line">num_outputs=<span class="number">10</span></span><br><span class="line"></span><br><span class="line">W=torch.normal(<span class="number">0</span>,<span class="number">0.01</span>,size=(num_inputs,num_outputs),requires_grad=<span class="literal">True</span>)<span class="comment">#用正态分布初始化权重W</span></span><br><span class="line">b=torch.zeros(num_outputs,requires_grad=<span class="literal">True</span>)<span class="comment">#偏置b初始化为0</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X=torch.tensor([[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>],[<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>]])</span><br><span class="line">X.<span class="built_in">sum</span>(<span class="number">0</span>,keepdim=<span class="literal">True</span>),X.<span class="built_in">sum</span>(<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[5., 7., 9.]]),
 tensor([[ 6.],
         [15.]]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义softmax操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">X</span>):</span><br><span class="line">    X_exp=torch.exp(X)</span><br><span class="line">    partition=X_exp.<span class="built_in">sum</span>(<span class="number">1</span>,keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> X_exp/partition <span class="comment">#应用广播机制</span></span><br><span class="line"></span><br><span class="line">X=torch.normal(<span class="number">0</span>,<span class="number">1</span>,(<span class="number">2</span>,<span class="number">5</span>))</span><br><span class="line">X_prob=softmax(X)</span><br><span class="line">X_prob,X_prob.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(tensor([[0.2143, 0.0127, 0.1268, 0.2248, 0.4214],
         [0.3360, 0.2826, 0.0913, 0.1454, 0.1446]]),
 tensor([1.0000, 1.0000]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">X</span>):</span><br><span class="line">    <span class="keyword">return</span> softmax(torch.matmul(X.reshape((-<span class="number">1</span>,W.shape[<span class="number">0</span>])),W)+b)   <span class="comment">#使用reshape函数将每张原始图像展平为向量</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y=torch.tensor([<span class="number">0</span>,<span class="number">2</span>])</span><br><span class="line">y_hat=torch.tensor([[<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.6</span>],[<span class="number">0.3</span>,<span class="number">0.2</span>,<span class="number">0.5</span>]])</span><br><span class="line">y_hat[[<span class="number">0</span>,<span class="number">1</span>],y]</span><br></pre></td></tr></table></figure>




<pre><code>tensor([0.1000, 0.5000])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义交叉熵损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">y_hat,y</span>):</span><br><span class="line">    <span class="keyword">return</span> - torch.log(y_hat[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)),y])</span><br><span class="line"></span><br><span class="line">cross_entropy(y_hat,y)</span><br></pre></td></tr></table></figure>




<pre><code>tensor([2.3026, 0.6931])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_hat,y</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#计算正确预测的数量</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(y_hat.shape)&gt;<span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>]&gt;<span class="number">1</span>:</span><br><span class="line">        y_hat=y_hat.argmax(axis=<span class="number">1</span>)</span><br><span class="line">    cmp=y_hat.<span class="built_in">type</span>(y.dtype)==y</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(cmp.<span class="built_in">type</span>(y.dtype).<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line">accuracy(y_hat,y)/<span class="built_in">len</span>(y)  <span class="comment">#正确预测的概率（分类精度率）</span></span><br></pre></td></tr></table></figure>




<pre><code>0.5
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy</span>(<span class="params">net,data_iter</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#计算在指定数据集上模型的精度</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net,torch.nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>() <span class="comment">#将模型设置为评估模式</span></span><br><span class="line">    metric=Accumulator(<span class="number">2</span>) <span class="comment">#正确预测数、预测总数的叠加</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X,y <span class="keyword">in</span> data_iter:</span><br><span class="line">            metric.add(accuracy(net(X),y),y.numel())  <span class="comment">#accracy(net(X),y):正确预测数；y.numel()预测总数</span></span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>]/metric[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Accumulator</span>: <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#在n个变量上累加</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n</span>):</span><br><span class="line">        self.data=[<span class="number">0.0</span>]*n</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self,*args</span>):</span><br><span class="line">        self.data=[a+<span class="built_in">float</span>(b) <span class="keyword">for</span> a,b <span class="keyword">in</span> <span class="built_in">zip</span>(self.data,args)]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        self.data=[<span class="number">0.0</span>]*<span class="built_in">len</span>(self.data)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.data[idx]</span><br><span class="line">    </span><br><span class="line">evaluate_accuracy(net,test_iter)</span><br></pre></td></tr></table></figure>




<pre><code>0.1326
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch_ch3</span>(<span class="params">net,train_iter,loss,updater</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#训练模型一个迭代周期</span></span><br><span class="line">    <span class="comment">#将模型设置为训练模型</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net,torch.nn.Module):</span><br><span class="line">        net.train()</span><br><span class="line">    <span class="comment">#训练损失总和、训练准确度总和、样本数</span></span><br><span class="line">    metric=Accumulator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">        <span class="comment">#计算梯度并更新参数</span></span><br><span class="line">        y_hat=net(X)</span><br><span class="line">        l=loss(y_hat,y)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(updater,torch.optim.Optimizer):</span><br><span class="line">            <span class="comment">#使用PyTorch内置的优化器和损失函数</span></span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            l.mean().backward()</span><br><span class="line">            updater.step()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#使用定制的优化器和损失函数</span></span><br><span class="line">            l.<span class="built_in">sum</span>().backward()</span><br><span class="line">            updater(X.shape[<span class="number">0</span>])</span><br><span class="line">        metric.add(<span class="built_in">float</span>(l.<span class="built_in">sum</span>()),accuracy(y_hat,y),y.numel())</span><br><span class="line">    <span class="comment">#返回训练损失和训练精度</span></span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>]/metric[<span class="number">2</span>],metric[<span class="number">1</span>]/metric[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Animator</span>:  <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#在动画中绘制数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, xlabel=<span class="literal">None</span>, ylabel=<span class="literal">None</span>, legend=<span class="literal">None</span>, xlim=<span class="literal">None</span>,ylim=<span class="literal">None</span>, xscale=<span class="string">&#x27;linear&#x27;</span>, yscale=<span class="string">&#x27;linear&#x27;</span>,fmts=(<span class="params"><span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;m--&#x27;</span>, <span class="string">&#x27;g-.&#x27;</span>, <span class="string">&#x27;r:&#x27;</span></span>), nrows=<span class="number">1</span>, ncols=<span class="number">1</span>,figsize=(<span class="params"><span class="number">3.5</span>, <span class="number">2.5</span></span>)</span>):</span><br><span class="line">        <span class="comment"># 增量地绘制多条线</span></span><br><span class="line">        <span class="keyword">if</span> legend <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            legend = []</span><br><span class="line">        d2l.use_svg_display()</span><br><span class="line">        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)</span><br><span class="line">        <span class="keyword">if</span> nrows * ncols == <span class="number">1</span>:</span><br><span class="line">            self.axes = [self.axes, ]</span><br><span class="line">        <span class="comment"># 使用lambda函数捕获参数</span></span><br><span class="line">        self.config_axes = <span class="keyword">lambda</span>: d2l.set_axes(</span><br><span class="line">            self.axes[<span class="number">0</span>], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)</span><br><span class="line">        self.X, self.Y, self.fmts = <span class="literal">None</span>, <span class="literal">None</span>, fmts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="comment"># 向图表中添加多个数据点</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(y, <span class="string">&quot;__len__&quot;</span>):</span><br><span class="line">            y = [y]</span><br><span class="line">        n = <span class="built_in">len</span>(y)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(x, <span class="string">&quot;__len__&quot;</span>):</span><br><span class="line">            x = [x] * n</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.X:</span><br><span class="line">            self.X = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.Y:</span><br><span class="line">            self.Y = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> i, (a, b) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(x, y)):</span><br><span class="line">            <span class="keyword">if</span> a <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> b <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                self.X[i].append(a)</span><br><span class="line">                self.Y[i].append(b)</span><br><span class="line">        self.axes[<span class="number">0</span>].cla()</span><br><span class="line">        <span class="keyword">for</span> x, y, fmt <span class="keyword">in</span> <span class="built_in">zip</span>(self.X, self.Y, self.fmts):</span><br><span class="line">            self.axes[<span class="number">0</span>].plot(x, y, fmt)</span><br><span class="line">        self.config_axes()</span><br><span class="line">        display.display(self.fig)</span><br><span class="line">        display.clear_output(wait=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch3</span>(<span class="params">net,train_iter,test_iter,loss,num_epochs,updater</span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#训练模型</span></span><br><span class="line">    animator=Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>,xlim=[<span class="number">1</span>,num_epochs],ylim=[<span class="number">0.3</span>,<span class="number">0.9</span>],legend=[<span class="string">&#x27;train loss&#x27;</span>,<span class="string">&#x27;train acc&#x27;</span>,<span class="string">&#x27;test acc&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_metrics=train_epoch_ch3(net,train_iter,loss,updater)</span><br><span class="line">        test_acc=evaluate_accuracy(net,test_iter)</span><br><span class="line">        animator.add(epoch+<span class="number">1</span>,train_metrics+(test_acc,))</span><br><span class="line">    train_loss,train_acc=train_metrics</span><br><span class="line">    <span class="keyword">assert</span> train_loss&lt;<span class="number">0.5</span>,train_loss</span><br><span class="line">    <span class="keyword">assert</span> train_acc&lt;=<span class="number">1</span> <span class="keyword">and</span> train_acc&gt;<span class="number">0.7</span>,train_acc</span><br><span class="line">    <span class="keyword">assert</span> test_acc&lt;=<span class="number">1</span> <span class="keyword">and</span> test_acc&gt;<span class="number">0.7</span>,test_acc</span><br><span class="line">    </span><br><span class="line">lr=<span class="number">0.1</span> <span class="comment">#学习率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updater</span>(<span class="params">batch_size</span>):</span><br><span class="line">    <span class="keyword">return</span> d2l.sgd([W,b],lr,batch_size)<span class="comment">#小批量随机梯度下降</span></span><br><span class="line"></span><br><span class="line">num_epochs=<span class="number">10</span> <span class="comment">#迭代周期</span></span><br><span class="line">train_ch3(net,train_iter,test_iter,cross_entropy,num_epochs,updater)</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_files/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_35_0.svg" alt="svg"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#预测</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_ch3</span>(<span class="params">net,test_iter,n=<span class="number">6</span></span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="comment">#预测标签</span></span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> test_iter:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    trues=d2l.get_fashion_mnist_labels(y)</span><br><span class="line">    preds=d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="number">1</span>))</span><br><span class="line">    titles=[true+<span class="string">&#x27;\n&#x27;</span>+pred <span class="keyword">for</span> true,pred <span class="keyword">in</span> <span class="built_in">zip</span>(trues,preds)]</span><br><span class="line">    d2l.show_images(X[<span class="number">0</span>:n].reshape((n,<span class="number">28</span>,<span class="number">28</span>)),<span class="number">1</span>,n,titles=titles[<span class="number">0</span>:n])</span><br><span class="line">    </span><br><span class="line">predict_ch3(net,test_iter)</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_files/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_36_0.svg" alt="svg"><br>​    </p>
<h2 id="3-7-softmax回归的简洁实现"><a href="#3-7-softmax回归的简洁实现" class="headerlink" title="3.7 softmax回归的简洁实现"></a>3.7 softmax回归的简洁实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">256</span></span><br><span class="line">train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#初始化模型参数</span></span><br><span class="line"><span class="comment">#PyTorch不会隐式地调整输入的形状，因此，我们在线性层前定义了展平层（flatten),来调整网络输入的形状</span></span><br><span class="line">net=nn.Sequential(nn.Flatten(),nn.Linear(<span class="number">784</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(m)==nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight,std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">net.apply(init_weights);</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss=nn.CrossEntropyLoss(reduction=<span class="string">&#x27;none&#x27;</span>) <span class="comment">#保留softmax函数，但在计算交叉熵损失函数时传递未规范化的预测并同时计算softmax及其对数以防止数值上溢或下溢</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#优化算法：学习度为0.1的小批量随机梯度下降</span></span><br><span class="line">trainer=torch.optim.SGD(net.parameters(),lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练</span></span><br><span class="line">num_epochs=<span class="number">10</span></span><br><span class="line">d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,trainer)</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_files/3.%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C_42_0.svg" alt="svg"><br>​    </p>
</div><div class="article-licensing box"><div class="licensing-title"><p>3.线性神经网络</p><p><a href="http://asgard-tim.github.io/2023/10/05/3.线性神经网络/">http://asgard-tim.github.io/2023/10/05/3.线性神经网络/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Tim</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-10-05</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-03-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">动手学深度学习</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/wechat.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/alipay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/10/13/%E6%B0%94%E7%BC%B8%E6%B4%BB%E5%A1%9E%E6%8A%A5%E5%91%8A/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">课题：发动机驱动部件的制作（气缸）</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/10/01/%E6%8A%A5%E5%91%8A/"><span class="level-item">课题：典型建筑墙体的稳态传热分析</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.16/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "4YfCkg9RY2bBZosr2CIG3MbR-gzGzoHsz",
            appKey: "yY6mlbvEevj97fBj9Ri4czpD",
            placeholder: "请多指教",
            avatar: "mm",
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: false,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#3-1-线性回归"><span class="level-left"><span class="level-item">1</span><span class="level-item">3.1 线性回归</span></span></a></li><li><a class="level is-mobile" href="#3-2-线性回归的从零开始实现"><span class="level-left"><span class="level-item">2</span><span class="level-item">3.2 线性回归的从零开始实现</span></span></a></li><li><a class="level is-mobile" href="#3-3-线性回归的简洁实现"><span class="level-left"><span class="level-item">3</span><span class="level-item">3.3 线性回归的简洁实现</span></span></a></li><li><a class="level is-mobile" href="#3-5-图像分类数据集"><span class="level-left"><span class="level-item">4</span><span class="level-item">3.5 图像分类数据集</span></span></a></li><li><a class="level is-mobile" href="#3-6-softmax回归的从零开始实现"><span class="level-left"><span class="level-item">5</span><span class="level-item">3.6 softmax回归的从零开始实现</span></span></a></li><li><a class="level is-mobile" href="#3-7-softmax回归的简洁实现"><span class="level-left"><span class="level-item">6</span><span class="level-item">3.7 softmax回归的简洁实现</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/head1.jpg" alt="Jinghua Xu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jinghua Xu</p><p class="is-size-6 is-block">明月科创实验班人工智能专业 本科大三在读</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>重庆 重庆大学国家卓越工程师学院</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">75</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Asgard-Tim" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/u/6315188431"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/171895120"><i class="fab fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:20224546@stu.cqu.edu.cn"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Phone" href="tel:+86 19132050174"><i class="fas fa-phone"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/02/22/index/"><img src="/images/avatar.jpg" alt="个人简历"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-02-22T11:52:30.000Z">2025-02-22</time></p><p class="title"><a href="/2025/02/22/index/">个人简历</a></p><p class="categories"><a href="/categories/About-XJH/">About XJH</a> / <a href="/categories/About-XJH/%E6%98%8E%E8%AF%9A/">明诚</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/01/11/smoke/"><img src="/images/smoke/media/image55.png" alt="烟雾扩散问题"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-01-11T12:58:03.000Z">2025-01-11</time></p><p class="title"><a href="/2025/01/11/smoke/">烟雾扩散问题</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95/">数学物理方法</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/01/05/graph/"><img src="/images/graph/media/image19.png" alt="基于自编码器和卷积网络的肺炎图像识别"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-01-04T17:02:03.000Z">2025-01-05</time></p><p class="title"><a href="/2025/01/05/graph/">基于自编码器和卷积网络的肺炎图像识别</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">智能图像处理</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/12/31/ecg/"><img src="/images/ecg/media/image67.png" alt="心电信号采集与处理"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-12-30T18:02:03.000Z">2024-12-31</time></p><p class="title"><a href="/2024/12/31/ecg/">心电信号采集与处理</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95II/">定量工程设计方法II</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/12/22/control/"><img src="/images/control/media/image135.png" alt="基于直流电源调控的自动调光控制设计"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-12-21T18:15:03.000Z">2024-12-22</time></p><p class="title"><a href="/2024/12/22/control/">基于直流电源调控的自动调光控制设计</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/">自动控制原理</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/About-XJH/"><span class="level-start"><span class="level-item">About XJH</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E6%85%B5/"><span class="level-start"><span class="level-item">明慵</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E8%AF%9A/"><span class="level-start"><span class="level-item">明诚</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">个人项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">动手学深度学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">课程项目</span></span><span class="level-end"><span class="level-item tag">21</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">产品设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95I/"><span class="level-start"><span class="level-item">定量工程设计方法I</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95II/"><span class="level-start"><span class="level-item">定量工程设计方法II</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E6%95%88%E5%AD%A6/"><span class="level-start"><span class="level-item">工效学</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">工程原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">工程设计</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95/"><span class="level-start"><span class="level-item">数学物理方法</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">智能图像处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">机器人基础</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><span class="level-start"><span class="level-item">概率论与数理统计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="level-start"><span class="level-item">线性代数</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">自动控制原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">软件设计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">一月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">七月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">六月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">三月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ADS1292/"><span class="tag">ADS1292</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Arduino/"><span class="tag">Arduino</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Buck%E5%8F%98%E6%8D%A2%E5%99%A8/"><span class="tag">Buck变换器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C51/"><span class="tag">C51</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/COMSOL/"><span class="tag">COMSOL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ChatGPT/"><span class="tag">ChatGPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FIR/"><span class="tag">FIR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FPGA/"><span class="tag">FPGA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FreeRTOS/"><span class="tag">FreeRTOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IIR/"><span class="tag">IIR</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Logistic%E5%9B%9E%E5%BD%92/"><span class="tag">Logistic回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MATLAB/"><span class="tag">MATLAB</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matlab/"><span class="tag">Matlab</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PID%E9%97%AD%E7%8E%AF%E6%8E%A7%E5%88%B6/"><span class="tag">PID闭环控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QQbot/"><span class="tag">QQbot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RANSAC/"><span class="tag">RANSAC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROS/"><span class="tag">ROS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R%E8%AF%AD%E8%A8%80/"><span class="tag">R语言</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/STM32/"><span class="tag">STM32</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Shewhart%E6%8E%A7%E5%88%B6%E5%9B%BE/"><span class="tag">Shewhart控制图</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XJH/"><span class="tag">XJH</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/"><span class="tag">二分类</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%A7%E5%93%81%E8%B4%A8%E9%87%8F%E7%AE%A1%E7%90%86/"><span class="tag">产品质量管理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92/"><span class="tag">人机交互</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%A0%E7%83%AD%E5%AD%A6/"><span class="tag">传热学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/"><span class="tag">信号与系统</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"><span class="tag">假设检验</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"><span class="tag">傅里叶变换</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%89%E4%BC%8FMPPT/"><span class="tag">光伏MPPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E5%8A%9B%E5%AD%A6%E4%BB%BF%E7%9C%9F/"><span class="tag">动力学仿真</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">动手学深度学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"><span class="tag">单片机</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="tag">卷积神经网络</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"><span class="tag">可视化</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"><span class="tag">图像识别</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="tag">学习笔记</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90/"><span class="tag">定量分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E8%BD%A6/"><span class="tag">小车</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E7%A8%8B%E7%83%AD%E5%8A%9B%E5%AD%A6/"><span class="tag">工程热力学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BF%83%E7%94%B5%E4%BF%A1%E5%8F%B7%E9%87%87%E9%9B%86/"><span class="tag">心电信号采集</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BF%AB%E9%80%9F%E6%88%AA%E6%96%ADHuber%E6%8D%9F%E5%A4%B1/"><span class="tag">快速截断Huber损失</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%89%A9%E6%95%A3%E6%96%B9%E7%A8%8B/"><span class="tag">扩散方程</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"><span class="tag">支持向量机</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%91%E7%81%BE%E6%9C%BA%E5%99%A8%E4%BA%BA/"><span class="tag">救灾机器人</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"><span class="tag">数字信号处理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90/"><span class="tag">数据处理分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%8F%91%E5%8A%A8%E6%9C%BA/"><span class="tag">斯特林发动机</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%BE%AA%E7%8E%AF/"><span class="tag">斯特林循环</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E4%BB%BF%E7%9C%9F/"><span class="tag">有限元仿真</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%AC%E5%BE%81%E5%80%BC%E6%B1%82%E8%A7%A3/"><span class="tag">本征值求解</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E8%87%82/"><span class="tag">机械臂</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E6%A2%B0%E8%AE%BE%E8%AE%A1/"><span class="tag">机械设计</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9F%94%E6%80%A7%E5%A5%97%E7%B4%A2%E6%83%A9%E7%BD%9A/"><span class="tag">柔性套索惩罚</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%BB%A4%E6%B3%A2%E5%99%A8/"><span class="tag">滤波器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%83%9F%E9%9B%BE%E6%89%A9%E6%95%A3/"><span class="tag">烟雾扩散</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%B5%E6%9C%BA%E6%8E%A7%E5%88%B6/"><span class="tag">电机控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="tag">线性代数</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E8%BF%87%E7%A8%8B%E6%8E%A7%E5%88%B6/"><span class="tag">统计过程控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"><span class="tag">自动控制原理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E5%8A%A8%E8%B0%83%E5%85%89/"><span class="tag">自动调光</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/"><span class="tag">自编码器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%88%B9/"><span class="tag">船</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="tag">计算机视觉</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1%E6%80%9D%E7%BB%B4/"><span class="tag">设计思维</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%9D%E7%A6%BB%E7%89%B9%E6%80%A7/"><span class="tag">距离特性</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"><span class="tag">路径规划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%97%AD%E7%8E%AF%E6%8E%A7%E5%88%B6/"><span class="tag">闭环控制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A2%91%E8%B0%B1%E5%88%86%E6%9E%90/"><span class="tag">频谱分析</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%AB%98%E6%96%AF%E6%A0%B8%E5%87%BD%E6%95%B0/"><span class="tag">高斯核函数</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a><p class="is-size-7"><span>&copy; 2025 Tim</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© Copyright by Jinghua Xu</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>
        <link rel="stylesheet" href="https://cdn1.tianli0.top/gh/zhheo/Post-Abstract-AI@0.15.2/tianli_gpt.css">
        <script>
        let tianliGPT_postSelector = 'article.article .content';
        let tianliGPT_key = '0c7949b4d4956ca16024';
        </script>
        <script src="https://cdn1.tianli0.top/gh/zhheo/Post-Abstract-AI@0.15.2/tianli_gpt.min.js"></script>
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=EcdeIC110ly5NqL8_Ofvg7uwL4-NE9F-lRhSp4--kPY"></script>
<!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>常微分方程反演的机器学习方法 - Homepage of Jinghua Xu</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Homepage of Jinghua Xu"><meta name="msapplication-TileImage" content="/img/photo.jpg"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Homepage of Jinghua Xu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="/img/photo.jpg"><meta name="description" content="选题背景与意义微分方程是数学中一个重要且广泛应用的领域，涉及到描述变化和相互关系的方程。它是一种包含导数或微分的方程，常用于自然现象建模以及解决科学和工程领域中的问题。微分方程研究是数学中的一个重要分支，涵盖了广泛的领域和应用。通过研究微分方程，我们可以理解和预测自然现象的行为，以及解决科学和工程中的实际问题。同时，微分方程的研究也促进了数学的发展和数学工具在其他学科中的应用。  常微分方程被广泛"><meta property="og:type" content="blog"><meta property="og:title" content="常微分方程反演的机器学习方法"><meta property="og:url" content="http://asgard-tim.github.io/2025/06/10/project3/"><meta property="og:site_name" content="Homepage of Jinghua Xu"><meta property="og:description" content="选题背景与意义微分方程是数学中一个重要且广泛应用的领域，涉及到描述变化和相互关系的方程。它是一种包含导数或微分的方程，常用于自然现象建模以及解决科学和工程领域中的问题。微分方程研究是数学中的一个重要分支，涵盖了广泛的领域和应用。通过研究微分方程，我们可以理解和预测自然现象的行为，以及解决科学和工程中的实际问题。同时，微分方程的研究也促进了数学的发展和数学工具在其他学科中的应用。  常微分方程被广泛"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://asgard-tim.github.io/images/project3/9.png"><meta property="article:published_time" content="2025-06-09T18:59:03.000Z"><meta property="article:modified_time" content="2025-07-01T15:22:18.826Z"><meta property="article:author" content="Tim"><meta property="article:tag" content="Python"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="常微分方程反演"><meta property="article:tag" content="多步神经网络"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://asgard-tim.github.io/images/project3/9.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://asgard-tim.github.io/2025/06/10/project3/"},"headline":"常微分方程反演的机器学习方法","image":["http://asgard-tim.github.io/images/project3/9.png"],"datePublished":"2025-06-09T18:59:03.000Z","dateModified":"2025-07-01T15:22:18.826Z","author":{"@type":"Person","name":"Tim"},"publisher":{"@type":"Organization","name":"Homepage of Jinghua Xu","logo":{"@type":"ImageObject","url":"http://asgard-tim.github.io/img/title1.png"}},"description":"选题背景与意义微分方程是数学中一个重要且广泛应用的领域，涉及到描述变化和相互关系的方程。它是一种包含导数或微分的方程，常用于自然现象建模以及解决科学和工程领域中的问题。微分方程研究是数学中的一个重要分支，涵盖了广泛的领域和应用。通过研究微分方程，我们可以理解和预测自然现象的行为，以及解决科学和工程中的实际问题。同时，微分方程的研究也促进了数学的发展和数学工具在其他学科中的应用。  常微分方程被广泛"}</script><link rel="canonical" href="http://asgard-tim.github.io/2025/06/10/project3/"><link rel="icon" href="/img/photo.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/xt256.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com">GitHub</a><a class="navbar-item" target="_blank" rel="noopener" title="Contect me on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2025-06-09T18:59:03.000Z" title="2025/6/10 02:59:03">2025-06-10</time>发表</span><span class="level-item"><time datetime="2025-07-01T15:22:18.826Z" title="2025/7/1 23:22:18">2025-07-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a><span>&nbsp;/&nbsp;</span><a class="link-muted" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">工程数值分析</a></span><span class="level-item">1 小时读完 (大约9294个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">常微分方程反演的机器学习方法</h1><div class="content"><div id="postchat_postcontent"><h2 id="选题背景与意义"><a href="#选题背景与意义" class="headerlink" title="选题背景与意义"></a>选题背景与意义</h2><p><strong>微分方程</strong>是数学中一个重要且广泛应用的领域，涉及到描述变化和相互关系的方程。它是一种包含导数或微分的方程，常用于自然现象建模以及解决科学和工程领域中的问题。微分方程研究是数学中的一个重要分支，涵盖了广泛的领域和应用。通过研究微分方程，我们可以<strong>理解和预测自然现象的行为</strong>，以及<strong>解决科学和工程中的实际问题</strong>。同时，微分方程的研究也促进了数学的发展和数学工具在其他学科中的应用。 </p>
<p>常微分方程被广泛应用于物理、生物、化学、经济学等各个领域。在许多情况下，观测数据是已知的，而其中隐含的微分方程仍然难以捉摸。因此，<strong>数据驱动的常微分方程(或动力系统)发现和反演</strong>是一个重要的研究方向。</p>
<p>微分方程反演问题是相对于微分方程的求解而言的：</p>
<ul>
<li>微分方程的求解通常是一个正向问题，即给定初始条件，求解关于未知函数的方程；</li>
<li>微分方程反演问题是指根据已知的结果，推导出产生这些结果的微分方程，是从结果向方程的逆向推导和反演。</li>
</ul>
<p>在数学上，微分方程的反演问题具有一系列的数学<strong>挑战和困难</strong>：</p>
<ul>
<li>反问题的<strong>病态性</strong>：微小扰动在反问题的输出中会导致较大的误差，因此需要稳定性分析和正则化方法来解决数值计算中的误差；</li>
<li>存在<strong>非唯一解</strong>情况：需要利用先验信息、约束条件和经验知识等来进行问题的约束和规定，以得到合理的解。</li>
</ul>
<p>微分方程反演问题研究在数学理论和实际应用中具有重要意义。通过解决微分方程的反演问题，我们可以从有限的观测数据中重建和推断未知的边界条件、初始条件或未知函数，从而深入理解系统的行为和性质，并提供科学、工程和医学等领域的相关应用。  </p>
<p>随着计算机技术的发展，数值计算和机器学习在微分方程反演问题研究中的应用也呈现出迅猛发展的趋势。传统的微分方程推断方法依赖于领域专家的知识和经验，而<strong>机器学习方法</strong>，如神经网络、深度学习和遗传算法等，<strong>可以自动从大量数据中学习模式和关系，从而更准确地推断出微分方程模型</strong>。如今我们可以获取到<strong>大规模的、高维度的数据集</strong>，这为从数据中推断微分方程提供了更多的信息和挑战。而传统的模型推断方法在处理大数据集时可能受到维度灾难和计算复杂度的限制。机器学习的强大计算能力和自适应建模能力为解决这些问题提供了新的思路。  </p>
<p>利用机器学习从数据中反演微分方程的方法可以分为两个方面：</p>
<ul>
<li>在<strong>模型选择</strong>方面，机器学习可以通过自动搜索和学习合适的微分方程模型，利用测度函数或结构特征来评估不同模型的性能，并选择最适合数据的微分方程模型；</li>
<li>在<strong>参数估计</strong>方面，机器学习可以利用大数据集中的样本来优化微分方程模型的参数，以最小化模型与实际数据之间的误差。</li>
</ul>
<p>利用机器学习从数据中反演微分方程是微分方程和机器学习交叉领域的重要研究方向。它利用机器学习的能力和大数据的优势，可以更准确地建模和预测复杂的动力学系统，推进科学研究和实际应用的发展。</p>
<p>针对常微分方程，目前<strong>常用的反演方法</strong>有如下几种：</p>
<ul>
<li><strong>高斯过程</strong>：将高斯过程置于状态函数之上，然后通过最大化边际对数似然性从数据中推断参数，这种方法适用于解决高维问题，但是对系统的形式有限制，并且仅用于估计系统的参数。</li>
<li><strong>符号回归</strong>：创建并更正与观测数据相对应的符号模型，为控制函数提供更具表现力的函数形式，但缺点是对于大型系统来说计算成本高，并可能容易过拟合。</li>
<li><strong>稀疏回归</strong>：找到候选基函数的稀疏组合来近似控制函数，其系数由最小二乘法或贝叶斯回归确定。这种方法提供系统的明确形式，不需要太多先验知识，但是依靠适当的候选函数；对于没有简单或稀疏表示的复杂动力系统来说可能是低效的。</li>
<li><strong>统计学习</strong>：通过最小化经验误差来学习系统在某个假设空间中的相互作用核，避免维度诅咒，可以发现非常高维度的系统，但是仅适用于具有交互作用的核函数的动力系统。</li>
<li><strong>物理信息神经网络（PINN）</strong>：一种新的深度学习方法，用于解决非线性偏微分方程的正问题和反问题。通过在前馈神经网络中嵌入由偏微分方程描述的物理信息，在不需要标签数据的情况下，将 PINN 训练为偏微分方程的近似解的代理模型。受此启发，进一步发展出了多步神经网络LMNets，这本质上是使用给定相点上的流映射提供的信息来反演动力系统种的未知控制函数f的一种逆过程。</li>
</ul>
<p>在数值分析中，发展<strong>高阶方法</strong>是许多应用中的一个重要课题。传统上，在求解动力系统时，高阶离散化技术，如线性多步法和龙格-库塔方法已经得到了发展。近年来，线性多步法也被用于动力系统的发现。随着使用深度学习的发现取得令人满意的进展，对它在动力系统发现的理论理解也在进一步发展。</p>
<p>基于以上所陈述的微分方程反演问题的研究现状，针对<strong>无显式方程的非线性系统</strong>这一在真实物理世界中更为广泛且常见的情形，我们希望基于高阶离散化技术<strong>线性多步法</strong>，结合<strong>多步神经网络LMNets</strong>这一深度学习方法，<strong>拟合和反演出数据背后的动力学物理规律</strong>。</p>
<h2 id="算法框架与原理"><a href="#算法框架与原理" class="headerlink" title="算法框架与原理"></a>算法框架与原理</h2><h3 id="研究对象——常微分方程（组）"><a href="#研究对象——常微分方程（组）" class="headerlink" title="研究对象——常微分方程（组）"></a>研究对象——常微分方程（组）</h3><p>首先明确我们的研究对象——常微分方程：<br>$$<br>\begin{aligned}&amp;\frac{dx(t)}{dt}=f(x(t),t),\&amp;x(t_{0})=x_{0}\end{aligned}<br>$$<br>上述式子是一个最简单的二维常微分方程示例，其中x(t) ∈ R是关于时间t的函数，函数关系由一个微分方程刻画，且给出了一定的初值条件以唯一确定函数x的表达式，从而能够真实地刻画物理过程随时间变化的发展情况。</p>
<p>事实上大多数时候我们需要观测的物理量远远不止x这一个，因此为了后续更容易推广到高维情形（后续无特别说明，均围绕自治常微分方程展开讨论），我们将上述的<strong>非自治常微分方程</strong>转化为向量化的<strong>自治常微分方程</strong>：<br>$$<br>\begin{aligned}&amp;\frac{d\boldsymbol{u}(t)}{dt}=\hat{f}(\boldsymbol{u}(t)),\&amp;\boldsymbol{u}(t_{0})=\boldsymbol{u}<em>{0}\end{aligned}<br>$$<br>其中：<br>$$<br>u=(x,y)\in\mathbb{R}^{D+1},\hat{f}=(f,1)^{T},u</em>{0}=(x_{0},t_{0})^{T}<br>$$<br>在反演问题中，已知在若干时刻节点t_1、t_2、…、t_n的解x的数据，我们一般不会希望直接解出x(t)的表达式，而是通过确定光滑函数f，从而利用给定的数据反演出微分方程。这样的传统是从简单的反演情形推广并沿用的，因为比起得到一个精确的函数表达式，我们更希望探究这个表达式背后的物理规律，而这往往离不开微分方程，因此保留微分方程的形式具有一定的必要性。</p>
<h3 id="多步神经网络"><a href="#多步神经网络" class="headerlink" title="多步神经网络"></a>多步神经网络</h3><p>线性多步法是用于微分方程数值求解的常用方法。传统上，它们用于求解给定常微分方程的解，可以称为微分方程的正问题。但线性多步法也可以用于反演给定解的原微分方程，属于微分方程的反问题，尤其是将线性多步法的经典数值方法与神经网络相结合，例如多步神经网络。</p>
<h4 id="线性多步法"><a href="#线性多步法" class="headerlink" title="线性多步法"></a>线性多步法</h4><p>线性多步法是求解常微分方程数值解的一种常见方法。随着计算机技术的发展，线性多步法得到更加广泛的应用。人们逐渐发现，在某些情况下，线性多步法可以提供更高的数值精度和数值稳定性。此外，线性多步法可以与其他数值方法（如龙格-库塔法）结合使用，互补彼此的优点。</p>
<p>对于上述常微分方程（非自治），设其中结点总数为N，<strong>时间间隔h</strong>为常数:<br>$$<br>h = t_{n + 1} - t_n, n = 1, …, N - 1<br>$$<br>则第n个结点的<strong>步长为M</strong>的线性多步法有以下公式：<br>$$<br>\sum_{m=0}^{M}[\alpha_{m}x_{n-m}+h\beta_{m}f(x_{n-m},t)]=0,n=M、\ldots、N, \alpha_{_M}\neq0<br>$$<br>使用线性多步法求解常微分方程时，必须<strong>选择初始的步长M值</strong>，以及<strong>确定系数α、β的不同方法</strong>，然后可以依次计算n≥M的近似值x_n。</p>
<p>事实上，根据确定系数的方法不同，线性多步法也分为多种类型，本项目中主要使用如下的三种常见的线性多步法：</p>
<ul>
<li><strong>Adams-Moulton 法</strong>：作为一种<strong>隐式</strong>方法，需要通过迭代或其他数值求解技术来解决每个时间步长的方程组。它在求解非刚性和刚性常微分方程时都表现良好，并且具有较高的数值稳定性，其精度随步长的减小而提高，但响应地可能会产生更高的计算代价。对于高阶常微分方程，Adams-Moulton 法需要结合相应的差分格式将高阶常微分方程转化为一阶方程组进行求解。</li>
</ul>
<p>$$<br>\sum_{m=0}^M\alpha_mx_{n-m}=h\sum_{m=0}^M\beta_mf(x_{n-m})<br>$$</p>
<ul>
<li><strong>Adams-Bashforth法</strong>：作为一种<strong>显式</strong>方法，在求解非刚性和刚性常微分方程时都表现良好，计算效率较高，并且容易实现，但可能会收到稳定性条件地限制，其精度随步长的减小而提高。对于高阶常微分方程，Adams-Bashforth法需要结合相应的差分格式将高阶常微分方程转化为一阶方程组进行求解。</li>
</ul>
<p>$$<br>\sum_{m=0}^M\alpha_mx_{n-m}=h\sum_{m=0}^M\beta_mf(x(t_{n-m}))<br>$$</p>
<ul>
<li><strong>后向微分公式法</strong>(Backward Differentiation Formula, <strong>BDF</strong>)：同样是一种<strong>隐式</strong>方法，但与Adams-Moulton法不同，后向微分公式法是通过解一个非线性方程组来得到当前时间步长的数值解。这个方程组可以用牛顿迭代等数值求解技术来解决。该方法具有较好的数值稳定性，其精度依赖于使用的插值多项式的阶数。一般来说，其高阶形式可以提供更高的精度，但也会增加计算的复杂性。它适用于求解非刚性和刚性常微分方程，并且在稳定性和数值精度方面通常有良好的表现。</li>
</ul>
<p>$$<br>\sum_{m=0}^{M}\alpha_{m}x_{n-m}=h\beta f(x(t_{n}))<br>$$</p>
<p>除此之外，即使采用同一种系数确定方式，选择的步长M不同，得到的系数α、β也有所不同。具体而言，本项目中针对以上三种线性多步法，分别选取步长M=2/3/4的三种情况进行实验测试，下面列出各方法对应不同步长时的系数情况：</p>
<p><img src="/images/project3/1.png" alt="线性多步法系数"></p>
<p>线性多步法的<strong>优点</strong>在于<u>其高阶的精度和较小的计算代价，可以有效地逼近微分方程的数值解</u>。但线性多步法可能会受到<u>稳定性和初始条件</u>的<strong>限制</strong>，选择适当的步长和求解方法非常重要。</p>
<h4 id="多步神经网络算法"><a href="#多步神经网络算法" class="headerlink" title="多步神经网络算法"></a>多步神经网络算法</h4><p>从线性多步法的公式中得到启发，可以用神经网络去反演常微分方程右端的f。通过相等时间间隔h的数值解x的数据训练神经网络，该神经网络的参数可以通过使以下均方误差损失函数MSE最小化来训练得到：<br>$$<br>MSE=\frac{1}{N-M+1}\sum_{n=M}^N\parallel y_n\parallel^2<br>$$<br>其中：<br>$$<br>y_n=\sum_{m=0}^M\left[\alpha_mu_{n-m}+h\beta_mf_{NN}(u_{n-m})\right],n=M,\ldots,N<br>$$<br>式中f_NN表示神经网络对函数f的近似，y_n也称为线性多步法（LMM）残差。</p>
<p>在Python中编写函数<code>train()</code>以封装多步神经网络的训练流程：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型训练 </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">u_tensor, model, loss_func, h, M</span>): </span><br><span class="line">    <span class="comment"># 参数说明：训练集u_tensor,待训练模型model,损失函数loss_func,时间步长h,步数M,最大训练次数EPOCH</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=LR)</span><br><span class="line">    loss_history = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):          </span><br><span class="line">        model.train()        </span><br><span class="line">        batch_u = u_tensor.to(device)        </span><br><span class="line">        train_loss = loss_func(batch_u, model, h, M)   </span><br><span class="line">        optimizer.zero_grad()      </span><br><span class="line">        train_loss.backward()    </span><br><span class="line">        optimizer.step()    </span><br><span class="line">        epoch_avg_loss = train_loss.item()         </span><br><span class="line">        loss_history.append(epoch_avg_loss) </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss_history</span><br></pre></td></tr></tbody></table></figure>

<p>其中<code>loss_func</code>即为上述定义的均方误差损失函数MSE：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_func</span>(<span class="params">u, model, h, M</span>):</span><br><span class="line">	<span class="comment"># 参数说明：模型输入数据u,待训练模型model,时间步长h,步数M</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据选定的方法确定系数α、β（示例：Adams-Moulton法，M=4）</span></span><br><span class="line">    alpha = [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    beta = [<span class="number">251</span>/<span class="number">720</span>, <span class="number">646</span>/<span class="number">720</span>, -<span class="number">264</span>/<span class="number">720</span>, <span class="number">106</span>/<span class="number">720</span>, -<span class="number">19</span>/<span class="number">720</span>]</span><br><span class="line">        </span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(M, <span class="built_in">len</span>(u)):</span><br><span class="line">        residual = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(M+<span class="number">1</span>):</span><br><span class="line">            u_nm = u[n - m].unsqueeze(<span class="number">0</span>)</span><br><span class="line">            f_nm = model(u_nm)</span><br><span class="line">            residual += alpha[m] * u[n - m] + h * beta[m] * f_nm.squeeze()</span><br><span class="line">        loss += torch.norm(residual) ** <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> loss / (<span class="built_in">len</span>(u) - M + <span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="基于多步神经网络改进的常微分方程反演算法"><a href="#基于多步神经网络改进的常微分方程反演算法" class="headerlink" title="基于多步神经网络改进的常微分方程反演算法"></a>基于多步神经网络<strong>改进</strong>的常微分方程反演算法</h3><h4 id="改进的多步神经网络算法"><a href="#改进的多步神经网络算法" class="headerlink" title="改进的多步神经网络算法"></a>改进的多步神经网络算法</h4><p>多步神经网络做出了比较理想的假设，即给出了所有的数值解数据是无噪声的，以及神经网络可以表示对常微分方程产生零残差的反演。这种假设是理想化的，我们可以在实际情况下使用改进的方法尝试发现未知常微分方程。  </p>
<p>对于多步神经网络，除线性多步法残差之外，如果神经网络能够满足一些通用近似性质，尤其是在多步神经网络反演法效果不佳的非自治常微分方程的反演问题中，可以扩展精确和完整数据的收敛结果。考虑到神经网络对函数近似的强大能力（见通用近似定理），这意味着至少在合适的光滑的常微分方程中存在良好的泛化误差。  </p>
<p>假设数据集为给定在若干时刻t_1、t_2、…、t_N的方程的数值解u的值，把每一时刻t_n对应的解u(t_n)记为u^(n)，而t_n对应的导数数据一般无从得知。当时间间隔h较小时，可用<strong>二阶中心差分法</strong>近似求出导数数据，记对于每一时刻t_n求出的导数数据为d^(n)，则：<br>$$<br>d^{(n)}=\begin{cases}(-3\boldsymbol{u}^{(n)}+4\boldsymbol{u}^{(n+1)}-\boldsymbol{u}^{(n+2)})/2h,\quad n=1,\(\boldsymbol{u}^{(n+1)}-\boldsymbol{u}^{(n-1)})/2h,\quad1&lt;n&lt;N,\(\boldsymbol{u}^{(n-2)}-4\boldsymbol{u}^{(n-1)}+3\boldsymbol{u}^{(n)})/2h,\quad n=N.&amp;\end{cases}<br>$$<br>显然二阶中心差分法求导数d^(n)的误差为o(h^2)。</p>
<p>对于常微分方程的反演，我们<strong>改进了多步神经网络的损失函数，其中既包含解数据，又包含导数数据</strong>：<br>$$<br>L=l_1(u,d)+l_2(u,d,f_{NN})<br>$$<br>其中：<br>$$<br>l_{1}=\frac{1}{N-M+1}\sum_{n=M}^{N}\left|\sum_{m=0}^{M}[\alpha_{m}u_{n-m}+h\beta_{m}f_{NN}(u_{n-m})]\right|^{2}<br>$$</p>
<p>$$<br>l_{2}=\frac{1}{N-M+1}\sum_{n=M}^{N}\left|f_{NN}(u_{n})-d_{n}\right|^{2}<br>$$</p>
<p>$$<br>n=M,\ldots,N<br>$$</p>
<p>式中向量范数采用二范数；u为数值解的数据，d为二阶中心差分法得到的导数数据，则有：</p>
<ul>
<li><strong>l_1</strong>：<strong>线性多步法残差</strong>，可以表示常微分方程的近似程度</li>
<li><strong>l_2</strong>：<strong>均方误差函数</strong>，可以表示网络结构的准确度</li>
</ul>
<p>把u^(n)作为输入，d^(n)作为期望输出进行训练，得到的f_NN即为对函数f的近似。训练流程与改进后的损失函数Python实现如下所示：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型训练 </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">u_tensor, model, loss_func, h, M</span>): </span><br><span class="line">    <span class="comment"># 参数说明：训练集u_tensor,待训练模型model,损失函数loss_func,时间步长h,步数M,最大训练次数EPOCH</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=LR)</span><br><span class="line">    loss_history = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">        model.train()</span><br><span class="line">        batch_u = u_tensor.to(device)</span><br><span class="line">        batch_d = d_tensor.to(device)</span><br><span class="line">        train_loss = loss_func(batch_u, batch_d, model, h, M)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        train_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        epoch_avg_loss = train_loss.item()</span><br><span class="line">        loss_history.append(epoch_avg_loss)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> loss_history</span><br></pre></td></tr></tbody></table></figure>

<p>可以看到，与改进前相比，在训练过程中增加了对二阶中心差分法得到的导数的相关计算，进一步利用了训练数据中的信息。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_func</span>(<span class="params">u, d, model, h, M</span>):</span><br><span class="line">    <span class="comment"># 参数说明：模型输入数据u,输入数据对应的真实微分数据d,待训练模型model,时间步长h,步数M</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据选定的方法确定系数α、β（示例：Adams-Moulton法，M=4）</span></span><br><span class="line">    alpha = [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    beta = [<span class="number">251</span>/<span class="number">720</span>, <span class="number">646</span>/<span class="number">720</span>, -<span class="number">264</span>/<span class="number">720</span>, <span class="number">106</span>/<span class="number">720</span>, -<span class="number">19</span>/<span class="number">720</span>]</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 多步法残差 l1</span></span><br><span class="line">    l1 = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(M, <span class="built_in">len</span>(u)):</span><br><span class="line">        residual = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(M+<span class="number">1</span>):</span><br><span class="line">            u_nm = u[n - m].unsqueeze(<span class="number">0</span>)</span><br><span class="line">            f_nm = model(u_nm)</span><br><span class="line">            residual += alpha[m] * u[n - m] + h * beta[m] * f_nm.squeeze()</span><br><span class="line">        l1 += torch.norm(residual) ** <span class="number">2</span></span><br><span class="line">    l1 = l1 / (<span class="built_in">len</span>(u) - M + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 导数拟合误差 l2</span></span><br><span class="line">    pred_d = model(u)</span><br><span class="line">    l2 = torch.mean(torch.norm(pred_d - d, dim=<span class="number">1</span>) ** <span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> l1 + l2  <span class="comment"># 总损失</span></span><br></pre></td></tr></tbody></table></figure>

<p>值得注意的是，针对非自治常微分方程，由于在将其变换为自治常微分方程时进行了升维操作，这意味着真实的导数向量在y=t这一分量上的值必然是1，因此后续在检验模型训练效果时可利用这一点对模型性能进行先决的把握。</p>
<h4 id="基于误差界理论论证改进算法的优越性"><a href="#基于误差界理论论证改进算法的优越性" class="headerlink" title="基于误差界理论论证改进算法的优越性"></a>基于误差界理论论证改进算法的优越性</h4><p>在上述损失函数中，l_1是对目标函数的良好近似，而l_2是神经网络中常用的损失函数。考虑到神经网络对函数近似的强大能力，这意味着即使对于噪声数据，改进的方法也应有良好的泛化能力和鲁棒性。在这里，我们先从理论上来论证改进方法在泛化能力与鲁棒性上的优越性，后续的数值实验部分将采用三类非自治方程的反演来验证改进的多步神经网络的效果。</p>
<p>对于二分类问题（可推广至函数近似的回归问题），当假设空间是有限个函数的集合F={f_1,f_2,…,f_d}时，对任意一个函数f∈F,至少以概率1-δ，以下不等式成立：<br>$$<br>R(f)\leq\hat{R}(f)+\varepsilon(d,N,\delta)<br>$$<br>其中：<br>$$<br>\begin{gathered}R(f)=E[L(Y,f(X))]\\hat{R}(f)=\frac{1}{N}\sum_{1}^{N}L(y_{i},f(x_{i}))\\varepsilon(d,N,\delta)=\sqrt{\frac{1}{2N}(\log d+\log\frac{1}{\delta})}\end{gathered}<br>$$<br>式中，R(f)为泛化误差（测试集上的测试风险），\hat{R}(f)为训练集上的经验风险，\hat{R}(f) + ε(d,N,δ)即为泛化误差界。观察上式可知，泛化误差界与样本数N成正比，与假设空间包含的函数数量d成反比。因此，当样本数N越大，泛化误差界越小，当假设空间F包含的函数越多，泛化误差界越大。</p>
<p>根据上述定理，针对改进后的神经网络，有如下不等式成立：<br>$$<br>\left|f_{NN}(u^{(n)})-\hat{f}(u^{(n)})\right|\leq\left|f_{NN}(u^{(n)})-d^{(n)}\right|+\left|\hat{f}(u^{(n)})-d^{(n)}\right|\leq w+o(h^{2})<br>$$<br>该不等式表明，改进后的损失函数可以拆解成两部分误差：</p>
<ul>
<li>第一部分为通过神经网络得到的导数近似值与通过二阶中心差分法求出的导数之间的误差，设该误差限为<strong>w</strong>；</li>
<li>第二部分为导数真实值与通过二阶中心差分法求出的导数之间的误差，根据二阶中心差分法的基本原理，其误差限为**o(h^2)**。</li>
</ul>
<p>显然改进后的多步神经网络的泛化误差相较改进前有了进一步的约束，尤其显著减小了<strong>噪声</strong>对模型的影响，具有<strong>更强的泛化能力和鲁棒性</strong>。</p>
<h2 id="数值实验与分析"><a href="#数值实验与分析" class="headerlink" title="数值实验与分析"></a>数值实验与分析</h2><p>为充分验证改进方法的泛化能力与鲁棒性，我们选取了六个实际的物理问题（对应常微分方程）作为测试用例，对应自治/非自治以及三种不同的线性多步法，在每一个测试用例内选取不同的线性多步法步数以及训练数据所含的高斯噪声方差，对改进前后的两种基于多步神经网络的常微分方程反演方法进行测试。下面我们以“受迫振动方程”这一用例详细展示测试流程，其他的测试用例仅作结果展示。</p>
<h3 id="数值实验流程"><a href="#数值实验流程" class="headerlink" title="数值实验流程"></a>数值实验流程</h3><h4 id="数据构建"><a href="#数据构建" class="headerlink" title="数据构建"></a>数据构建</h4><p>基于选定的测试用例对应的常微分方程，可采用如下步骤生成原始的真实数据集：</p>
<ol>
<li>在所给区域内均匀选取间隔为h的N个结点t_n,n=1,2,…,N ,使用Python中的Scipy库求出各结点对应的数值解u^(n)；</li>
<li>将数值解u^(n) 代入二阶中心差分法中得到每个x_n 对应的导数值d^(n) ；</li>
<li>噪声数据构建：在各结点对应的数值解u^(n) 上依次加上<strong>期望为0，方差为0、0.01、0.05的高斯噪声</strong>。</li>
</ol>
<p>在Python中，用函数<code>get_data()</code>函数实现了数据构建的代码封装：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>(<span class="params">t0, t_end, h, y0, noise_std=<span class="number">0.0</span></span>):     </span><br><span class="line">    t_eval = np.arange(t0, t_end + h, h)     </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数值解    </span></span><br><span class="line">    sol = solve_ivp(forced_oscillator, [t0, t_end], y0, t_eval=t_eval)    </span><br><span class="line">    x = sol.y.T  <span class="comment"># shape: [N, 2]     </span></span><br><span class="line">    t = sol.t.reshape(-<span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># shape: [N, 1]     </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 添加高斯噪声     </span></span><br><span class="line">    <span class="keyword">if</span> noise_std &gt; <span class="number">0</span>:         </span><br><span class="line">        x += np.random.normal(<span class="number">0</span>, noise_std, size=x.shape)      </span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 构造 u = [x1, x2, t]     </span></span><br><span class="line">    u = np.hstack([x, t])      </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 二阶中心差分求导数 d ≈ du/dt     </span></span><br><span class="line">    d = np.zeros_like(u)     </span><br><span class="line">    <span class="comment"># 边界点使用前向/后向差分     </span></span><br><span class="line">    d[<span class="number">0</span>] = (-<span class="number">3</span> * u[<span class="number">0</span>] + <span class="number">4</span> * u[<span class="number">1</span>] - u[<span class="number">2</span>]) / (<span class="number">2</span> * h)     </span><br><span class="line">    d[-<span class="number">1</span>] = (u[-<span class="number">3</span>] - <span class="number">4</span> * u[-<span class="number">2</span>] + <span class="number">3</span> * u[-<span class="number">1</span>]) / (<span class="number">2</span> * h)     </span><br><span class="line">    <span class="comment"># 内部点使用中心差分     </span></span><br><span class="line">    d[<span class="number">1</span>:-<span class="number">1</span>] = (u[<span class="number">2</span>:] - u[:-<span class="number">2</span>]) / (<span class="number">2</span> * h)      </span><br><span class="line">    </span><br><span class="line">    u_tensor = torch.tensor(u, dtype=torch.float32)     </span><br><span class="line">    d_tensor = torch.tensor(d, dtype=torch.float32)      </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> u_tensor, d_tensor, t<span class="comment"># 模型训练 </span></span><br></pre></td></tr></tbody></table></figure>

<p>以“受迫振动方程”这一测试框架为例，<code>force_oscillator</code>函数中刻画了该场景下的微分方程规律：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forced_oscillator</span>(<span class="params">t, y</span>):</span><br><span class="line">    x1, x2 = y</span><br><span class="line">    dx1dt = x2</span><br><span class="line">    dx2dt = -np.cos(t) * x1 - x2 + t / <span class="number">50</span></span><br><span class="line">    <span class="keyword">return</span> [dx1dt, dx2dt]</span><br></pre></td></tr></tbody></table></figure>

<p>生成的无噪声数据如下图所示：</p>
<p><img src="/images/project3/2.png" alt="受迫振动方程数据构建x1"></p>
<p><img src="/images/project3/3.png" alt="受迫振动方程数据构建x2"></p>
<h4 id="神经网络训练"><a href="#神经网络训练" class="headerlink" title="神经网络训练"></a>神经网络训练</h4><p>根据上述算法理论部分列出的训练流程框架，适用数据（u，d）对神经网络进行训练，训练后得到的函数f_NN即为对函数f的近似。</p>
<p>关于神经网络的结构与参数，本项目中所使用的<strong>神经网络结构</strong>均相同（后续不再赘述），均<strong>包含4个隐藏层，每层128个神经元，激活函数为tanh</strong>，Python中基于pytorch框架对神经网络架构的实现如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ODEApproximator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, hidden_dim=<span class="number">128</span>, output_dim=<span class="number">3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ODEApproximator, self).__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, hidden_dim),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(hidden_dim, hidden_dim),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(hidden_dim, hidden_dim),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(hidden_dim, hidden_dim),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(hidden_dim, output_dim)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br></pre></td></tr></tbody></table></figure>

<p>训练过程中实时记录了每一个epoch的损失函数值，下图分别绘制了改进前后的多步神经网络在无噪声数据集上训练过程中损失函数值的变化情况（总Epoch=100），可以看到损失函数均呈收敛态势，且改进后的多步神经网络收敛更快：</p>
<p><img src="/images/project3/4.png" alt="改进前多步神经网络训练过程损失函数值变化"></p>
<p><img src="/images/project3/5.png" alt="改进后多步神经网络训练过程损失函数值变化"></p>
<h4 id="效果检验"><a href="#效果检验" class="headerlink" title="效果检验"></a>效果检验</h4><p>为定量地比较改进前后的多步神经网络的泛化性能与鲁棒性，采取如下的实验步骤进行训练后模型的效果检验：</p>
<ol>
<li>用训练得到的函数f_NN解方程得到数值解u_NN^(n) ,观察近似效果，计算均方误差mse_x 和平均绝对误差mae_x并与多步神经网络作比较；</li>
<li>用数值解u^(n)代入训练得到的函数f_NN得到的导数的近似值d_NN^(n)，将u^(n)代入给定的常微分方程中的 f 得到导数的真实值d^(n),计算均方误差mse_f和平均绝对误差mae_f并与多步神经网络作比较。</li>
</ol>
<p>其中用于比较性能的指标均方误差mse和平均绝对误差mae的定义式如下所示：<br>$$<br>mse_{x}=\frac{1}{ND}\sum_{n=1}^{N}\left|u_{NN}^{(n)}-u^{(n)}\right|_{2}^{2}<br>$$</p>
<p>$$<br>mse_{f}=\frac{1}{ND}\sum_{n=1}^{N}\left|d_{NN}^{(n)}-d^{(n)}\right|_{2}^{2}<br>$$</p>
<p>$$<br>mae_{x}=\frac{1}{ND}\sum_{n=1}^{N}\left|u_{NN}^{(n)}-u^{(n)}\right|_{1}<br>$$</p>
<p>$$<br>mae_{f}=\frac{1}{ND}\sum_{n=1}^{N}\left|d_{NN}^{(n)}-d^{(n)}\right|_{1}<br>$$</p>
<p>Python中将利用训练好的模型进行预测的过程封装成函数<code>predict_u</code>，指标计算直接调用scikit-learn函数库中的相关函数：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rhs</span>(<span class="params">t, u_np</span>):      </span><br><span class="line">    <span class="string">"""用于 solve_ivp：输入 u = [x1, x2, t] 输出 du/dt"""</span>      </span><br><span class="line">    u_tensor = torch.tensor(u_np, dtype=torch.float32).unsqueeze(<span class="number">0</span>).to(device)      </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():          </span><br><span class="line">        du_dt = model(u_tensor).squeeze().cpu().numpy()      </span><br><span class="line">    <span class="keyword">return</span> du_dt    </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_u</span>(<span class="params">u_tensor</span>):      </span><br><span class="line">    <span class="comment"># 初始条件与时间点一致     </span></span><br><span class="line">    u0 = u_tensor[<span class="number">0</span>].cpu().numpy()  <span class="comment"># [x1, x2, t]    </span></span><br><span class="line">    t_span = (<span class="number">0</span>, <span class="number">100</span>)  </span><br><span class="line">    t_eval = np.arange(<span class="number">0</span>, <span class="number">100</span> + <span class="number">0.05</span>, <span class="number">0.05</span>)    </span><br><span class="line">    </span><br><span class="line">    sol_nn = solve_ivp(rhs, t_span, u0, t_eval=t_eval)   </span><br><span class="line">    <span class="keyword">return</span> sol_nn.y.T  <span class="comment"># shape: [N, 3]</span></span><br></pre></td></tr></tbody></table></figure>

<p>在“受迫振动方程”这一测试案例中，基于训练轮数Epoch=50的模型，运行以上检验流程，得到如下检验指标数据：</p>
<p><img src="/images/project3/6.png" alt="Epoch=50时数值解预测误差"></p>
<p>可以看到，随着<strong>噪声强度增加</strong>，两种方法的<strong>误差均增大</strong>，但<strong>改进方法对数值解的预测误差在各种情况下均小于多步神经网络</strong>。 </p>
<p><img src="/images/project3/7.png" alt="Epoch=50时导数值预测误差"></p>
<p>可以看到，当数据无噪声时，本文提出的<strong>改进方法</strong>对于受迫振动方程的<strong>近似效果强</strong>于多步神经网络;随着<strong>噪声强度的增加</strong>，<strong>多步神经网络的误差大幅增加</strong>，而<strong>改进的方法的误差一直保持较小</strong>且始终强于多步神经网络。</p>
<p>除此之外，针对在无噪声数据集上训练轮数分别为Epoch=100和Epoch=500时的模型，将其作为微分方程中的f用于预测数据的生成，效果分别如下图所示：</p>
<p><img src="/images/project3/8.png" alt="Epoch=100时预测效果与真实值对比"></p>
<p><img src="/images/project3/9.png" alt="Epoch=500时预测效果与真实值对比"></p>
<p>可以看到，随着训练轮数的增加，模型对于实际微分方程的拟合效果越来越好，生成的预测数据也越来越接近用于训练的真实数据；事实上，从理论上讲，大概在训练轮数Epoch达到10^4数量级时才会有较为精准的拟合效果，本项目由于用于训练的计算资源有限，仅进行了最大训练轮数为1000的测试。在后续的结果分析部分，将直接采用高训练轮数下的精确结果进行展示。</p>
<h3 id="数值实验结果分析"><a href="#数值实验结果分析" class="headerlink" title="数值实验结果分析"></a>数值实验结果分析</h3><h4 id="非自治常微分方程"><a href="#非自治常微分方程" class="headerlink" title="非自治常微分方程"></a>非自治常微分方程</h4><h5 id="受迫振动方程——Adams-Moulton法"><a href="#受迫振动方程——Adams-Moulton法" class="headerlink" title="受迫振动方程——Adams-Moulton法"></a>受迫振动方程——Adams-Moulton法</h5><p>受迫振动方程(Forced Oscillator)是描述一个振动系统在外界力的作用下进行振动的方程。这个方程可以用来研究各种物理系统中的振动现象，例如弹簧振子、摆锤、电路振荡等。受迫振动方程的核心思想是将外界力引入方程中，以描述振动系统在外界激励下的行为。受迫振动方程的研究对于科学、工程和技术领域具有重要意义。它不仅有助于我们深入理解振动现象的本质和规律，还为我们设计和优化振动控制系统、减振装置等提供了理论基础。同时，它在电子设备、结构工程、交通运输等方面也有广泛的应用。</p>
<p>实验使用的受迫振动方程如下：<br>$$<br>\begin{aligned}&amp;\frac{dx_1}{dt}=x_2,\&amp;\frac{dx_2}{dt}=-cosy\cdot x_1-x_2+\frac{y}{50},\&amp;\frac{dy}{dt}=1\end{aligned}<br>$$<br>使用[0,1,0]T作为初值，生成从t=0到t=100，间隔h=0.05的数据作为训练集，最终得到的多步神经网络对常微分方程的反演效果如下图所示，其中红色曲线是原方程数值解的曲线，蓝色点是用无噪声数据训练的函数f_NN代替f得到的数值解:</p>
<p><img src="/images/project3/10.png" alt="受迫振动方程反演效果"></p>
<h5 id="线性标量方程——Adams-Bashforth法"><a href="#线性标量方程——Adams-Bashforth法" class="headerlink" title="线性标量方程——Adams-Bashforth法"></a>线性标量方程——Adams-Bashforth法</h5><p>线性标量方程(Linear Scalar Equation)是一种描述某个未知函数与其导数之间的关系的方程，其中未知函数的导数的最高次数为1。线性标量方程是微分方程中的一类重要问题，它在数学物理等领域中有广泛应用。线性标量方程的研究对于数学、物理学和工程学等领域具有重要意义。它可以用来描述动力学系统的行为、传热和传质过程、量子力学中的波函数演化等。通过分析和求解线性标量方程，可以深入理解系统的特征、稳定性、渐近行为等，为问题的模拟、控制和优化提供理论基础。在现代科学和工程中，线性标量方程的研究得到了进一步推广和延伸。例如，非线性标量方程、偏微分方程等是线性标量方程的扩展和推广，它们更好地描述了一些复杂的物理现象和现实问题。</p>
<p>实验使用的线性标量方程如下：<br>$$<br>\frac{dx_1}{dt}=-x_1(sin4y+1)+cos\frac{y^2}{1000},<br>$$</p>
<p>$$<br>\frac{dy}{dt}=1<br>$$</p>
<p>使用[2,0]T作为初值，生成从t=0到t=20，间隔h=0.05的数据作为训练集，最终得到的多步神经网络对常微分方程的反演效果如下图所示，其中红色曲线是原方程数值解的曲线，蓝色点是用无噪声数据训练的函数f_NN代替f得到的数值解:</p>
<p><img src="/images/project3/11.png" alt="线性标量方程反演效果"></p>
<h5 id="食饵-捕食者模型方程——后向微分公式法"><a href="#食饵-捕食者模型方程——后向微分公式法" class="headerlink" title="食饵-捕食者模型方程——后向微分公式法"></a>食饵-捕食者模型方程——后向微分公式法</h5><p>食饵-捕食者模型(Predator-prey Model)是生态学中研究食物链和生物群落动力学的重要模型之一，描述了食物链中食饵(被捕食者)和捕食者之间的相互作用关系。这种模型的研究对于我们理解生态系统的稳定性、物种相互作用以及生态系统中物种数量的变化具有重要意义。通过食饵-捕食者模型，我们可以研究食饵与捕食者之间的数量关系以及它们之间的相互作用。一般来说，食饵的数量被认为是捕食者的食物来源，并且捕食者的数量受到食饵的供给和捕食行为的影响。该模型通常描述了食饵数量随时间的变化，以及捕食者数量随时间的变化。食饵-捕食者模型的研究对于生态学、环境保护和资源管理等领域具有重要意义。通过该模型，我们可以深入了解生态系统中物种数量的变化规律，从而预测物种灭绝和生态系统崩溃的风险，以及寻找保护和管理生物多样性的方法。</p>
<p>实验使用的食饵-捕食者模型方程如下：<br>$$<br>\begin{aligned}&amp;\frac{dx_1}{dt}=x_1-x_1\cdot x_2+sin\frac{y}{2}+cosy+2,\&amp;\frac{dx_2}{dt}=x_1\cdot x_2-x_2,\&amp;\frac{dy}{dt}=1\end{aligned}<br>$$<br>使用[3,3,0]T作为初值，生成从t=0到t=50，间隔h=0.05的数据作为训练集，最终得到的多步神经网络对常微分方程的反演效果如下图所示，其中红色曲线是原方程数值解的曲线，蓝色点是用无噪声数据训练的函数f_NN代替f得到的数值解:</p>
<p><img src="/images/project3/12.png" alt="食饵-捕食者模型方程反演效果"></p>
<h4 id="自治常微分方程"><a href="#自治常微分方程" class="headerlink" title="自治常微分方程"></a>自治常微分方程</h4><h5 id="线性常微分方程——Adams-Moulton法"><a href="#线性常微分方程——Adams-Moulton法" class="headerlink" title="线性常微分方程——Adams-Moulton法"></a>线性常微分方程——Adams-Moulton法</h5><p>线性常微分方程(Linear ODEs)是微分方程中的一类重要问题，它描述了未知函数及其导数之间的线性关系。线性常微分方程的研究对于数学、物理学和工程学等领域具有重要意义。它们出现在物理学中许多基础问题的数学描述中，例如弹簧振动、电路分析、传热过程等。在工程学中，线性常微分方程也广泛应用于控制系统的建模和分析。随着科学技术的发展，研究者提出了各种各样的数值方法和近似方法，以求解复杂的线性常微分方程。这些方法包括欧拉方法、龙格-库塔方法、有限差分方法、变分法等，它们为实际问题的求解提供了有效的数值工具。随着对非线性动力学系统的研究和认识的深入，研究者们开始将非线性常微分方程引入到线性常微分方程中，以描述更为复杂的现象和现实问题。</p>
<p>实验使用的线性常微分方程如下：<br>$$<br>\frac{dx_1}{dt}=x_1-4x_2,<br>$$</p>
<p>$$<br>\frac{dx_2}{dt}=4x_1-7x_2<br>$$</p>
<p>使用[0,-1]T作为初值，生成从t=0到t=10，间隔h=0.01的数据作为训练集，最终得到的多步神经网络对常微分方程的反演效果如下图所示，其中红色曲线是原方程数值解的曲线，蓝色点是用无噪声数据训练的函数f_NN代替f得到的数值解:</p>
<p><img src="/images/project3/13.png" alt="线性常微分方程反演效果"></p>
<h5 id="阻尼三次振子方程——Adams-Bashforth法"><a href="#阻尼三次振子方程——Adams-Bashforth法" class="headerlink" title="阻尼三次振子方程——Adams-Bashforth法"></a>阻尼三次振子方程——Adams-Bashforth法</h5><p>阻尼三次振子(Damped Cubic Oscillator)是一种物理系统，它描述了受到阻尼力和弹力作用的振动系统。阻尼指的是系统中存在能量损耗的因素，如摩擦力，它会导致振动的逐渐减弱；三次振子表示系统的势能函数是一个三次函数，它具有非线性的特性。阻尼三次振子最早出现在振动力学和非线性动力学的研究中。对于振动系统的研究是物理学、工程学和应用数学等领域的重要课题之一。阻尼三次振子的研究对于理解和预测复杂动力学系统的行为具有重要意义。通过分析阻尼三次振子的运动规律和稳定性，我们可以深入了解非线性振动系统的动力学特性，例如振动的周期性、混沌行为等。这些研究也为控制系统、电子电路、力学系统等领域的工程应用提供了参考和启示。 </p>
<p>实验使用的阻尼三次振子方程如下：<br>$$<br>\frac{dx_1}{dt}=-0.1x_1^3+2x_2^3,<br>$$</p>
<p>$$<br>\frac{dx_2}{dt}=-2x_1^3-0.1x_2^3<br>$$</p>
<p>使用[1,1]T作为初值，生成从t=0到t=25，间隔h=0.01的数据作为训练集，最终得到的多步神经网络对常微分方程的反演效果如下图所示，其中红色曲线是原方程数值解的曲线，蓝色点是用无噪声数据训练的函数f_NN代替f得到的数值解:</p>
<p><img src="/images/project3/14.png" alt="阻尼三次振子方程反演效果"></p>
<h5 id="阻尼简谐摆方程——后向微分公式法"><a href="#阻尼简谐摆方程——后向微分公式法" class="headerlink" title="阻尼简谐摆方程——后向微分公式法"></a>阻尼简谐摆方程——后向微分公式法</h5><p>阻尼简谐摆(Damped Pendulum)是一个经典力学中的物理系统，它由一个具有质量的物体通过一根轻质绳或杆与一个固定支点相连接组成。阻尼简谐摆在受到重力作用下，沿着一条弧线进行周期性振动。阻尼简谐摆的研究对于理解和预测振动系统的行为具有重要意义。通过分析阻尼简谐摆的运动规律和稳定性，我们可以深入了解振动系统在存在阻尼时的响应特性，例如振动的振幅、频率等。这些研究不仅在理论物理学中具有重要意义，也为工程学中的控制系统、机械振动和结构动力学等领域的应用提供了基础。</p>
<p>实验使用的阻尼简谐摆方程如下：<br>$$<br>\begin{aligned}&amp;\frac{dx_1}{dt}=x_2,\&amp;\frac{dx_2}{dt}=-\alpha x_2-\beta\sin x_1,\&amp;\alpha=0.2,\beta=8.91\end{aligned}<br>$$<br>使用[-1.193,-3.876]T作为初值，生成从t=0到t=20，间隔h=0.01的数据作为训练集，最终得到的多步神经网络对常微分方程的反演效果如下图所示，其中红色曲线是原方程数值解的曲线，蓝色点是用无噪声数据训练的函数f_NN代替f得到的数值解:</p>
<p><img src="/images/project3/15.png" alt="阻尼简谐摆方程反演效果"></p>
<h2 id="研究结论与创新"><a href="#研究结论与创新" class="headerlink" title="研究结论与创新"></a>研究结论与创新</h2><h3 id="研究结论"><a href="#研究结论" class="headerlink" title="研究结论"></a>研究结论</h3><p>本项目<strong>针对常微分方程的反演问题提出了一种基于多步神经网络改进的常微分方程反演算法</strong>，旨在<strong>从数据中提取内含的常微分方程</strong>。通过<strong>将导数数据融入训练数据</strong>，我们改进了多步神经网络的数据集，并<strong>优化了神经网络的损失函数</strong>，以<strong>提高模型的准确性和泛化能力</strong>。经过训练，改进的神经网络成功拟合原方程中的函数，实现了对非自治常微分方程的反演。我们还推导并讨论了改进算法的误差界。我们进一步将改进的算法应用于自治常微分方程反演，通过训练网络拟合原方程函数，拓展了算法在自治常微分方程反演中的适用性。  </p>
<p>本项目通过实验以非自治常微分方程中的受迫振动方程、线性标量方程和食饵-捕食者模型方程，以及自治常微分方程中的线性常微分方程、阻尼三次振子方程和阻尼简谐摆方程为例，展示了算法的有效性。在实验中，我们添加了不同强度的噪声，并利用改进算法对常微分方程进行反演。实验结果表明，<strong>改进方法在大多数情况下优于多步神经网络，在处理有噪声数据时表现更为出色</strong>。这些结果充分验证了本文提出的方法在反演问题中的可行性和优越性。</p>
<h3 id="研究方法创新性"><a href="#研究方法创新性" class="headerlink" title="研究方法创新性"></a>研究方法创新性</h3><p>传统方法通常利用多步神经网络来处理常微分方程的反演问题，主要集中在处理自治常微分方程，对于非自治常微分方程的反演效果不尽理想，特别是在使用带有噪声数据进行训练时表现不佳。本研究首次将研究重点聚焦于非自治常微分方程的反演，通过<strong>将非自治方程转化为自治方程</strong>的形式，提出了一种新的研究思路。针对带有噪声数据的方程反演问题，采用了<strong>改进损失函数</strong>的方法以提升算法的鲁棒性。此外，将这种新方法扩展应用于自治常微分方程的反演问题，结果显示其反演效果明显优于多步神经网络。这一新思路对解决常微分方程反演问题带来了一种新的方法。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 王开荣,杨大地编著.应用数值分析[M].高等教育出版社,2010.</p>
<p>[2] 付长铠.常微分方程反演的机器学习方法研究[D].长春工业大学,2024.</p>
<p>[3] Raissi M, Perdikaris P, Karniadakis G E. Multistep neural networks for data-driven discovery of nonlinear dynamical systems[J]. arXiv preprint arXiv:1801.01236, 2018.</p>
<p>[4] 李航. 统计学习方法[M]. 第二版. 北京：清华大学出版社, 2019.</p>
<p>[5] 陈新海, 刘杰, 万仟, 等. 一种改进的基于深度神经网络的偏微分方程求解方法[J]. 计算机工程与科学, 2022, 44(11): 1932-1940.</p>
</div></div><div class="article-licensing box"><div class="licensing-title"><p>常微分方程反演的机器学习方法</p><p><a href="http://asgard-tim.github.io/2025/06/10/project3/">http://asgard-tim.github.io/2025/06/10/project3/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Tim</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-06-10</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-07-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E5%8F%8D%E6%BC%94/">常微分方程反演</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%A4%9A%E6%AD%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">多步神经网络</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/wechat.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/alipay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/06/21/sweeping/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">SmartRobot扫地机器人</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2025/05/15/Survey/"><span class="level-item">A Survey on Vision-Language-Action Models for Embodied AI</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.16/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "4YfCkg9RY2bBZosr2CIG3MbR-gzGzoHsz",
            appKey: "yY6mlbvEevj97fBj9Ri4czpD",
            placeholder: "请多指教",
            avatar: "mm",
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: false,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#选题背景与意义"><span class="level-left"><span class="level-item">1</span><span class="level-item">选题背景与意义</span></span></a></li><li><a class="level is-mobile" href="#算法框架与原理"><span class="level-left"><span class="level-item">2</span><span class="level-item">算法框架与原理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#研究对象——常微分方程（组）"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">研究对象——常微分方程（组）</span></span></a></li><li><a class="level is-mobile" href="#多步神经网络"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">多步神经网络</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#线性多步法"><span class="level-left"><span class="level-item">2.2.1</span><span class="level-item">线性多步法</span></span></a></li><li><a class="level is-mobile" href="#多步神经网络算法"><span class="level-left"><span class="level-item">2.2.2</span><span class="level-item">多步神经网络算法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#基于多步神经网络改进的常微分方程反演算法"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">基于多步神经网络改进的常微分方程反演算法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#改进的多步神经网络算法"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">改进的多步神经网络算法</span></span></a></li><li><a class="level is-mobile" href="#基于误差界理论论证改进算法的优越性"><span class="level-left"><span class="level-item">2.3.2</span><span class="level-item">基于误差界理论论证改进算法的优越性</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#数值实验与分析"><span class="level-left"><span class="level-item">3</span><span class="level-item">数值实验与分析</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#数值实验流程"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">数值实验流程</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#数据构建"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">数据构建</span></span></a></li><li><a class="level is-mobile" href="#神经网络训练"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">神经网络训练</span></span></a></li><li><a class="level is-mobile" href="#效果检验"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">效果检验</span></span></a></li></ul></li><li><a class="level is-mobile" href="#数值实验结果分析"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">数值实验结果分析</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#非自治常微分方程"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">非自治常微分方程</span></span></a></li><li><a class="level is-mobile" href="#自治常微分方程"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">自治常微分方程</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#研究结论与创新"><span class="level-left"><span class="level-item">4</span><span class="level-item">研究结论与创新</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#研究结论"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">研究结论</span></span></a></li><li><a class="level is-mobile" href="#研究方法创新性"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">研究方法创新性</span></span></a></li></ul></li><li><a class="level is-mobile" href="#参考文献"><span class="level-left"><span class="level-item">5</span><span class="level-item">参考文献</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer=""></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/head2.png" alt="Jinghua Xu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jinghua Xu</p><p class="is-size-6 is-block">明月科创实验班人工智能专业 本科大三在读</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>重庆 重庆大学国家卓越工程师学院</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">37</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">24</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">102</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Asgard-Tim" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/u/6315188431"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/171895120"><i class="fab fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:20224546@stu.cqu.edu.cn"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Phone" href="tel:+86 19132050174"><i class="fas fa-phone"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/06/29/manufac/"><img src="/images/manufac/b99d7042c32e0662693c9051eb8316a5.jpg" alt="小提琴自动演奏机器人中的齿轮系统设计与制造"></a></figure><div class="media-content"><p class="date"><time datetime="2025-06-29T08:40:43.000Z">2025-06-29</time></p><p class="title"><a href="/2025/06/29/manufac/">小提琴自动演奏机器人中的齿轮系统设计与制造</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E5%88%B6%E9%80%A0/">产品制造</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/06/21/sweeping/"><img src="/images/sweeping/0c9ca142c80746ccde051fd86d54a57c.png" alt="SmartRobot扫地机器人"></a></figure><div class="media-content"><p class="date"><time datetime="2025-06-20T20:02:03.000Z">2025-06-21</time></p><p class="title"><a href="/2025/06/21/sweeping/">SmartRobot扫地机器人</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%BE%AE%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1/">微电路设计</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/06/10/project3/"><img src="/images/project3/9.png" alt="常微分方程反演的机器学习方法"></a></figure><div class="media-content"><p class="date"><time datetime="2025-06-09T18:59:03.000Z">2025-06-10</time></p><p class="title"><a href="/2025/06/10/project3/">常微分方程反演的机器学习方法</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">工程数值分析</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/15/Survey/"><img src="/images/survey/2.png" alt="A Survey on Vision-Language-Action Models for Embodied AI"></a></figure><div class="media-content"><p class="date"><time datetime="2025-05-15T15:32:03.000Z">2025-05-15</time></p><p class="title"><a href="/2025/05/15/Survey/">A Survey on Vision-Language-Action Models for Embodied AI</a></p><p class="categories"><a href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/09/PaLM-E/"><img src="/images/palm-e/0.png" alt="PaLM-E：An Embodied Multimodal Language Model"></a></figure><div class="media-content"><p class="date"><time datetime="2025-05-09T11:57:03.000Z">2025-05-09</time></p><p class="title"><a href="/2025/05/09/PaLM-E/">PaLM-E：An Embodied Multimodal Language Model</a></p><p class="categories"><a href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/About-XJH/"><span class="level-start"><span class="level-item">About XJH</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E6%85%B5/"><span class="level-start"><span class="level-item">明慵</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E8%AF%9A/"><span class="level-start"><span class="level-item">明诚</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">个人项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">具身智能论文阅读</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">动手学深度学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/"><span class="level-start"><span class="level-item">算法基础课</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">课程项目</span></span><span class="level-end"><span class="level-item tag">26</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E5%88%B6%E9%80%A0/"><span class="level-start"><span class="level-item">产品制造</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">产品设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95I/"><span class="level-start"><span class="level-item">定量工程设计方法I</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95II/"><span class="level-start"><span class="level-item">定量工程设计方法II</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E6%95%88%E5%AD%A6/"><span class="level-start"><span class="level-item">工效学</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">工程原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">工程数值分析</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">工程设计</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%BE%AE%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">微电路设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95/"><span class="level-start"><span class="level-item">数学物理方法</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">智能图像处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">机器人基础</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><span class="level-start"><span class="level-item">概率论与数理统计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="level-start"><span class="level-item">线性代数</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">自动控制原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">软件设计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">六月 2025</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/05/"><span class="level-start"><span class="level-item">五月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">三月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">一月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">七月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">六月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">三月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"><span class="tag">单片机</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/STM32/"><span class="tag">STM32</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLA/"><span class="tag">VLA</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/"><span class="tag">具身智能</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">多模态大模型</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%8F%91%E5%8A%A8%E6%9C%BA/"><span class="tag">斯特林发动机</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MATLAB/"><span class="tag">MATLAB</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matlab/"><span class="tag">Matlab</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">动手学深度学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="tag">学习笔记</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E8%BD%A6/"><span class="tag">小车</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/"><span class="tag">信号与系统</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A2%91%E8%B0%B1%E5%88%86%E6%9E%90/"><span class="tag">频谱分析</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%BE%AA%E7%8E%AF/"><span class="tag">斯特林循环</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E5%8A%9B%E5%AD%A6%E4%BB%BF%E7%9C%9F/"><span class="tag">动力学仿真</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E4%BB%BF%E7%9C%9F/"><span class="tag">有限元仿真</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="tag">算法与数据结构</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/3D-VLA/"><span class="tag">3D-VLA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PaLM-E/"><span class="tag">PaLM-E</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"><span class="tag">路径规划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RANSAC/"><span class="tag">RANSAC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90/"><span class="tag">数据处理分析</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a><p class="is-size-7"><span>© 2025 Tim</span>&nbsp;&nbsp;Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>&nbsp;&amp;&nbsp;<a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© Copyright by Jinghua Xu</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer=""></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer=""></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer=""></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer=""></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer=""></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer=""></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer=""></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer=""></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script>
    <link rel="stylesheet" href="https://ai.tianli0.top/static/public/postChatUser_summary.min.css">
    <script>
        let tianliGPT_key = 'S-TA3IX28M1ZT7TILW';
        let tianliGPT_postSelector = '#postchat_postcontent';
        let tianliGPT_Title = '文章摘要';
        let tianliGPT_postURL = '/^https?://[^/]+/[0-9]{4}/[0-9]{2}/[0-9]{2}/';
        let tianliGPT_blacklist = '';
        let tianliGPT_wordLimit = '1000';
        let tianliGPT_typingAnimate = true;
        let tianliGPT_theme = 'default';
        var postChatConfig = {
          backgroundColor: "#3e86f6",
          bottom: "16px",
          left: "16px",
          fill: "#FFFFFF",
          width: "44px",
          frameWidth: "375px",
          frameHeight: "600px",
          defaultInput: true,
          upLoadWeb: true,
          showInviteLink: true,
          userTitle: "PostChat",
          userDesc: "如果你对网站的内容有任何疑问，可以来问我哦～",
          addButton: true,
          beginningText: "这篇文章介绍了",
          userIcon: "https://ai.tianli0.top/static/img/PostChat.webp",
          userMode: "magic",
          defaultChatQuestions: ["你好","你是谁"],
          defaultSearchQuestions: ["视频压缩","设计"]
        };
    </script>
    <script data-postchat_key="S-TA3IX28M1ZT7TILW" src="https://ai.tianli0.top/static/public/tianli_gpt.min.js"></script>
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=EcdeIC110ly5NqL8_Ofvg7uwL4-NE9F-lRhSp4--kPY"></script>
  <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>
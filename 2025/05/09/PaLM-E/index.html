<!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>PaLM-E：An Embodied Multimodal Language Model - Homepage of Jinghua Xu</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Homepage of Jinghua Xu"><meta name="msapplication-TileImage" content="/img/photo.jpg"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Homepage of Jinghua Xu"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="/img/photo.jpg"><meta name="description" content="Date：2023-3-6 论文主页：https:&amp;#x2F;&amp;#x2F;palm-e.github.io&amp;#x2F; 论文链接：PaLM-E: An Embodied Multimodal Language Model 模型架构实现：kyegomez&amp;#x2F;PALM-E: Implementation of “PaLM-E: An Embodied Multimodal Language Model” 提出大型具身多模态"><meta property="og:type" content="blog"><meta property="og:title" content="PaLM-E：An Embodied Multimodal Language Model"><meta property="og:url" content="http://asgard-tim.github.io/2025/05/09/PaLM-E/"><meta property="og:site_name" content="Homepage of Jinghua Xu"><meta property="og:description" content="Date：2023-3-6 论文主页：https:&amp;#x2F;&amp;#x2F;palm-e.github.io&amp;#x2F; 论文链接：PaLM-E: An Embodied Multimodal Language Model 模型架构实现：kyegomez&amp;#x2F;PALM-E: Implementation of “PaLM-E: An Embodied Multimodal Language Model” 提出大型具身多模态"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://asgard-tim.github.io/images/palm-e/0.png"><meta property="article:published_time" content="2025-05-09T11:57:03.000Z"><meta property="article:modified_time" content="2025-07-01T15:58:18.205Z"><meta property="article:author" content="Tim"><meta property="article:tag" content="VLA"><meta property="article:tag" content="具身智能"><meta property="article:tag" content="多模态大模型"><meta property="article:tag" content="PaLM-E"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://asgard-tim.github.io/images/palm-e/0.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://asgard-tim.github.io/2025/05/09/PaLM-E/"},"headline":"PaLM-E：An Embodied Multimodal Language Model","image":["http://asgard-tim.github.io/images/palm-e/0.png"],"datePublished":"2025-05-09T11:57:03.000Z","dateModified":"2025-07-01T15:58:18.205Z","author":{"@type":"Person","name":"Tim"},"publisher":{"@type":"Organization","name":"Homepage of Jinghua Xu","logo":{"@type":"ImageObject","url":"http://asgard-tim.github.io/img/title1.png"}},"description":"Date：2023-3-6 论文主页：https:&#x2F;&#x2F;palm-e.github.io&#x2F; 论文链接：PaLM-E: An Embodied Multimodal Language Model 模型架构实现：kyegomez&#x2F;PALM-E: Implementation of “PaLM-E: An Embodied Multimodal Language Model” 提出大型具身多模态"}</script><link rel="canonical" href="http://asgard-tim.github.io/2025/05/09/PaLM-E/"><link rel="icon" href="/img/photo.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/xt256.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">时间轴</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com">GitHub</a><a class="navbar-item" target="_blank" rel="noopener" title="Contect me on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2025-05-09T11:57:03.000Z" title="2025/5/9 19:57:03">2025-05-09</time>发表</span><span class="level-item"><time datetime="2025-07-01T15:58:18.205Z" title="2025/7/1 23:58:18">2025-07-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></span><span class="level-item">41 分钟读完 (大约6130个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">PaLM-E：An Embodied Multimodal Language Model</h1><div class="content"><div id="postchat_postcontent"><p>Date：2023-3-6</p>
<p>论文主页：<a target="_blank" rel="noopener" href="https://palm-e.github.io/">https://palm-e.github.io/</a></p>
<p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.03378">PaLM-E: An Embodied Multimodal Language Model</a></p>
<p>模型架构实现：<a target="_blank" rel="noopener" href="https://github.com/kyegomez/PALM-E">kyegomez/PALM-E: Implementation of “PaLM-E: An Embodied Multimodal Language Model”</a></p>
<p>提出大型具身多模态模型PaLM-E（-562B），直接将现实世界的连续传感器模态（视觉【<strong>图像</strong>】+<strong>连续状态</strong>估计）<strong>融入</strong>语言模型（<strong>文本</strong>输入），从而建立词语与感知之间的联系。在<u>预训练的大型语言模型基础</u>上，端到端地训练【图像+连续状态+文本】的混合编码语句，用于机器人操作顺序规划（推理）、视觉问答（VQA）、图像/视频场景描述等具身任务，将视觉-语言领域的知识迁移到具身推理中。</p>
<p>该模型可基于多种观察模态，在多种具身设备上处理各种具身推理任务，并且具有良好的正向迁移性能【模型受益于跨互联网规模的语言、视觉和视觉-语言领域的多样化联合训练】。在机器人任务上训练后的模型还<strong>具有很好的视觉-语言通用性</strong>，在OK-VQA数据集上达到了SOTA，并且在参数规模增加时保留了通用的语言能力。</p>
<p>images/palm-e/<img src="/images/palm-e/0.png" alt="approach"></p>
<blockquote>
<p>连续状态：来自于机器人的各种传感器的观测结果</p>
<p>VQA【visual-question-answering】：一种基本的多模态任务，结合视觉信息回答问题（V-Q为输入，A为输出）</p>
<p><a target="_blank" rel="noopener" href="https://okvqa.allenai.org/">OK-VQA</a>：基于外部知识的VQA数据集，在COCO数据集上改进补充而来</p>
</blockquote>
<p><img src="/images/palm-e/1.png" alt="VQA example"></p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><ul>
<li>尽管LLM具有强大的推理能力，在海量文本数据上训练的LLM其生成结果可能会与真实物理世界产生关联，但针对更广泛的现实世界问题（CV/Robotics, etc.），在实际应用落地时，显然更重要的是<strong>将LLM生成的表示结果和现实世界的视觉和物理传感器模态连接起来</strong>。</li>
<li>先前的工作在决策时简单地将LLM的输出与学习到的机器人执行策略和可供函数连接起来，但受限于LLM本身仅提供文本输入，这在许多场景几何配置重要的任务中是不够的。</li>
<li>当前最先进的视觉-语言模型在典型的视觉-语言任务（如VQA）上训练后，无法直接解决机器人推理任务。</li>
</ul>
<blockquote>
<p>可供函数（affordance function）：描述事物提供的行为可能</p>
</blockquote>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Multi-model-sentences——不同模态的对齐"><a href="#Multi-model-sentences——不同模态的对齐" class="headerlink" title="Multi-model sentences——不同模态的对齐"></a>Multi-model sentences——不同模态的对齐</h3><p>显然要将高维的感知数据降到和文本相同的维度直接嵌入会造成较大程度的失真，因此所谓的对齐是<strong>将文本Token和连续感知状态都映射到同一个嵌入空间χ中</strong>，对于不同的数据需要采用不同的映射方法。</p>
<p><img src="/images/palm-e/1.jpg" alt="模态对齐"></p>
<h4 id="Token-embedding-space——将文本映射至嵌入空间"><a href="#Token-embedding-space——将文本映射至嵌入空间" class="headerlink" title="Token embedding space——将文本映射至嵌入空间"></a>Token embedding space——将文本映射至嵌入空间</h4><p>对于单个文本token ω而言，需要通过映射γ将其映射到嵌入空间χ中的k维向量x中：<br>$$<br>x_{i}=\gamma(w_{i})\in R^{k}<br>$$<br>在本模型中，设定的文本总长度（token数量）为W=256000，显然嵌入空间χ为一个规模为k*W的矩阵。</p>
<p>对于具体的计划任务，PaLM-E必须能够在其生成的计划中引用对象。在简单的场景下，往往可以使用很简短的语言准确指向某一个物体对象，而在复杂场景下特别是具有较多相似物体的情况下则不能使用很简短的语言准确的指向某一个物体。针对这一问题，提出<strong>Entity Referrals 方法</strong>（类似取代号），用于解决物体描述非常长的情况下的编码问题：</p>
<p>在数据的最前面部分（输入提示prompt中）添加上对每个具体物体的描述（多模态标记），如：</p>
<figure class="highlight text"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Object_1 is &lt;obj_1&gt;. ... Object_j is &lt;obj_j&gt;.</span><br></pre></td></tr></tbody></table></figure>

<p>其中 <code>Object_1</code> 和 <code>Object_j</code> 分别指代一个具体的物品，<code>&lt;obj_1&gt;</code> 和 <code>&lt;obj_j&gt;</code> 分别是对这两个物品的详细描述。</p>
<p>该方法使得PaLM-E能够在其生成的输出语句中通过 <code>&lt;obj_j&gt;</code> 形式的特殊标记来引用对象，后面的文本中再需要使用某个物品时就直接使用 <code>Object_j</code> 来代指，而不用再写出<code>&lt;obj_j&gt;</code> 的复杂描述。</p>
<h4 id="不同传感器的数据映射"><a href="#不同传感器的数据映射" class="headerlink" title="不同传感器的数据映射"></a>不同传感器的数据映射</h4><p>和文本相比，显然将不同传感器观测到的多种连续状态对齐到嵌入空间χ的难度要高很多，这里先根据传感器观测到的信息规格类型对其编码策略做简单的讨论：</p>
<h5 id="状态值（状态向量）"><a href="#状态值（状态向量）" class="headerlink" title="状态值（状态向量）"></a>状态值（状态向量）</h5><p>最简单的情况——传感器的观测结果直接就是单个/多个状态值  【 e.g. 坐标、位置、大小、颜色……  】</p>
<p>这种输入数据可以直接转为向量，可能还需要做一些归一化、对齐之类的操作；可以通过MLP（多层感知机，一个/多个全连接层）将该状态向量的维度进行转换，从而映射到嵌入空间χ中。</p>
<h5 id="图像类数据"><a href="#图像类数据" class="headerlink" title="图像类数据"></a>图像类数据</h5><p>针对观测结果是图像类数据，直接使用比较成熟的 <strong>ViT（Vision Transformer）</strong> 模型（需事先进行图像分类的预训练）进行编码，将图像映射为多个token嵌入。</p>
<p>注意：ViT编码后的维数不一定和嵌入空间χ相同，还需要通过仿射变换ψ（参数需训练）将其投影至嵌入空间χ中。</p>
<p>待选择的编码方案：</p>
<ul>
<li>ViT-4B</li>
<li>ViT-22B</li>
<li>ViT + TL（TokenLearner）</li>
</ul>
<blockquote>
<p>TokenLearner：由于图像类数据维度是2维的，如果直接使用像素点进行编码的话形成的token序列会非常长，而transformer架构对长序列的运算速度非常慢。针对这个问题，Google提出了TokenLearner方法，该方法能够自适应的学习输入图片或视频中的重要区域，然后主要对这些重要区域进行tokenize编码，以达到只需要少量的token就足以表征所有的视觉特征的目的，既降低了计算复杂度，又提升了指标。</p>
<p>针对ViT + TL架构，对其从头开始进行端到端训练。</p>
</blockquote>
<p>和文本输入不同，视觉输入之间往往不具有有意义的实体和关系。虽然ViT可以捕捉语义，但表示的结构类似于彼此相同的静态网格，而不是对象实例的集合，这意味着往往会把片中的一个对象划分成了多个部分，从而对与经过符号预训练的LLM接口以及解决需要与物理对象交互的具体推理都提出了挑战。针对这一问题，提出<strong>结构化编码器Object Centric Representations</strong>，在将视觉输入注入LLM之前将其分离成不同的对象，并在后续的划分过程中以图片中的每个对象为中心进行划分：<br>$$<br>x_{1:m}^{j}=\phi_{\mathrm{ViT}}(M_{j}\circ I)<br>$$<br>对于对象j，式中Mj为该对象实例的掩码，将其与原图像I相乘即可将该对象实例分割出来。</p>
<p>另一种不需要真实标注分割的方法是<strong>OSRT（Object Scene Representation Transformer）</strong>：不依赖于关于对象的外部知识，而是通过架构中的归纳偏差以无监督的方式发现。基于SRT模型，OSRT通过新的视图合成任务来学习数据域内以3D为中心的神经场景表示。</p>
<p>注意：针对于<strong>连续的观察数据</strong>，每个对象总是会通过<strong>MLP编码器ϕ（需训练）</strong>映射为<strong>多个嵌入</strong>，再对齐到嵌入空间χ。</p>
<hr>
<p>将以上的文本数据和感知数据映射到相同的嵌入空间χ后，还需要<strong>将感知数据嵌入到文本数据中</strong>：</p>
<p>将映射后的连续感知向量与普通嵌入文本标记交错，以形成LLM的前缀prefix，其中的每个向量 xi 由单词标记嵌入器 γ 或编码器 ϕi 构成：<br>$$<br>x_i=\left{\begin{array}{ll}\gamma\left(w_i\right)&amp;\quad\mathrm{if}\text{ i a is text token, or}\\phi_j\left(O_j\right)_i&amp;\quad\mathrm{if}\text{ i corresponds to observation}O_j\end{array}\right.<br>$$<br>显然单个观测（状态值/图像） Oj 通常被编码为多个嵌入向量。</p>
<p>可以在前缀中的不同位置交错不同的编码器 ϕi ，以<u>组合来自不同观测空间的信息</u>。以这种方式将连续信息注入LLM将重用其现有的位置编码。与其他VLM方法相比，这种嵌入没有插入固定位置，而是动态地放置在周围文本中。</p>
<h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h3><p><strong>基本思想</strong>：将具身代理的<strong>传感器模态</strong>的连续输入<strong>融入语言模型</strong>，将连续的、具身的观察（如图像、位姿估计或其他传感器模态）添加到预训练语言模型的语言嵌入空间中，从而使语言模型本身能够为现实世界中的顺序决策做出更为基础的推断。</p>
<p><strong>实现方式</strong>：基于预训练语言模型<a target="_blank" rel="noopener" href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html">PaLM</a>（decoder-only）【PaLM-E：PaLM +  <strong>E</strong>mbodied】，将连续状态观测编码为与输入文本<strong>维度相同</strong>的向量序列，作为语言标记的嵌入空间【以类似于语言标记的方式<strong>将连续信息注入到语言模型中</strong>，<u>多模态的信息与文本可能是交错的</u>】，并由基于Transformer的LLM的自注意力层以与纯文本相同的方式进行处理，在给定前缀提示词prefix prompt的情况下<em>自回归地（autoregressive，用已生成的词来预测下一个位置的词）</em>生成<strong>文本</strong>。</p>
<blockquote>
<p>注意：该模型仅有文本输出，既可以是经典VQA任务中的回答，也可以表示机器人的决策/计划（任务分解）以控制机器人的底层执行行为（模型仅输出决策，套用现有的转化器将决策转化为底层行为）；后者是本文研究的重点，但该模型在前者中也取得了SOTA的结果。</p>
</blockquote>
<h4 id="Decoder-only-LLM"><a href="#Decoder-only-LLM" class="headerlink" title="Decoder-only LLM"></a>Decoder-only LLM</h4><p>通过大型Transformer网络p_LM，在给定前面文本序列的情况下，预测概率p（各token的联合概率）最大的下一段文本（文本由一系列token ω_l表示）：<br>$$<br>p\left(w_{1:L}\right)=\prod_{l=1}^Lp_{\mathrm{LM}}\left(w_l\mid w_{1:l-1}\right)<br>$$</p>
<h4 id="Prefix-decoder-only-LLM"><a href="#Prefix-decoder-only-LLM" class="headerlink" title="Prefix-decoder-only LLM"></a>Prefix-decoder-only LLM</h4><p>在原有Decoder-only LLM架构基础上，在每条文本数据前添加一段前缀提示词prefix prompt（离散/连续）【通常包含任务描述或类似任务的文本示例】，以其为条件进行后续预测：<br>$$<br>p\left(w_{n+1:L}\mid w_{1:n}\right)=\prod_{l=n+1}^Lp_{\mathrm{LM}}\left(w_l\mid w_{1:l-1}\right)<br>$$</p>
<blockquote>
<p>位置1~n：prefix prompt</p>
<p>位置n+1~L：输入的文本数据</p>
<p>训练时prefix prompt不参与loss计算</p>
</blockquote>
<h4 id="模型在机器人控制环中的输出"><a href="#模型在机器人控制环中的输出" class="headerlink" title="模型在机器人控制环中的输出"></a>模型在机器人控制环中的输出</h4><p>为了将模型的输出连接到机器人控制实例，主要有两种情况：</p>
<ul>
<li>如果任务可以通过仅输出文本来完成（VQA/场景描述任务），则模型的输出被直接认为是任务的解决方案；</li>
<li>如果用于解决一个具体的计划或控制任务，它会生成一个文本来调节低级命令。</li>
</ul>
<blockquote>
<p>用简单的词汇表来执行低级技能的策略，模型输出的有效策略文本应为一系列低级技能的组合，对低级策略进行排序和控制。对于复杂的任务或指令，可能需要额外采用模型实现转换。这里假设低级策略可以直接操作物体对象的tokens，而不需要对于单个物体对象再进行拆分和转换。</p>
<p>PaLM-E实际上仅作为整个机器人控制中的上层决策模块，机器人控制环中还应有对应上层决策结果中的各低级策略的执行机构。</p>
<p>注意：模型必须根据训练数据和提示自行确定哪些技能可用，并且不使用其他机制来约束或过滤其输出。因此，模型训练时应放到整个机器人控制环中进行整体观测，根据执行结果动态调整上层决策模块PaLM-E生成的行为规划。</p>
</blockquote>
<h3 id="模型训练方法"><a href="#模型训练方法" class="headerlink" title="模型训练方法"></a>模型训练方法</h3><h4 id="训练数据集"><a href="#训练数据集" class="headerlink" title="训练数据集"></a>训练数据集</h4><p><strong>训练数据集</strong>可以表示为：<br>$$<br>D=\left{\left(I_{1:u_{i}}^{i},w_{1:L_{i}}^{i},n_{i}\right)\right}_{i=1}^{N}<br>$$<br>其中：</p>
<ul>
<li>i：第i条数据</li>
<li>L：一条数据的总长度【文本+连续状态编码后的结果】</li>
<li>u：一条数据中有多少个通过传感器观测到的连续状态</li>
<li>n：一条数据中 prefix prompt 部分的长度</li>
<li>I：通过传感器观测到的连续状态</li>
<li>ω：文本token</li>
</ul>
<p>每条数据以文本为主体，基于文本中的特殊标记，用编码器的嵌入向量取代这些标记在原文本中的位置，从而把图像、连续状态都串成一条数据。显然每个图像经过嵌入层之后会被转化为多少个向量是固定的，所以只要给每个图像预留上对应个数的位置即可。</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h4><p>在各非前缀tokens（n+1及之后位置）上平均的<strong>交叉熵损失</strong>（每条数据的前 ni 个位置是prefix prompt，不计算损失）</p>
<h4 id="模型参数规模"><a href="#模型参数规模" class="headerlink" title="模型参数规模"></a>模型参数规模</h4><p>将PaLM的不同预训练参数变体作为Decoder-only-LLM，通过编码器将连续观测值注入其中，这些编码器要么经过预训练，要么从头开始训练（见模态对齐部分）。</p>
<p>基于不同的PaLM预训练参数规模，得到了以下几种PaLM-E模型：</p>
<ul>
<li>PaLM-E-12B：8B PaLM + 4B ViT</li>
<li>PaLM-E-84B：62B PaLM + 22B ViT</li>
<li>PaLM-E-562B：540B PaLM + 22B ViT</li>
</ul>
<h4 id="模型冻结"><a href="#模型冻结" class="headerlink" title="模型冻结"></a>模型冻结</h4><p>本文中的整个模型系统可以分为三部分：</p>
<ul>
<li>解码器Encoder，用 ϕ 表示；</li>
<li>MLP（用于维度转换），用 ψ 表示；</li>
<li>LLM，用 pLM 表示。</li>
</ul>
<p>考虑如下事实：如果提供适当的提示，LLM可能会显示出令人印象深刻的推理能力。因此，在训练时不一定要这三部分的权重都同时更新，可以冻结其中的一部分（如LLM），只训练另外部分（如编码器）的权重。训练这种编码可以理解为一种与正常软提示相关的输入条件软提示形式。</p>
<p>本文中实际采用的三个策略为：</p>
<ul>
<li>三个部分都同时进行训练；</li>
<li>冻结 LLM，训练编码器和MLP；</li>
<li>冻结 LLM 和 编码器，只训练MLP。</li>
</ul>
<p>采用后两种策略的理由：LLM部分是基于PaLM模型，已经在大量数据上做过预训练的，其本身可能就已经有着非常强的能力；解码器也是类似的，比如采用ViT模型，那么该模型也是在大量图像数据上预训练过的；<strong>在上述三部分中只有 ψ 是随机初始化的，这部分模型必须要重新训练</strong>。</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>测试演示详见论文主页：<a target="_blank" rel="noopener" href="https://palm-e.github.io/">https://palm-e.github.io/</a></p>
<p><strong>对比Baseline：VLM——PaLI（未在实例机器人数据上进行训练）、SayCan算法</strong></p>
<h3 id="机器人任务"><a href="#机器人任务" class="headerlink" title="机器人任务"></a>机器人任务</h3><p><img src="/images/palm-e/3.png" alt="机器人任务效果总览"></p>
<h4 id="任务和运动规划Task-and-Motion-Planning（TAMP）"><a href="#任务和运动规划Task-and-Motion-Planning（TAMP）" class="headerlink" title="任务和运动规划Task and Motion Planning（TAMP）"></a>任务和运动规划Task and Motion Planning（TAMP）</h4><p><strong>四种 VQA 问题 + 两种plan问题</strong>：</p>
<p>四种 VQA 问题：</p>
<ul>
<li>q1 : <strong>物品颜色问题</strong>。举例：给定一张图片。问：桌面上的物体是什么颜色？答：桌面上的物体是黄色。</li>
<li>q2 : <strong>物品-桌面位置关系问题</strong>。举例：给定一张图片。问：红色的物体在桌面的上方？左方？还是中心？答：红色的物体在桌面的中心。</li>
<li>q3 : <strong>物品-物品位置关系问题</strong>。举例：给定一张图片。问：黄色的物体是在蓝色的物体的下方吗？答：黄色的物体不在蓝色的物体的下方。</li>
<li>q4 : <strong>计划的可行性问题</strong>。举例：给定一张图片。问：先把蓝色的物体拿起来，然后把它堆放到黄色的物体上，然后能直接拿起黄色的物体吗？答：不能。</li>
</ul>
<p>两种 plan 问题：</p>
<ul>
<li>p1 : <strong>抓取问题</strong>。举例：给定一张图片。问：如何抓取绿色的物体？答：首先抓取黄色的物体并将其放到桌面上，然后抓取绿色的物体。</li>
<li>p2 : <strong>堆叠问题</strong>。举例：给定一张图片。问：如何将白色的物体堆放到红色的物体上方？答：首先抓取绿色的物体并将其放到桌面上，然后抓取白色的物体并将其堆放到红色的物体上方。</li>
</ul>
<p><img src="/images/palm-e/7.png" alt="Task and Motion Planning"></p>
<p>实验结果：</p>
<p><img src="/images/palm-e/8.png" alt="来自TAMP的数据仅占总训练数据大小的1%"></p>
<ul>
<li>在训练比较少的情况下，使用预训练模型能够有较大的收益；</li>
<li>ViT+TL 还是 ViT-4B 都不能够很好的处理2个plan任务，而加上跨任务（NLP+图像任务+机器人任务TAMP）的数据做训练之后（full mixture）在2个plan任务上的效果有了较大幅度的提升，这说明跨任务联合训练是有效的；</li>
<li>使用了 OSRT 作为编码器的效果较好；</li>
<li>SayCan 和 PaLI 在仅使用1%的训练数据做训练的场景下，几乎没有能力解决相应的问题。</li>
</ul>
<p><img src="/images/palm-e/6.png" alt="在全量TAMP数据上训练，未使用除TAMP以外的任务数据"></p>
<p>任务 TAMP 的每条训练数据中都是有3~5个物体，测试时还将每条数据中的物体数量增加到6个、甚至8个，以及还会增加训练数据中不存在的物体（out-of-distribution, OOD）。</p>
<ul>
<li>当每条测试数据中的物体数量为3~5个时，各模型表现较为接近；</li>
<li>将每条测试数据中的物体数量增加到6个、甚至8个时，使用了预训练的 LLM 之后效果有着明显的提升；</li>
<li>在出现了训练数据中不存在的物体（OOD）时，不使用预训练 LLM 的模型完全无法处理该任务；使用了预训练 LLM 之后效果明显提升；并且将模型的尺寸由8B增大到62B之后也会有明显的提升。</li>
</ul>
<p><img src="/images/palm-e/15.png" alt="Frozen Comparision"></p>
<h4 id="桌面级操作Tabletop-Manipulation"><a href="#桌面级操作Tabletop-Manipulation" class="headerlink" title="桌面级操作Tabletop Manipulation"></a>桌面级操作Tabletop Manipulation</h4><p>在桌面上摆一些不同颜色、不同形状的物体，机器人按照输入的命令用机械臂移动这些物体。</p>
<p><img src="/images/palm-e/4.png" alt="Tabletop Manipulation"></p>
<p>长期任务数据集：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.06407">Language-Table</a></p>
<blockquote>
<p>长期任务：模型无法通过一步完成该任务，而是需要每次自己生成策略、执行相应的action，然后观察外界环境，再次自己生成策略、执行相应的action，直到观察外界环境满足了任务要求。</p>
</blockquote>
<p><img src="/images/palm-e/10.png" alt="Tabletop Manipulation"></p>
<p>数据集中包含3个任务类型：</p>
<ul>
<li><strong>Task1</strong> ：将最靠近{某个方位，比如：右上角}的块，推到与它颜色相同的另一个块那里。</li>
<li><strong>Task2</strong> ：将所有的块按照颜色分组，并将每组推到桌面的四个角上。</li>
<li><strong>Task3</strong> ：将 左侧/右侧 的块推到一起，不要移动任何 右侧/左侧 的块。</li>
</ul>
<p><img src="/images/palm-e/9.png" alt="Tabletop Manipulation"></p>
<ul>
<li>使用预训练模型后效果大幅提升；</li>
<li>增大模型参数规模后，在Task1和Task3这两个任务上有明显的提升，但是在Task2这个任务上有一些降低；</li>
<li>SayCan 和 PaLI 这两个Baseline依然不具有解决该问题的能力。</li>
</ul>
<h4 id="移动操作Mobile-Manipulation"><a href="#移动操作Mobile-Manipulation" class="headerlink" title="移动操作Mobile Manipulation"></a>移动操作Mobile Manipulation</h4><p>移动操作环境就是机器人是可移动的，不再固定在桌面上。</p>
<p><img src="/images/palm-e/5.png" alt="Mobile Manipulation"></p>
<p>测试任务：</p>
<ul>
<li>Affordance Prediction：给定一个物体/环境，以及一个操作，让模型预测该操作是否可在给定的物体/环境上执行。比如当环境中是红色块堆放在绿色块上方时，让模型预测能否抓取绿色块。模型预测结果应该是不能，因为必须先将红色块从绿色块上拿下来放到桌面上之后才能够抓取绿色块。</li>
<li>Failure Detection: 对于机器人来说，当它执行完某一个操作之后，检测该操作是否执行成功也是很重要的。该任务就是检测执行的操作是否成功。</li>
</ul>
<p><img src="/images/palm-e/14.png" alt="Mobile Manipulation"></p>
<ul>
<li>对于任务 Affordance Prediction：12B的 PaLM 预训练模型效果比 PaLI 和 QT-OPT 效果都要好；</li>
<li>对于任务 Failure Detection：12B的 PaLM 预训练模型效果明显超过了 PaLI 和 CLIP-FT；即使是使用了额外的数据做了优化的 CLIP-FT-hindsight 的效果也比 PaLM-E-12B 要略差一些。</li>
</ul>
<h3 id="视觉语言相关任务"><a href="#视觉语言相关任务" class="headerlink" title="视觉语言相关任务"></a>视觉语言相关任务</h3><h4 id="Visual-Language-Tasks"><a href="#Visual-Language-Tasks" class="headerlink" title="Visual-Language Tasks"></a>Visual-Language Tasks</h4><p>总共3个任务，两个VQA任务：OK-VQA 任务和 VQAv2 任务，一个字幕任务：COCO captioning 任务。</p>
<p><img src="/images/palm-e/12.png" alt="Visual-Language Tasks"></p>
<h4 id="Natural-Language-Processing-Tasks"><a href="#Natural-Language-Processing-Tasks" class="headerlink" title="Natural Language Processing Tasks"></a>Natural Language Processing Tasks</h4><p>测试模型：</p>
<ul>
<li>PaLM-E-12B ：使用 PaLM-8B 作为基座，加上 ViT-4B 得到的模型；</li>
<li>PaLM-E-84B ：使用 PaLM-62B 作为基座，加上 ViT-22B 得到的模型；</li>
<li>PaLM-E-562B ：使用 PaLM-540B 作为基座，加上 ViT-22B 得到的模型；</li>
</ul>
<p><img src="/images/palm-e/13.png" alt="NLP Tasks"></p>
<p>所有的 PaLM-E 模型都在机器人任务上做了微调，显然微调后的 PaLM-E 模型相较其对应的基本PaLM模型在NLP（NLG + NLU）任务上的效果均有所下降：</p>
<ul>
<li>PaLM-E-12B 相比于 PaLM-8B 在NLU和NLG任务上分别下降了 15.0% 和 87.3%；</li>
<li>PaLM-E-84B 相比于 PaLM-62B 在NLU和NLG任务上分别下降了 4.3% 和 61.6%；</li>
<li>PaLM-E-562B 相比于 PaLM-540B 在NLU任务上上升了 0.4%，在NLG任务上下降了 3.8%；</li>
</ul>
<p><img src="/images/palm-e/11.png" alt="NLG Tasks"></p>
<p><strong>增加模型参数规模可以减少相应的 PaLM-E 模型与其继承的 PaLM 模型之间的灾难性遗忘。</strong>当模型特别大时，其所能储备信息的能力大幅增大，这样在新任务上做训练之后，就对之前的任务损耗较小。</p>
</div></div><div class="article-licensing box"><div class="licensing-title"><p>PaLM-E：An Embodied Multimodal Language Model</p><p><a href="http://asgard-tim.github.io/2025/05/09/PaLM-E/">http://asgard-tim.github.io/2025/05/09/PaLM-E/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Tim</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2025-05-09</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-07-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/VLA/">VLA</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/">具身智能</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/">多模态大模型</a><a class="link-muted mr-2" rel="tag" href="/tags/PaLM-E/">PaLM-E</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/wechat.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/alipay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/05/15/Survey/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">A Survey on Vision-Language-Action Models for Embodied AI</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2025/04/23/project02/"><span class="level-item">图像插值算法及其优化</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.16/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "4YfCkg9RY2bBZosr2CIG3MbR-gzGzoHsz",
            appKey: "yY6mlbvEevj97fBj9Ri4czpD",
            placeholder: "请多指教",
            avatar: "mm",
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: false,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Background"><span class="level-left"><span class="level-item">1</span><span class="level-item">Background</span></span></a></li><li><a class="level is-mobile" href="#Model"><span class="level-left"><span class="level-item">2</span><span class="level-item">Model</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Multi-model-sentences——不同模态的对齐"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Multi-model sentences——不同模态的对齐</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Token-embedding-space——将文本映射至嵌入空间"><span class="level-left"><span class="level-item">2.1.1</span><span class="level-item">Token embedding space——将文本映射至嵌入空间</span></span></a></li><li><a class="level is-mobile" href="#不同传感器的数据映射"><span class="level-left"><span class="level-item">2.1.2</span><span class="level-item">不同传感器的数据映射</span></span></a></li></ul></li><li><a class="level is-mobile" href="#模型架构"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">模型架构</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Decoder-only-LLM"><span class="level-left"><span class="level-item">2.2.1</span><span class="level-item">Decoder-only LLM</span></span></a></li><li><a class="level is-mobile" href="#Prefix-decoder-only-LLM"><span class="level-left"><span class="level-item">2.2.2</span><span class="level-item">Prefix-decoder-only LLM</span></span></a></li><li><a class="level is-mobile" href="#模型在机器人控制环中的输出"><span class="level-left"><span class="level-item">2.2.3</span><span class="level-item">模型在机器人控制环中的输出</span></span></a></li></ul></li><li><a class="level is-mobile" href="#模型训练方法"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">模型训练方法</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#训练数据集"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">训练数据集</span></span></a></li><li><a class="level is-mobile" href="#损失函数"><span class="level-left"><span class="level-item">2.3.2</span><span class="level-item">损失函数</span></span></a></li><li><a class="level is-mobile" href="#模型参数规模"><span class="level-left"><span class="level-item">2.3.3</span><span class="level-item">模型参数规模</span></span></a></li><li><a class="level is-mobile" href="#模型冻结"><span class="level-left"><span class="level-item">2.3.4</span><span class="level-item">模型冻结</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#Experiments"><span class="level-left"><span class="level-item">3</span><span class="level-item">Experiments</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#机器人任务"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">机器人任务</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#任务和运动规划Task-and-Motion-Planning（TAMP）"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">任务和运动规划Task and Motion Planning（TAMP）</span></span></a></li><li><a class="level is-mobile" href="#桌面级操作Tabletop-Manipulation"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">桌面级操作Tabletop Manipulation</span></span></a></li><li><a class="level is-mobile" href="#移动操作Mobile-Manipulation"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">移动操作Mobile Manipulation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#视觉语言相关任务"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">视觉语言相关任务</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Visual-Language-Tasks"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">Visual-Language Tasks</span></span></a></li><li><a class="level is-mobile" href="#Natural-Language-Processing-Tasks"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">Natural Language Processing Tasks</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer=""></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/head2.png" alt="Jinghua Xu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jinghua Xu</p><p class="is-size-6 is-block">明月科创实验班人工智能专业 本科大三在读</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>重庆 重庆大学国家卓越工程师学院</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">37</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">24</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">102</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Asgard-Tim" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/u/6315188431"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Bilibili" href="https://space.bilibili.com/171895120"><i class="fab fa-bilibili"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:20224546@stu.cqu.edu.cn"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Phone" href="tel:+86 19132050174"><i class="fas fa-phone"></i></a></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2025/06/29/manufac/"><img src="/images/manufac/b99d7042c32e0662693c9051eb8316a5.jpg" alt="小提琴自动演奏机器人中的齿轮系统设计与制造"></a></figure><div class="media-content"><p class="date"><time datetime="2025-06-29T08:40:43.000Z">2025-06-29</time></p><p class="title"><a href="/2025/06/29/manufac/">小提琴自动演奏机器人中的齿轮系统设计与制造</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E5%88%B6%E9%80%A0/">产品制造</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/06/21/sweeping/"><img src="/images/sweeping/0c9ca142c80746ccde051fd86d54a57c.png" alt="SmartRobot扫地机器人"></a></figure><div class="media-content"><p class="date"><time datetime="2025-06-20T20:02:03.000Z">2025-06-21</time></p><p class="title"><a href="/2025/06/21/sweeping/">SmartRobot扫地机器人</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%BE%AE%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1/">微电路设计</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/06/10/project3/"><img src="/images/project3/9.png" alt="常微分方程反演的机器学习方法"></a></figure><div class="media-content"><p class="date"><time datetime="2025-06-09T18:59:03.000Z">2025-06-10</time></p><p class="title"><a href="/2025/06/10/project3/">常微分方程反演的机器学习方法</a></p><p class="categories"><a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/">课程项目</a> / <a href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/">工程数值分析</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/15/Survey/"><img src="/images/survey/2.png" alt="A Survey on Vision-Language-Action Models for Embodied AI"></a></figure><div class="media-content"><p class="date"><time datetime="2025-05-15T15:32:03.000Z">2025-05-15</time></p><p class="title"><a href="/2025/05/15/Survey/">A Survey on Vision-Language-Action Models for Embodied AI</a></p><p class="categories"><a href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2025/05/09/PaLM-E/"><img src="/images/palm-e/0.png" alt="PaLM-E：An Embodied Multimodal Language Model"></a></figure><div class="media-content"><p class="date"><time datetime="2025-05-09T11:57:03.000Z">2025-05-09</time></p><p class="title"><a href="/2025/05/09/PaLM-E/">PaLM-E：An Embodied Multimodal Language Model</a></p><p class="categories"><a href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">具身智能论文阅读</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/About-XJH/"><span class="level-start"><span class="level-item">About XJH</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E6%85%B5/"><span class="level-start"><span class="level-item">明慵</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/About-XJH/%E6%98%8E%E8%AF%9A/"><span class="level-start"><span class="level-item">明诚</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">个人项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="level-start"><span class="level-item">具身智能论文阅读</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">动手学深度学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/"><span class="level-start"><span class="level-item">算法基础课</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">课程项目</span></span><span class="level-end"><span class="level-item tag">26</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E5%88%B6%E9%80%A0/"><span class="level-start"><span class="level-item">产品制造</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">产品设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95I/"><span class="level-start"><span class="level-item">定量工程设计方法I</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%AE%9A%E9%87%8F%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95II/"><span class="level-start"><span class="level-item">定量工程设计方法II</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E6%95%88%E5%AD%A6/"><span class="level-start"><span class="level-item">工效学</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">工程原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">工程数值分析</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%B7%A5%E7%A8%8B%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">工程设计</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E5%BE%AE%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">微电路设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E6%B3%95/"><span class="level-start"><span class="level-item">数学物理方法</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%99%BA%E8%83%BD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">智能图像处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">机器人基础</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><span class="level-start"><span class="level-item">概率论与数理统计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="level-start"><span class="level-item">线性代数</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/"><span class="level-start"><span class="level-item">自动控制原理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BE%E7%A8%8B%E9%A1%B9%E7%9B%AE/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">软件设计</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">六月 2025</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/05/"><span class="level-start"><span class="level-item">五月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">四月 2025</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">三月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/02/"><span class="level-start"><span class="level-item">二月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">一月 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">一月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">十一月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">七月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">六月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">三月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%95%E7%89%87%E6%9C%BA/"><span class="tag">单片机</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/STM32/"><span class="tag">STM32</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLA/"><span class="tag">VLA</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/"><span class="tag">具身智能</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">多模态大模型</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%8F%91%E5%8A%A8%E6%9C%BA/"><span class="tag">斯特林发动机</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MATLAB/"><span class="tag">MATLAB</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matlab/"><span class="tag">Matlab</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">动手学深度学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="tag">学习笔记</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E8%BD%A6/"><span class="tag">小车</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/"><span class="tag">信号与系统</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A2%91%E8%B0%B1%E5%88%86%E6%9E%90/"><span class="tag">频谱分析</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%AF%E7%89%B9%E6%9E%97%E5%BE%AA%E7%8E%AF/"><span class="tag">斯特林循环</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E5%8A%9B%E5%AD%A6%E4%BB%BF%E7%9C%9F/"><span class="tag">动力学仿真</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%89%E9%99%90%E5%85%83%E4%BB%BF%E7%9C%9F/"><span class="tag">有限元仿真</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="tag">算法与数据结构</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/3D-VLA/"><span class="tag">3D-VLA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PaLM-E/"><span class="tag">PaLM-E</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"><span class="tag">路径规划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RANSAC/"><span class="tag">RANSAC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%88%86%E6%9E%90/"><span class="tag">数据处理分析</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/title1.png" alt="Homepage of Jinghua Xu" height="28"></a><p class="is-size-7"><span>© 2025 Tim</span>&nbsp;&nbsp;Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>&nbsp;&amp;&nbsp;<a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© Copyright by Jinghua Xu</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Asgard-Tim"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer=""></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer=""></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer=""></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer=""></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer=""></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer=""></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer=""></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer=""></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script>
    <link rel="stylesheet" href="https://ai.tianli0.top/static/public/postChatUser_summary.min.css">
    <script>
        let tianliGPT_key = 'S-TA3IX28M1ZT7TILW';
        let tianliGPT_postSelector = '#postchat_postcontent';
        let tianliGPT_Title = '文章摘要';
        let tianliGPT_postURL = '/^https?://[^/]+/[0-9]{4}/[0-9]{2}/[0-9]{2}/';
        let tianliGPT_blacklist = '';
        let tianliGPT_wordLimit = '1000';
        let tianliGPT_typingAnimate = true;
        let tianliGPT_theme = 'default';
        var postChatConfig = {
          backgroundColor: "#3e86f6",
          bottom: "16px",
          left: "16px",
          fill: "#FFFFFF",
          width: "44px",
          frameWidth: "375px",
          frameHeight: "600px",
          defaultInput: true,
          upLoadWeb: true,
          showInviteLink: true,
          userTitle: "PostChat",
          userDesc: "如果你对网站的内容有任何疑问，可以来问我哦～",
          addButton: true,
          beginningText: "这篇文章介绍了",
          userIcon: "https://ai.tianli0.top/static/img/PostChat.webp",
          userMode: "magic",
          defaultChatQuestions: ["你好","你是谁"],
          defaultSearchQuestions: ["视频压缩","设计"]
        };
    </script>
    <script data-postchat_key="S-TA3IX28M1ZT7TILW" src="https://ai.tianli0.top/static/public/tianli_gpt.min.js"></script>
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=EcdeIC110ly5NqL8_Ofvg7uwL4-NE9F-lRhSp4--kPY"></script>
  <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>